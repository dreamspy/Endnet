{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which GPU to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiGPU = False\n",
    "whichGPU = 0\n",
    " \n",
    "# Select which GPU to use\n",
    "if(multiGPU):\n",
    "    from keras.utils.training_utils import multi_gpu_model\n",
    "else:\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    # The GPU id to use, usually either \"0\" or \"1\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(whichGPU)\n",
    "    \n",
    "# # Do other imports now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run -i 'arena.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# What data to use\n",
    "tableBase = '4PpKk'\n",
    "convertStates = False\n",
    "\n",
    "# Interactive (just in general if one is asked for confirmations, set to False if on autopilot over night f.x.)\n",
    "askForConfirmation = False\n",
    "\n",
    "# NN parameters\n",
    "filters = [16,32,32,64,128,128,128]\n",
    "filterShape = [2,2,2,2,2,2,2]\n",
    "batch_size = 256\n",
    "optimizer = 'Adadelta'\n",
    "useBatchNorm = False\n",
    "num_classes = 3\n",
    "input_shape = (4,8,8)\n",
    "\n",
    "### DON'T MODIFY BELOW ###\n",
    "# Generate dataset variables\n",
    "fileName = tableBase + '.hdf5'\n",
    "dataSetName = tableBase + '_onlyLegal'\n",
    "if not convertStates: \n",
    "    dataSetName = tableBase + '_onlyLegal_fullStates'\n",
    "dataSetWdlName = tableBase + '_Wdl_onlyLegal_3Values'\n",
    "\n",
    "# Number of Pieces\n",
    "nPi =  int(dataSetName[0])\n",
    "nPa = nPi - 2\n",
    "nWPa = math.ceil(nPa/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "Bengio methood\n",
    "3n4 no freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 1 Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3n4 no freeze \n",
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch\n",
    "freeze = False\n",
    "resSaveFile = '3n4nofreeze'\n",
    "epochs = 10\n",
    "averageOver = 10\n",
    "expDescr = \"Bengio 3n4 - freeze = {} - average over {} runs\".format(str(freeze), averageOver)\n",
    "\n",
    "saveEveryRun = False # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = False # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "saveDir = 'bengioResults'\n",
    "\n",
    "resSaveFile = resSaveFile + '-{}runAverage'.format(averageOver)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save file exists...\n",
      "\n",
      "X_train shape: (4982178, 4, 8, 8)\n",
      "y_train shape: (4982178, 1)\n",
      "X_test shape: (2453910, 4, 8, 8)\n",
      "y_test shape: (2453910, 1)\n",
      "4982178 train samples\n",
      "2453910 test samples\n",
      "Done loading dataset\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n",
      "\n",
      "Starting/restarting TL at 1 transfered layers\n"
     ]
    }
   ],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData()\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==========================================================================================\n",
      "=                                                                                        =\n",
      "=                    Currently transfering first 1 layers, out of 8                      =\n",
      "=                                                                                        =\n",
      "==========================================================================================\n",
      "\n",
      "Loading first 1 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 2: <keras.layers.convolutional.Conv2D object at 0x7f6294ff9978>\n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f6294f8fc50>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f6294fa2400>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f6294fb9518>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f6294f691d0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f6294f02588>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f6294f1c588>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f6294f1c9b0>\n",
      "Train on 4982178 samples, validate on 2453910 samples\n",
      "Epoch 1/10\n",
      " 997632/4982178 [=====>........................] - ETA: 2:02 - loss: 0.3996 - acc: 0.8232"
     ]
    }
   ],
   "source": [
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "    accumulatedScore = 0\n",
    "    for a in range(averageOver):\n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            file.write('Layers Transfered: {}\\nInner avg loop position: {}'.format(copyFirstNLayers, a)) \n",
    "        \n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "\n",
    "    ############ T O D O ############## \n",
    "    # save old results to backup dir\n",
    "    \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "\n",
    "    # to load:\n",
    "    # results = load_obj('temp','3n4.txt')\n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:endnetGpu]",
   "language": "python",
   "name": "conda-env-endnetGpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
