{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = '3PKk.hdf5'\n",
    "# fileName = 'AllStates_intVec.hdf5'\n",
    "nPi = 3\n",
    "nPa = 1\n",
    "nWPa = 1\n",
    "input_shape = (4,8,8)\n",
    "batch_size = 256\n",
    "epochs = 300\n",
    "dataDiv = 1\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "import keras\n",
    "# from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "# import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage\n",
      "    Open file handle:        f = h5py.File(fileName,'a')\n",
      "    Close file handle:       f.close\n",
      "    Load dataset :           dataset = loadDataSetFromFile(fileHandle, dataSetName)\n",
      "    Load dataset interactively:dataset = loadDataSetInteractive(f)\n",
      "    Display this help:       help() \n"
     ]
    }
   ],
   "source": [
    "# %load h5View.py\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import signal\n",
    "\n",
    "def db(t,v):\n",
    "    if debug == True:\n",
    "        print(t,v)\n",
    "debug = False\n",
    "debug = True\n",
    "\n",
    "def Db(t,v):\n",
    "    if Debug == True:\n",
    "        print(t,v)\n",
    "Debug = False\n",
    "Debug = True\n",
    "\n",
    "def loadDataSetFromFile(fileName, dataSetName):\n",
    "    f = h5py.File(fileName, 'a')\n",
    "    return f[dataSetName]\n",
    "\n",
    "def loadDataSetFromHandle(f, dataSetName = None):\n",
    "    ####################\n",
    "    #\n",
    "    #   Signal Handler\n",
    "    #\n",
    "    ####################\n",
    "    def exit_gracefully(signum, frame):\n",
    "        # restore the original signal handler as otherwise evil things will happen\n",
    "        # in raw_input when CTRL+C is pressed, and our signal handler is not re-entrant\n",
    "        signal.signal(signal.SIGINT, original_sigint)\n",
    "\n",
    "        try:\n",
    "            # if input(\"\\nReally quit? (y/n)> \").lower().startswith('y'):\n",
    "            #     print(\"Flushing data to disk\")\n",
    "            #     f.close()\n",
    "            #     sys.exit(1)\n",
    "            print(\"\\nFlushing data to disk\")\n",
    "            f.close()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nOk ok, quitting\")\n",
    "            print(\"Flushing data to disk\")\n",
    "            f.close()\n",
    "            sys.exit(1)\n",
    "\n",
    "        # restore the exit gracefully handler here\n",
    "        signal.signal(signal.SIGINT, exit_gracefully)\n",
    "\n",
    "    # store the original SIGINT handler\n",
    "    original_sigint = signal.getsignal(signal.SIGINT)\n",
    "    signal.signal(signal.SIGINT, exit_gracefully)\n",
    "\n",
    "    ####################\n",
    "    #\n",
    "    #   Main\n",
    "    #\n",
    "    ####################\n",
    "\n",
    "    # f = h5py.File(fileName, 'a')\n",
    "    # print(\"File loadded, f = \" + fileName)\n",
    "    \n",
    "    if dataSetName != None:\n",
    "    \n",
    "        print(\"Datasets:\")\n",
    "        i = 0\n",
    "        datasetNames = [ds for ds in f]\n",
    "        for ds in datasetNames:\n",
    "            print('Nr:' , i , '  Name:', ds.ljust(15), \"Size:\", f[ds].shape )\n",
    "            i += 1\n",
    "        # print(f[0])\n",
    "        while True:\n",
    "            selectDS = int(input(\"Select dataset: \"))\n",
    "            action = input(str(\"Do you want to load dataset: \" + datasetNames[selectDS] + \"? [y/n] \"))\n",
    "            if action == 'y' or action == 'Y':\n",
    "                dataset = f[datasetNames[selectDS]]\n",
    "                print(\"Dataset loaded\")\n",
    "                break\n",
    "        return dataset\n",
    "    else:\n",
    "        return f[dataSetName]\n",
    "\n",
    "def checkForTens(dataset):\n",
    "    d = 1000\n",
    "    l = len(dataset)\n",
    "    p = int(l/d)\n",
    "\n",
    "    for i in range(l):\n",
    "        if dataset[i]==10:\n",
    "            print('i: ', i, ' dataset[{}]'.format(i), dataset[i])\n",
    "        if i%p==0:\n",
    "            print(round(i/l,3))\n",
    "\n",
    "def help():\n",
    "\n",
    "    Db(\"Usage\" +\n",
    "       \"\\n    \" +\n",
    "       \"Open file handle:\".ljust(25) + \"f = h5py.File(fileName,'a')\" +\n",
    "       \"\\n    \" +\n",
    "       \"Close file handle:\".ljust(25) + \"f.close\" +\n",
    "       \"\\n    \" +\n",
    "       \"Load dataset :\".ljust(25) + \"dataset = loadDataSetFromFile(fileHandle, dataSetName)\" +\n",
    "       \"\\n    \" +\n",
    "       \"Load dataset interactively:\".ljust(25) + \"dataset = loadDataSetInteractive(f)\" +\n",
    "       \"\\n    \" +\n",
    "       \"Display this help:\". ljust(25) + \"help()\"\n",
    "       ,'')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ########################\n",
    "    #\n",
    "    #   Parameters\n",
    "    #\n",
    "    ########################\n",
    "\n",
    "#     fileName = 'AllStates_intVec.hdf5'\n",
    "#     dataSetName = \"36KPvKPP\"\n",
    "\n",
    "    help()\n",
    "\n",
    "#     db(\"\\nOpening file:\", fileName)\n",
    "#     f = h5py.File(fileName, 'a')\n",
    "#     dataset = 0\n",
    "#     dataset = loadDataSetInteractive(f)\n",
    "#     print(\"...to variable dataset\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "```\n",
    "3PKk-Wdl-Buffered == 3PKk-Wdl-Seq\n",
    "\n",
    "4PpKk-Wdl == 4PpKk-Wdl-Buffered != 4PpKk-Wdl-retry\n",
    "\n",
    "5PPpKk-Wdl != 5PPpKk-Wdl-Buffered\n",
    "    from 50.000 then buffered != 10, but wdl == 10\n",
    "```\n",
    "  \n",
    "### WDL score count\n",
    "#### 3PKk-WDL-Seq\n",
    "[0, 0, 125024, 0, 124960]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for vector to full state conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sq2hnit(sq):\n",
    "    col = sq%8\n",
    "    row = (sq - col)//8\n",
    "    return col,row\n",
    "\n",
    "# 0: pawns\n",
    "# 1: kings\n",
    "def vecSt2fullSt(vecSt, nPi, nPa, nWPa):\n",
    "    fullSt = np.zeros((4,8,8), dtype = 'int8')\n",
    "    for i in range(nPi - 2):\n",
    "        sq = vecSt[i]\n",
    "        col,row = sq2hnit(sq)\n",
    "        if i < nWPa:\n",
    "            fullSt[0][row][col] = 1\n",
    "        else:\n",
    "            fullSt[1][row][col] = -1\n",
    "    col,row = sq2hnit(vecSt[-2])\n",
    "    fullSt[2][row][col] = 1\n",
    "    col,row = sq2hnit(vecSt[-1])\n",
    "    fullSt[3][row][col] = -1\n",
    "    return fullSt \n",
    "\n",
    "def vecSt2fullSt_8x8x2(vecSt, nPi, nPa, nWPa):\n",
    "    fullSt = np.zeros((8,8,2), dtype = 'int8')\n",
    "    for i in range(nPi - 2):\n",
    "        sq = vecSt[i]\n",
    "        col,row = sq2hnit(sq)\n",
    "        if i < nWPa:\n",
    "            fullSt[row][col][0] = 1\n",
    "        else:\n",
    "            fullSt[row][col][0] = -1\n",
    "    col,row = sq2hnit(vecSt[-2])\n",
    "    fullSt[row][col][1] = 1\n",
    "    col,row = sq2hnit(vecSt[-1])\n",
    "    fullSt[row][col][1] = -1\n",
    "    return fullSt \n",
    "# nPi = 3\n",
    "# nPa = 1\n",
    "# nWPa = 1\n",
    "# vecSt2fullSt(d3[0], nPi, nPa, nWPa)\n",
    "# nPi = 5\n",
    "# nPa = 3\n",
    "# nWPa = 2\n",
    "# vecSt2fullSt(d5[0], nPi, nPa, nWPa)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "f = h5py.File(fileName, 'a')\n",
    "d3 = f['3PKk']\n",
    "d3t = f['3PKk-Wdl-Seq']\n",
    "# d5 = f['5PPpKk']\n",
    "l = len(d3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count nr of each score instance\n",
    "# wdlCounter placeholders: [-2, -1, 0, 1 ,2]\n",
    "\n",
    "def wdlCountingMachine(ds):\n",
    "    wdlCounter = [0,0,0,0,0]\n",
    "    l = len(ds)\n",
    "    i = 0\n",
    "    intv = l//100\n",
    "    for wdl in ds:\n",
    "        i += 1\n",
    "        if i%intv == 0:\n",
    "            sys.stdout.write(str((i*100)//l) + \" percentage\")\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.flush()\n",
    "        wdlCounter[wdl[0] + 2] += 1\n",
    "    print(wdlCounter)\n",
    "    return wdlCounter\n",
    "# wdlCountingMachine(d3t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([vecSt2fullSt(vecSt,nPi, nPa, nWPa) for vecSt in d3[:l//dataDiv]])\n",
    "y = d3t[:l//dataDiv]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82495, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (167489, 4, 8, 8)\n",
      "y_train shape: (167489, 1)\n",
      "X_test shape: (82495, 4, 8, 8)\n",
      "y_test shape: (82495, 1)\n",
      "167489 train samples\n",
      "82495 test samples\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 6, 6)          2368      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 62, 4, 96)         5280      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 2, 256)        221440    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30720)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 153605    \n",
      "=================================================================\n",
      "Total params: 382,693\n",
      "Trainable params: 382,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 data_format = \"channels_first\",\n",
    "#                  kernel_initializer = \n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(96, kernel_size=(3, 3),\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 167489 samples, validate on 82495 samples\n",
      "Epoch 1/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 0.3408 - acc: 0.8330 - val_loss: 0.1340 - val_acc: 0.9447\n",
      "Epoch 2/300\n",
      "167489/167489 [==============================] - 91s 545us/step - loss: 0.1017 - acc: 0.9587 - val_loss: 0.0825 - val_acc: 0.9658\n",
      "Epoch 3/300\n",
      "167489/167489 [==============================] - 91s 545us/step - loss: 0.0649 - acc: 0.9737 - val_loss: 0.0552 - val_acc: 0.9779\n",
      "Epoch 4/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0522 - acc: 0.9791 - val_loss: 0.0902 - val_acc: 0.9628\n",
      "Epoch 5/300\n",
      "167489/167489 [==============================] - 96s 575us/step - loss: 0.0438 - acc: 0.9823 - val_loss: 0.0534 - val_acc: 0.9790\n",
      "Epoch 6/300\n",
      "167489/167489 [==============================] - 97s 576us/step - loss: 0.0376 - acc: 0.9852 - val_loss: 0.0460 - val_acc: 0.9821\n",
      "Epoch 7/300\n",
      "167489/167489 [==============================] - 96s 575us/step - loss: 0.0335 - acc: 0.9867 - val_loss: 0.0347 - val_acc: 0.9864\n",
      "Epoch 8/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0298 - acc: 0.9881 - val_loss: 0.0494 - val_acc: 0.9803\n",
      "Epoch 9/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0266 - acc: 0.9895 - val_loss: 0.0422 - val_acc: 0.9835\n",
      "Epoch 10/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0243 - acc: 0.9905 - val_loss: 0.0271 - val_acc: 0.9891\n",
      "Epoch 11/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0216 - acc: 0.9915 - val_loss: 0.0316 - val_acc: 0.9875\n",
      "Epoch 12/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0195 - acc: 0.9924 - val_loss: 0.0255 - val_acc: 0.9900\n",
      "Epoch 13/300\n",
      "167489/167489 [==============================] - 96s 575us/step - loss: 0.0190 - acc: 0.9927 - val_loss: 0.0185 - val_acc: 0.9930\n",
      "Epoch 14/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0167 - acc: 0.9936 - val_loss: 0.0213 - val_acc: 0.9917\n",
      "Epoch 15/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0145 - acc: 0.9944 - val_loss: 0.0163 - val_acc: 0.9937\n",
      "Epoch 16/300\n",
      "167489/167489 [==============================] - 97s 580us/step - loss: 0.0135 - acc: 0.9948 - val_loss: 0.0251 - val_acc: 0.9908\n",
      "Epoch 17/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0123 - acc: 0.9954 - val_loss: 0.0662 - val_acc: 0.9788\n",
      "Epoch 18/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0114 - acc: 0.9956 - val_loss: 0.0233 - val_acc: 0.9912\n",
      "Epoch 19/300\n",
      "167489/167489 [==============================] - 96s 575us/step - loss: 0.0104 - acc: 0.9960 - val_loss: 0.0188 - val_acc: 0.9930\n",
      "Epoch 20/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0099 - acc: 0.9963 - val_loss: 0.0174 - val_acc: 0.9934\n",
      "Epoch 21/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0087 - acc: 0.9968 - val_loss: 0.0414 - val_acc: 0.9861\n",
      "Epoch 22/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0076 - acc: 0.9973 - val_loss: 0.0151 - val_acc: 0.9947\n",
      "Epoch 23/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0174 - val_acc: 0.9938\n",
      "Epoch 24/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0066 - acc: 0.9976 - val_loss: 0.0369 - val_acc: 0.9886\n",
      "Epoch 25/300\n",
      "167489/167489 [==============================] - 96s 576us/step - loss: 0.0061 - acc: 0.9978 - val_loss: 0.0174 - val_acc: 0.9941\n",
      "Epoch 26/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0165 - val_acc: 0.9942\n",
      "Epoch 27/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0117 - val_acc: 0.9961\n",
      "Epoch 28/300\n",
      "167489/167489 [==============================] - 97s 580us/step - loss: 0.0051 - acc: 0.9982 - val_loss: 0.0140 - val_acc: 0.9951\n",
      "Epoch 29/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0154 - val_acc: 0.9948\n",
      "Epoch 30/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0040 - acc: 0.9986 - val_loss: 0.0143 - val_acc: 0.9954\n",
      "Epoch 31/300\n",
      "167489/167489 [==============================] - 97s 577us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0165 - val_acc: 0.9947\n",
      "Epoch 32/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0195 - val_acc: 0.9939\n",
      "Epoch 33/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0043 - acc: 0.9985 - val_loss: 0.0190 - val_acc: 0.9940\n",
      "Epoch 34/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0123 - val_acc: 0.9960\n",
      "Epoch 35/300\n",
      "167489/167489 [==============================] - 98s 588us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0149 - val_acc: 0.9953\n",
      "Epoch 36/300\n",
      "167489/167489 [==============================] - 97s 577us/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0176 - val_acc: 0.9943\n",
      "Epoch 37/300\n",
      "167489/167489 [==============================] - 96s 575us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0123 - val_acc: 0.9966\n",
      "Epoch 38/300\n",
      "167489/167489 [==============================] - 97s 577us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0111 - val_acc: 0.9967\n",
      "Epoch 39/300\n",
      "167489/167489 [==============================] - 97s 577us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0147 - val_acc: 0.9955\n",
      "Epoch 40/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0154 - val_acc: 0.9956\n",
      "Epoch 41/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0111 - val_acc: 0.9968\n",
      "Epoch 42/300\n",
      "167489/167489 [==============================] - 97s 577us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0107 - val_acc: 0.9968\n",
      "Epoch 43/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0137 - val_acc: 0.9960\n",
      "Epoch 44/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0139 - val_acc: 0.9960\n",
      "Epoch 45/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0119 - val_acc: 0.9965\n",
      "Epoch 46/300\n",
      "167489/167489 [==============================] - 97s 581us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0162 - val_acc: 0.9951\n",
      "Epoch 47/300\n",
      "167489/167489 [==============================] - 97s 580us/step - loss: 8.2582e-04 - acc: 0.9998 - val_loss: 0.0142 - val_acc: 0.9959\n",
      "Epoch 48/300\n",
      "167489/167489 [==============================] - 97s 581us/step - loss: 7.0951e-04 - acc: 0.9999 - val_loss: 0.0141 - val_acc: 0.9960\n",
      "Epoch 49/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0140 - val_acc: 0.9960\n",
      "Epoch 50/300\n",
      "167489/167489 [==============================] - 96s 575us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0111 - val_acc: 0.9967\n",
      "Epoch 51/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0114 - val_acc: 0.9970\n",
      "Epoch 52/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0133 - val_acc: 0.9964\n",
      "Epoch 53/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 9.1675e-04 - acc: 0.9997 - val_loss: 0.0119 - val_acc: 0.9966\n",
      "Epoch 54/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 9.5624e-04 - acc: 0.9997 - val_loss: 0.0208 - val_acc: 0.9942\n",
      "Epoch 55/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 6.5951e-04 - acc: 0.9998 - val_loss: 0.0174 - val_acc: 0.9952\n",
      "Epoch 56/300\n",
      "167489/167489 [==============================] - 96s 576us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0141 - val_acc: 0.9961\n",
      "Epoch 57/300\n",
      "167489/167489 [==============================] - 97s 578us/step - loss: 9.9227e-04 - acc: 0.9997 - val_loss: 0.0114 - val_acc: 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "167489/167489 [==============================] - 97s 580us/step - loss: 6.9862e-04 - acc: 0.9998 - val_loss: 0.0172 - val_acc: 0.9952\n",
      "Epoch 59/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 5.9295e-04 - acc: 0.9999 - val_loss: 0.0113 - val_acc: 0.9971\n",
      "Epoch 60/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 9.9897e-04 - acc: 0.9997 - val_loss: 0.0113 - val_acc: 0.9969\n",
      "Epoch 61/300\n",
      "167489/167489 [==============================] - 97s 579us/step - loss: 5.4656e-04 - acc: 0.9999 - val_loss: 0.0141 - val_acc: 0.9963\n",
      "Epoch 62/300\n",
      "167489/167489 [==============================] - 97s 577us/step - loss: 7.0158e-04 - acc: 0.9998 - val_loss: 0.0180 - val_acc: 0.9950\n",
      "Epoch 63/300\n",
      "167489/167489 [==============================] - 94s 563us/step - loss: 6.4156e-04 - acc: 0.9999 - val_loss: 0.0102 - val_acc: 0.9973\n",
      "Epoch 64/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.7725e-04 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9973\n",
      "Epoch 65/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 4.1316e-04 - acc: 0.9999 - val_loss: 0.0106 - val_acc: 0.9974\n",
      "Epoch 66/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 4.5644e-04 - acc: 0.9999 - val_loss: 0.0134 - val_acc: 0.9964\n",
      "Epoch 67/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 4.6484e-04 - acc: 0.9999 - val_loss: 0.0136 - val_acc: 0.9962\n",
      "Epoch 68/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 3.3064e-04 - acc: 0.9999 - val_loss: 0.0122 - val_acc: 0.9967\n",
      "Epoch 69/300\n",
      "167489/167489 [==============================] - 92s 547us/step - loss: 3.1244e-04 - acc: 0.9999 - val_loss: 0.0104 - val_acc: 0.9974\n",
      "Epoch 70/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 3.5717e-04 - acc: 0.9999 - val_loss: 0.0099 - val_acc: 0.9975\n",
      "Epoch 71/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 5.0358e-04 - acc: 0.9998 - val_loss: 0.0140 - val_acc: 0.9963\n",
      "Epoch 72/300\n",
      "167489/167489 [==============================] - 93s 556us/step - loss: 4.7496e-04 - acc: 0.9999 - val_loss: 0.0143 - val_acc: 0.9964\n",
      "Epoch 73/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 6.4377e-04 - acc: 0.9998 - val_loss: 0.0126 - val_acc: 0.9968\n",
      "Epoch 74/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 3.1955e-04 - acc: 0.9999 - val_loss: 0.0118 - val_acc: 0.9969\n",
      "Epoch 75/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 3.7602e-04 - acc: 0.9999 - val_loss: 0.0115 - val_acc: 0.9970\n",
      "Epoch 76/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 4.4310e-04 - acc: 0.9999 - val_loss: 0.0123 - val_acc: 0.9970\n",
      "Epoch 77/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.4058e-04 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9972\n",
      "Epoch 78/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.0278 - val_acc: 0.9932\n",
      "Epoch 79/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0155 - val_acc: 0.9961\n",
      "Epoch 80/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 9.3235e-04 - acc: 0.9997 - val_loss: 0.0139 - val_acc: 0.9962\n",
      "Epoch 81/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 4.1596e-04 - acc: 0.9999 - val_loss: 0.0112 - val_acc: 0.9973\n",
      "Epoch 82/300\n",
      "167489/167489 [==============================] - 92s 547us/step - loss: 7.8630e-04 - acc: 0.9998 - val_loss: 0.0132 - val_acc: 0.9968\n",
      "Epoch 83/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 6.4773e-04 - acc: 0.9998 - val_loss: 0.0112 - val_acc: 0.9971\n",
      "Epoch 84/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 3.2107e-04 - acc: 0.9999 - val_loss: 0.0111 - val_acc: 0.9972\n",
      "Epoch 85/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0122 - val_acc: 0.9968\n",
      "Epoch 86/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 5.9719e-04 - acc: 0.9999 - val_loss: 0.0115 - val_acc: 0.9971\n",
      "Epoch 87/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 3.8549e-04 - acc: 0.9999 - val_loss: 0.0129 - val_acc: 0.9966\n",
      "Epoch 88/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 3.1939e-04 - acc: 0.9999 - val_loss: 0.0108 - val_acc: 0.9971\n",
      "Epoch 89/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 3.3825e-04 - acc: 0.9999 - val_loss: 0.0108 - val_acc: 0.9973\n",
      "Epoch 90/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 3.2038e-04 - acc: 0.9999 - val_loss: 0.0127 - val_acc: 0.9968\n",
      "Epoch 91/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 3.5121e-04 - acc: 0.9999 - val_loss: 0.0107 - val_acc: 0.9973\n",
      "Epoch 92/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 3.5984e-04 - acc: 0.9999 - val_loss: 0.0163 - val_acc: 0.9960\n",
      "Epoch 93/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.2384e-04 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9975\n",
      "Epoch 94/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.8254e-04 - acc: 0.9999 - val_loss: 0.0116 - val_acc: 0.9970\n",
      "Epoch 95/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 2.8866e-04 - acc: 0.9999 - val_loss: 0.0113 - val_acc: 0.9972\n",
      "Epoch 96/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.7168e-04 - acc: 0.9999 - val_loss: 0.0103 - val_acc: 0.9975\n",
      "Epoch 97/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 2.3065e-04 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9974\n",
      "Epoch 98/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.7351e-04 - acc: 0.9999 - val_loss: 0.0128 - val_acc: 0.9970\n",
      "Epoch 99/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.2452e-04 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9973\n",
      "Epoch 100/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 1.9830e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9972\n",
      "Epoch 101/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 1.6848e-04 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9972\n",
      "Epoch 102/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.2814e-04 - acc: 0.9999 - val_loss: 0.0108 - val_acc: 0.9976\n",
      "Epoch 103/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.6037e-04 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9972\n",
      "Epoch 104/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 3.0981e-04 - acc: 0.9999 - val_loss: 0.0116 - val_acc: 0.9972\n",
      "Epoch 105/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 4.3315e-04 - acc: 0.9999 - val_loss: 0.0113 - val_acc: 0.9972\n",
      "Epoch 106/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.9218e-04 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9972\n",
      "Epoch 107/300\n",
      "167489/167489 [==============================] - 95s 567us/step - loss: 4.0784e-04 - acc: 0.9999 - val_loss: 0.0116 - val_acc: 0.9974\n",
      "Epoch 108/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 3.2315e-04 - acc: 0.9999 - val_loss: 0.0111 - val_acc: 0.9973\n",
      "Epoch 109/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 3.0234e-04 - acc: 0.9999 - val_loss: 0.0109 - val_acc: 0.9974\n",
      "Epoch 110/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.8370e-04 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9971\n",
      "Epoch 111/300\n",
      "167489/167489 [==============================] - 94s 559us/step - loss: 1.7307e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9969\n",
      "Epoch 112/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.7324e-04 - acc: 0.9999 - val_loss: 0.0111 - val_acc: 0.9973\n",
      "Epoch 113/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.4124e-04 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.6460e-04 - acc: 0.9999 - val_loss: 0.0111 - val_acc: 0.9973\n",
      "Epoch 115/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 3.7726e-04 - acc: 0.9999 - val_loss: 0.0113 - val_acc: 0.9973\n",
      "Epoch 116/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 3.3528e-04 - acc: 0.9999 - val_loss: 0.0113 - val_acc: 0.9973\n",
      "Epoch 117/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.0756e-04 - acc: 0.9999 - val_loss: 0.0119 - val_acc: 0.9972\n",
      "Epoch 118/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 6.3013e-04 - acc: 0.9998 - val_loss: 0.0150 - val_acc: 0.9964\n",
      "Epoch 119/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.9502e-04 - acc: 0.9999 - val_loss: 0.0127 - val_acc: 0.9970\n",
      "Epoch 120/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.1290e-04 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9975\n",
      "Epoch 121/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 1.2572e-04 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9975\n",
      "Epoch 122/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.9885e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9971\n",
      "Epoch 123/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.0126e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9967\n",
      "Epoch 124/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.7328e-04 - acc: 0.9999 - val_loss: 0.0123 - val_acc: 0.9971\n",
      "Epoch 125/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 1.8469e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9973\n",
      "Epoch 126/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.3216e-04 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9975\n",
      "Epoch 127/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 2.3555e-04 - acc: 0.9999 - val_loss: 0.0113 - val_acc: 0.9975\n",
      "Epoch 128/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.5262e-04 - acc: 0.9999 - val_loss: 0.0135 - val_acc: 0.9967\n",
      "Epoch 129/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3784e-04 - acc: 0.9999 - val_loss: 0.0140 - val_acc: 0.9968\n",
      "Epoch 130/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 3.2336e-04 - acc: 0.9999 - val_loss: 0.0143 - val_acc: 0.9966\n",
      "Epoch 131/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 3.3480e-04 - acc: 0.9999 - val_loss: 0.0135 - val_acc: 0.9968\n",
      "Epoch 132/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.6286e-04 - acc: 0.9999 - val_loss: 0.0150 - val_acc: 0.9965\n",
      "Epoch 133/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.5302e-04 - acc: 0.9999 - val_loss: 0.0151 - val_acc: 0.9965\n",
      "Epoch 134/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.2563e-04 - acc: 0.9999 - val_loss: 0.0120 - val_acc: 0.9973\n",
      "Epoch 135/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.5664e-04 - acc: 0.9999 - val_loss: 0.0142 - val_acc: 0.9968\n",
      "Epoch 136/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3978e-04 - acc: 0.9999 - val_loss: 0.0122 - val_acc: 0.9972\n",
      "Epoch 137/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.2440e-04 - acc: 0.9999 - val_loss: 0.0120 - val_acc: 0.9973\n",
      "Epoch 138/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.4066e-04 - acc: 0.9999 - val_loss: 0.0172 - val_acc: 0.9958\n",
      "Epoch 139/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 3.0370e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 140/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 3.1660e-04 - acc: 0.9999 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 141/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.2299e-04 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 0.9965\n",
      "Epoch 142/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.6223e-04 - acc: 0.9999 - val_loss: 0.0131 - val_acc: 0.9970\n",
      "Epoch 143/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.0740e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9968\n",
      "Epoch 144/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.3171e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9974\n",
      "Epoch 145/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.2891e-04 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 0.9958\n",
      "Epoch 146/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.1721e-04 - acc: 0.9999 - val_loss: 0.0149 - val_acc: 0.9967\n",
      "Epoch 147/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 2.5187e-04 - acc: 0.9999 - val_loss: 0.0118 - val_acc: 0.9973\n",
      "Epoch 148/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.5951e-04 - acc: 0.9999 - val_loss: 0.0138 - val_acc: 0.9968\n",
      "Epoch 149/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 1.9748e-04 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9973\n",
      "Epoch 150/300\n",
      "167489/167489 [==============================] - 94s 559us/step - loss: 2.2259e-04 - acc: 0.9999 - val_loss: 0.0126 - val_acc: 0.9972\n",
      "Epoch 151/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 4.9988e-04 - acc: 0.9999 - val_loss: 0.0121 - val_acc: 0.9973\n",
      "Epoch 152/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.5993e-04 - acc: 0.9999 - val_loss: 0.0130 - val_acc: 0.9971\n",
      "Epoch 153/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 2.0886e-04 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9969\n",
      "Epoch 154/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.6730e-04 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9972\n",
      "Epoch 155/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 1.7774e-04 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9972\n",
      "Epoch 156/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.0721e-04 - acc: 0.9999 - val_loss: 0.0191 - val_acc: 0.9956\n",
      "Epoch 157/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3881e-04 - acc: 0.9999 - val_loss: 0.0124 - val_acc: 0.9973\n",
      "Epoch 158/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.3353e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9975\n",
      "Epoch 159/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3686e-04 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9974\n",
      "Epoch 160/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 1.8800e-04 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9973\n",
      "Epoch 161/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.2435e-04 - acc: 0.9999 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 162/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 3.1464e-04 - acc: 0.9999 - val_loss: 0.0129 - val_acc: 0.9971\n",
      "Epoch 163/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.5713e-04 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9973\n",
      "Epoch 164/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.8372e-04 - acc: 0.9999 - val_loss: 0.0119 - val_acc: 0.9975\n",
      "Epoch 165/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.7839e-04 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9975\n",
      "Epoch 166/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 1.8705e-04 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9974\n",
      "Epoch 167/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.5840e-04 - acc: 0.9999 - val_loss: 0.0127 - val_acc: 0.9973\n",
      "Epoch 168/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 3.9614e-04 - acc: 0.9999 - val_loss: 0.0146 - val_acc: 0.9969\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.4820e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9970\n",
      "Epoch 170/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.0682e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9973\n",
      "Epoch 171/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.5872e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9973\n",
      "Epoch 172/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.1105e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9972\n",
      "Epoch 173/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 1.0987e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9974\n",
      "Epoch 174/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.4461e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9973\n",
      "Epoch 175/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.9460e-04 - acc: 0.9999 - val_loss: 0.0136 - val_acc: 0.9970\n",
      "Epoch 176/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.5117e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9971\n",
      "Epoch 177/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 3.3265e-04 - acc: 0.9999 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 178/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 1.6032e-04 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9971\n",
      "Epoch 179/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 2.1383e-04 - acc: 0.9999 - val_loss: 0.0132 - val_acc: 0.9969\n",
      "Epoch 180/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.3087e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9972\n",
      "Epoch 181/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.1314e-04 - acc: 0.9999 - val_loss: 0.0122 - val_acc: 0.9973\n",
      "Epoch 182/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.2801e-04 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9969\n",
      "Epoch 183/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.3015e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9974\n",
      "Epoch 184/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 1.8476e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9969\n",
      "Epoch 185/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.7158e-04 - acc: 0.9999 - val_loss: 0.0131 - val_acc: 0.9972\n",
      "Epoch 186/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 1.3465e-04 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9970\n",
      "Epoch 187/300\n",
      "167489/167489 [==============================] - 93s 556us/step - loss: 1.7386e-04 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9973\n",
      "Epoch 188/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.3018e-04 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 0.9969\n",
      "Epoch 189/300\n",
      "167489/167489 [==============================] - 94s 561us/step - loss: 2.5869e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9970\n",
      "Epoch 190/300\n",
      "167489/167489 [==============================] - 93s 555us/step - loss: 2.0911e-04 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 0.9973\n",
      "Epoch 191/300\n",
      "167489/167489 [==============================] - 93s 555us/step - loss: 1.9400e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9971\n",
      "Epoch 192/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 1.1658e-04 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9972\n",
      "Epoch 193/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 1.8377e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 194/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.0803e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9974\n",
      "Epoch 195/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.3026e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9971\n",
      "Epoch 196/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.9119e-04 - acc: 0.9999 - val_loss: 0.0126 - val_acc: 0.9972\n",
      "Epoch 197/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.0811e-04 - acc: 0.9999 - val_loss: 0.0123 - val_acc: 0.9974\n",
      "Epoch 198/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.2704e-04 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 0.9965\n",
      "Epoch 199/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 1.9853e-04 - acc: 0.9999 - val_loss: 0.0140 - val_acc: 0.9968\n",
      "Epoch 200/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.2328e-04 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9970\n",
      "Epoch 201/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.4687e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 202/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.6334e-04 - acc: 0.9999 - val_loss: 0.0133 - val_acc: 0.9970\n",
      "Epoch 203/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.1217e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9971\n",
      "Epoch 204/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.5207e-04 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9969\n",
      "Epoch 205/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 2.0321e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 0.9965\n",
      "Epoch 206/300\n",
      "167489/167489 [==============================] - 93s 555us/step - loss: 1.7840e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9970\n",
      "Epoch 207/300\n",
      "167489/167489 [==============================] - 93s 556us/step - loss: 3.4179e-04 - acc: 0.9999 - val_loss: 0.0132 - val_acc: 0.9971\n",
      "Epoch 208/300\n",
      "167489/167489 [==============================] - 93s 556us/step - loss: 2.5900e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9972\n",
      "Epoch 209/300\n",
      "167489/167489 [==============================] - 93s 557us/step - loss: 1.8494e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9973\n",
      "Epoch 210/300\n",
      "167489/167489 [==============================] - 93s 556us/step - loss: 2.8708e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9973\n",
      "Epoch 211/300\n",
      "167489/167489 [==============================] - 93s 555us/step - loss: 8.6555e-05 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9975\n",
      "Epoch 212/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 2.5167e-04 - acc: 0.9999 - val_loss: 0.0133 - val_acc: 0.9971\n",
      "Epoch 213/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.1588e-04 - acc: 0.9999 - val_loss: 0.0130 - val_acc: 0.9972\n",
      "Epoch 214/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 3.2030e-04 - acc: 0.9999 - val_loss: 0.0138 - val_acc: 0.9968\n",
      "Epoch 215/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 1.6354e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 216/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.3631e-04 - acc: 0.9999 - val_loss: 0.0125 - val_acc: 0.9972\n",
      "Epoch 217/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.7454e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9970\n",
      "Epoch 218/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 1.8444e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9973\n",
      "Epoch 219/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.4739e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9974\n",
      "Epoch 220/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3623e-04 - acc: 0.9999 - val_loss: 0.0141 - val_acc: 0.9969\n",
      "Epoch 221/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3416e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9971\n",
      "Epoch 222/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 1.7273e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9973\n",
      "Epoch 223/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.1730e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9969\n",
      "Epoch 224/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167489/167489 [==============================] - 92s 550us/step - loss: 1.4751e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9972\n",
      "Epoch 225/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 2.6194e-04 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9971\n",
      "Epoch 226/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 1.5486e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 0.9966\n",
      "Epoch 227/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.5476e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9973\n",
      "Epoch 228/300\n",
      "167489/167489 [==============================] - 94s 558us/step - loss: 1.9869e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9973\n",
      "Epoch 229/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.2279e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9973\n",
      "Epoch 230/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.1635e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9973\n",
      "Epoch 231/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 1.6336e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9974\n",
      "Epoch 232/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.3029e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9973\n",
      "Epoch 233/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 1.7283e-04 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9964\n",
      "Epoch 234/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 1.3495e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 235/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.2434e-04 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9968\n",
      "Epoch 236/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.3788e-04 - acc: 0.9999 - val_loss: 0.0131 - val_acc: 0.9972\n",
      "Epoch 237/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.4552e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9971\n",
      "Epoch 238/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.5428e-04 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9973\n",
      "Epoch 239/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.7240e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9974\n",
      "Epoch 240/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.0806e-04 - acc: 0.9999 - val_loss: 0.0131 - val_acc: 0.9972\n",
      "Epoch 241/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.1717e-04 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9969\n",
      "Epoch 242/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 1.5756e-04 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9968\n",
      "Epoch 243/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 1.5080e-04 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9973\n",
      "Epoch 244/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.4380e-04 - acc: 0.9999 - val_loss: 0.0142 - val_acc: 0.9971\n",
      "Epoch 245/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3915e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9970\n",
      "Epoch 246/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 1.6983e-04 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9973\n",
      "Epoch 247/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3445e-04 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9972\n",
      "Epoch 248/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.3640e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9973\n",
      "Epoch 249/300\n",
      "167489/167489 [==============================] - 93s 552us/step - loss: 2.0693e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9972\n",
      "Epoch 250/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.4085e-04 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9972\n",
      "Epoch 251/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 1.1356e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9972\n",
      "Epoch 252/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 1.3952e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9972\n",
      "Epoch 253/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 1.6317e-04 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9969\n",
      "Epoch 254/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.7080e-04 - acc: 0.9999 - val_loss: 0.0144 - val_acc: 0.9969\n",
      "Epoch 255/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3360e-04 - acc: 0.9999 - val_loss: 0.0150 - val_acc: 0.9967\n",
      "Epoch 256/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.5147e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9971\n",
      "Epoch 257/300\n",
      "167489/167489 [==============================] - 92s 548us/step - loss: 1.5547e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9972\n",
      "Epoch 258/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.7034e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9971\n",
      "Epoch 259/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 1.8335e-04 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9970\n",
      "Epoch 260/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3772e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9972\n",
      "Epoch 261/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.5507e-04 - acc: 0.9999 - val_loss: 0.0137 - val_acc: 0.9971\n",
      "Epoch 262/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.0433e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9973\n",
      "Epoch 263/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.0724e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9972\n",
      "Epoch 264/300\n",
      "167489/167489 [==============================] - 92s 549us/step - loss: 2.0173e-04 - acc: 0.9999 - val_loss: 0.0140 - val_acc: 0.9970\n",
      "Epoch 265/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.6624e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9971\n",
      "Epoch 266/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.6853e-04 - acc: 0.9999 - val_loss: 0.0131 - val_acc: 0.9973\n",
      "Epoch 267/300\n",
      "167489/167489 [==============================] - 93s 558us/step - loss: 1.1866e-04 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9968\n",
      "Epoch 268/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.0734e-04 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9973\n",
      "Epoch 269/300\n",
      "167489/167489 [==============================] - 93s 555us/step - loss: 2.2387e-04 - acc: 0.9999 - val_loss: 0.0140 - val_acc: 0.9970\n",
      "Epoch 270/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.0398e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 271/300\n",
      "167489/167489 [==============================] - 93s 556us/step - loss: 1.5772e-04 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9972\n",
      "Epoch 272/300\n",
      "167489/167489 [==============================] - 93s 556us/step - loss: 1.2968e-04 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9967\n",
      "Epoch 273/300\n",
      "167489/167489 [==============================] - 93s 558us/step - loss: 2.5955e-04 - acc: 0.9999 - val_loss: 0.0159 - val_acc: 0.9966\n",
      "Epoch 274/300\n",
      "167489/167489 [==============================] - 93s 555us/step - loss: 1.7721e-04 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9970\n",
      "Epoch 275/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 1.7870e-04 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 276/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 2.3127e-04 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9972\n",
      "Epoch 277/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 2.1046e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9971\n",
      "Epoch 278/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.7691e-04 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 0.9972\n",
      "Epoch 279/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.0590e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9972\n",
      "Epoch 280/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 1.8075e-04 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9971\n",
      "Epoch 281/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.3558e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9973\n",
      "Epoch 282/300\n",
      "167489/167489 [==============================] - 93s 556us/step - loss: 1.4816e-04 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 0.9973\n",
      "Epoch 283/300\n",
      "167489/167489 [==============================] - 92s 550us/step - loss: 1.7533e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9971\n",
      "Epoch 284/300\n",
      "167489/167489 [==============================] - 93s 555us/step - loss: 2.0150e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9972\n",
      "Epoch 285/300\n",
      "167489/167489 [==============================] - 93s 555us/step - loss: 1.9464e-04 - acc: 0.9999 - val_loss: 0.0135 - val_acc: 0.9972\n",
      "Epoch 286/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 1.8913e-04 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9973\n",
      "Epoch 287/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.4336e-04 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9972\n",
      "Epoch 288/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 2.0624e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9973\n",
      "Epoch 289/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 4.9119e-04 - acc: 0.9999 - val_loss: 0.0152 - val_acc: 0.9970\n",
      "Epoch 290/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.4081e-04 - acc: 0.9999 - val_loss: 0.0144 - val_acc: 0.9968\n",
      "Epoch 291/300\n",
      "167489/167489 [==============================] - 93s 557us/step - loss: 1.8905e-04 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9970\n",
      "Epoch 292/300\n",
      "167489/167489 [==============================] - 93s 557us/step - loss: 1.9633e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9972\n",
      "Epoch 293/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 1.7234e-04 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9972\n",
      "Epoch 294/300\n",
      "167489/167489 [==============================] - 93s 553us/step - loss: 1.8272e-04 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9973\n",
      "Epoch 295/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 2.1052e-04 - acc: 0.9999 - val_loss: 0.0135 - val_acc: 0.9972\n",
      "Epoch 296/300\n",
      "167489/167489 [==============================] - 92s 551us/step - loss: 1.8857e-04 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9972\n",
      "Epoch 297/300\n",
      "167489/167489 [==============================] - 92s 552us/step - loss: 1.9967e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9973\n",
      "Epoch 298/300\n",
      "167489/167489 [==============================] - 93s 554us/step - loss: 2.9557e-04 - acc: 0.9999 - val_loss: 0.0163 - val_acc: 0.9964\n",
      "Epoch 299/300\n",
      "167489/167489 [==============================] - 93s 555us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0205 - val_acc: 0.9958\n",
      "Epoch 300/300\n",
      "167489/167489 [==============================] - 93s 557us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0284 - val_acc: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd0d1ca2f98>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02843609377655515\n",
      "Test accuracy: 0.994751197042245\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
