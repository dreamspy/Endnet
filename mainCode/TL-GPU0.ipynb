{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which GPU to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiGPU = False\n",
    "whichGPU = 0\n",
    " \n",
    "# Select which GPU to use\n",
    "if(multiGPU):\n",
    "    from keras.utils.training_utils import multi_gpu_model\n",
    "else:\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    # The GPU id to use, usually either \"0\" or \"1\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(whichGPU)\n",
    "    \n",
    "# # Do other imports now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run -i 'arena.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# What data to use\n",
    "tableBase = '4PpKk'\n",
    "convertStates = False\n",
    "\n",
    "# Interactive (just in general if one is asked for confirmations, set to False if on autopilot over night f.x.)\n",
    "askForConfirmation = False\n",
    "\n",
    "# NN parameters\n",
    "filters = [16,32,32,64,128,128,128]\n",
    "filterShape = [2,2,2,2,2,2,2]\n",
    "batch_size = 256\n",
    "optimizer = 'Adadelta'\n",
    "useBatchNorm = False\n",
    "num_classes = 3\n",
    "input_shape = (4,8,8)\n",
    "\n",
    "### DON'T MODIFY BELOW ###\n",
    "# Generate dataset variables\n",
    "fileName = tableBase + '.hdf5'\n",
    "dataSetName = tableBase + '_onlyLegal'\n",
    "if not convertStates: \n",
    "    dataSetName = tableBase + '_onlyLegal_fullStates'\n",
    "dataSetWdlName = tableBase + '_Wdl_onlyLegal_3Values'\n",
    "\n",
    "# Number of Pieces\n",
    "nPi =  int(dataSetName[0])\n",
    "nPa = nPi - 2\n",
    "nWPa = math.ceil(nPa/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "Bengio methood\n",
    "3n4 no freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp 1 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = False                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 5 \n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 3n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '3n4'\n",
    "saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save file doesn't exists, creating...\n",
      "\n",
      "Save file for all runs doesn't exists, creating...\n",
      "\n",
      "Save file for this run doesn't exists, creating...\n",
      "\n",
      "7436088\n",
      "7436088\n",
      "X_train shape: (4982178, 4, 8, 8)\n",
      "y_train shape: (4982178, 1)\n",
      "X_test shape: (2453910, 4, 8, 8)\n",
      "y_test shape: (2453910, 1)\n",
      "4982178 train samples\n",
      "2453910 test samples\n",
      "Done loading dataset\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n",
      "\n",
      "Starting/restarting TL at 0 transfered layers\n"
     ]
    }
   ],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "# print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "==========================================================================================\n",
      "=                                                                                        =\n",
      "=                    Currently transfering first 0 layers, out of 8                      =\n",
      "=                                                                                        =\n",
      "==========================================================================================\n",
      "\n",
      "    ==================================================================================\n",
      "    =                                                                                =\n",
      "    =                Currently at run 1, out of 5                                   =\n",
      "    =                                                                                =\n",
      "    ==================================================================================\n",
      "\n",
      "Using first 0 layers from results Results/103/weights.hdf5, \n",
      "Loading all weights from results 103\n",
      "- 1: Resetting layer <keras.layers.convolutional.Conv2D object at 0x7f455ce62978>\n",
      "- 2: Resetting layer <keras.layers.convolutional.Conv2D object at 0x7f455ce62f28>\n",
      "- 3: Resetting layer <keras.layers.convolutional.Conv2D object at 0x7f455ce62c18>\n",
      "- 4: Resetting layer <keras.layers.convolutional.Conv2D object at 0x7f455ce2b128>\n",
      "- 5: Resetting layer <keras.layers.convolutional.Conv2D object at 0x7f455ce62828>\n",
      "- 6: Resetting layer <keras.layers.convolutional.Conv2D object at 0x7f455ce4d4a8>\n",
      "- 7: Resetting layer <keras.layers.convolutional.Conv2D object at 0x7f455cdf0898>\n",
      "- 8: Skipping layer <keras.layers.core.Flatten object at 0x7f455ce0af98>\n",
      "- 9: Resetting layer <keras.layers.core.Dense object at 0x7f455cdabe48>\n",
      "Loaded 0 first layers from 103 with freeze = False, model summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "7436088\n",
      "7436088\n",
      "X_train shape: (4982178, 4, 8, 8)\n",
      "y_train shape: (4982178, 1)\n",
      "X_test shape: (2453910, 4, 8, 8)\n",
      "y_test shape: (2453910, 1)\n",
      "4982178 train samples\n",
      "2453910 test samples\n",
      "Done loading dataset\n",
      "Save dir: Results/575/\n",
      "Creating save dir\n",
      "Done generating results dir Results/575/\n",
      "Train on 4982178 samples, validate on 2453910 samples\n",
      "Epoch 1/10\n",
      "4982178/4982178 [==============================] - 169s 34us/step - loss: 0.2756 - acc: 0.8819 - val_loss: 0.1994 - val_acc: 0.9168\n",
      "Epoch 2/10\n",
      "1646592/4982178 [========>.....................] - ETA: 1:41 - loss: 0.1804 - acc: 0.9248"
     ]
    }
   ],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "#     # start accumulated score from load file in case of starting from average run ≠ 0\n",
    "#     accumulatedScore = np.sum(resultsThisRun)\n",
    "\n",
    "    # Reset variables\n",
    "    resultsThisRun = []\n",
    "    accumulatedScore = 0\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save bengio checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "    \n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 0\n",
    "Converge 3>4 and rnd>4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "weightsSource = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "epochs = 300\n",
    "averageOver = 5\n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"converge 3to4 - {} averages - {} epochs\".format(averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dir\n",
    "saveBengioCheckPoints = True\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "compareResultsDuringTraining = False\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = True\n",
    "loadWeights = True \n",
    "loadCheckpointWeights = False\n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = 'conv3to4'\n",
    "dictFieldName = 'acc'\n",
    "saveDir = 'bengioResults'\n",
    "resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "# resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "# resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "# resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "# resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, {dictFieldName:[]})\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "# model, nnStr = createModel()\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "# resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "# resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "# startTrainingAtLayer = len(results)\n",
    "# print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "startThisRunAt = len(results[dictFieldName])\n",
    "print(\"\\nStarting/restarting TL at average {}\".format(startThisRunAt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# train and average results\n",
    "for a in range(startThisRunAt,averageOver):\n",
    "    print('    ==================================================================================')\n",
    "    print('    =                                                                                =')\n",
    "    print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "    print('    =                                                                                =')\n",
    "    print('    ==================================================================================')\n",
    "    print()\n",
    "\n",
    "    # set experement description test\n",
    "#     expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "    expDescr = expDescrBaseName + '__average_{}_of_{}'.format(a+1, averageOver)\n",
    "\n",
    "    # save current averagePosition to tmp file\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "        file.write('Inner avg loop position: {} out of {}'.format(a+1, averageOver))         \n",
    "\n",
    "    # load Model layers\n",
    "#     model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "    model, nnStr = createModel()\n",
    "\n",
    "    # load data\n",
    "    X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "    \n",
    "    # Prepare save dir\n",
    "    if saveEveryRun:\n",
    "        resID = genNextResultsDir(model)\n",
    "\n",
    "    # train\n",
    "    fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "    # calc score \n",
    "    score = calcScore(model)\n",
    "    results[dictFieldName].append(score[1])\n",
    "    if saveEveryRun:\n",
    "        saveTrainResults(resID, model, logDir, score)\n",
    "\n",
    "    # save checkpoint\n",
    "    if saveBengioCheckPoints:\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "\n",
    "        src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "\n",
    "        src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "\n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "\n",
    "\n",
    "print('\\n Final Results: {}'.format(results))\n",
    "print('\\n Final Results Averate: {}'.format(np.mean(np.array(results[dictFieldName]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "\n",
    "src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "if os.path.exists(src):\n",
    "    shutil.move(src, dest)\n",
    "\n",
    "src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "if os.path.exists(src):\n",
    "    shutil.move(src, dest)\n",
    "\n",
    "# save results \n",
    "save_obj(saveDir, resSaveFile, results)\n",
    "with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "    file.write(str(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "Bengio methood\n",
    "4n4 no freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp 2 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "# sourceNet = '103' # trained on 3pc from scratch\n",
    "sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = False                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 1\n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 4n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '4n4nofreeze'\n",
    "saveDir = 'bengioResults'\n",
    "resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "startThisRunAt = len(resultsThisRun)\n",
    "print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "    # start accumulated score from load file in case of starting from average run ≠ 0\n",
    "    accumulatedScore = np.sum(resultsThisRun)\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(startThisRunAt,averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "        \n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFile, results)\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "            file.write(str(results))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "\n",
    "    # to load:\n",
    "    # results = load_obj('temp','3n4.txt')\n",
    "    resultsThisRun = []\n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "converging 3_8_4+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 3 Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = False                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 10\n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Converging 3n4plus - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = False # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = False # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 0.001\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '3_8_4_plus_Converge'                          ############################### MODIFY\n",
    "saveDir = 'bengioResults'\n",
    "resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "startTrainingAtLayer = 7\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "startThisRunAt = len(resultsThisRun)\n",
    "print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "    # train and average results\n",
    "    accumulatedScore = np.sum(resultsThisRun)\n",
    "#     resultsThisRun = []\n",
    "    for a in range(startThisRunAt,averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        \n",
    "        # save checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "\n",
    "    # to load:\n",
    "    # results = load_obj('temp','3n4.txt')\n",
    "    resultsThisRun = []\n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsThisRun\n",
    "# save_ob('.','x',resultsThisRun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 0\n",
    "test batch size vs time vs validation valley location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 0 Paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "weightsSource = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch\n",
    "# freeze = False\n",
    "epochs = 350\n",
    "expDescrBaseName = \"Batch size test\"\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "# resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "loadCheckpointWeights = False\n",
    "askForConfirmation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "batches = [128, 1024]\n",
    "for batch_size in batches:\n",
    "    \n",
    "    expDescr = expDescrBaseName + '_batchSize{}'.format(batch_size)\n",
    "    \n",
    "    # create model\n",
    "    model, nnStr = createModel()\n",
    "\n",
    "    # Prepare save dir\n",
    "    if saveEveryRun:\n",
    "        resID = genNextResultsDir(model)\n",
    "        \n",
    "    # train\n",
    "    fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "        \n",
    "    # score and save results\n",
    "    score = calcScore(model)\n",
    "    if saveEveryRun:\n",
    "        saveTrainResults(resID, model, logDir, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
