{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which GPU to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiGPU = False\n",
    "whichGPU = 0\n",
    " \n",
    "# Select which GPU to use\n",
    "if(multiGPU):\n",
    "    from keras.utils.training_utils import multi_gpu_model\n",
    "else:\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    # The GPU id to use, usually either \"0\" or \"1\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(whichGPU)\n",
    "    \n",
    "# # Do other imports now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run -i 'arena.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# What data to use\n",
    "tableBase = '4PpKk'\n",
    "convertStates = False\n",
    "\n",
    "# Interactive (just in general if one is asked for confirmations, set to False if on autopilot over night f.x.)\n",
    "askForConfirmation = False\n",
    "\n",
    "# NN parameters\n",
    "filters = [16,32,32,64,128,128,128]\n",
    "filterShape = [2,2,2,2,2,2,2]\n",
    "batch_size = 256\n",
    "optimizer = 'Adadelta'\n",
    "useBatchNorm = False\n",
    "num_classes = 3\n",
    "input_shape = (4,8,8)\n",
    "\n",
    "### DON'T MODIFY BELOW ###\n",
    "# Generate dataset variables\n",
    "fileName = tableBase + '.hdf5'\n",
    "dataSetName = tableBase + '_onlyLegal'\n",
    "if not convertStates: \n",
    "    dataSetName = tableBase + '_onlyLegal_fullStates'\n",
    "dataSetWdlName = tableBase + '_Wdl_onlyLegal_3Values'\n",
    "\n",
    "# Number of Pieces\n",
    "nPi =  int(dataSetName[0])\n",
    "nPa = nPi - 2\n",
    "nWPa = math.ceil(nPa/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 8\n",
    "Converge rnd>4\n",
    "\n",
    "## single run only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "# weightsSource = '103' # trained on 3pc from scratch\n",
    "# weightsSource = '521' # trained on 3pc then 4pc for 150ep\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "epochs = 160\n",
    "averageOver = 5\n",
    "optimizer = 'Adam'\n",
    "\n",
    "                          ############################### MODIFY\n",
    "expDescrBase = \"converge rnd to 4 - {} epochs\".format(epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = True # save chkp in results dir\n",
    "saveBengioCheckPoints = False\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "compareResultsDuringTraining = False\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "loadCheckpointWeights = False\n",
    "askForConfirmation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________ RUN 0\n",
      "7436088\n",
      "7436088\n",
      "X_train shape: (4982178, 4, 8, 8)\n",
      "y_train shape: (4982178, 1)\n",
      "X_test shape: (2453910, 4, 8, 8)\n",
      "y_test shape: (2453910, 1)\n",
      "4982178 train samples\n",
      "2453910 test samples\n",
      "Done loading dataset\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n",
      "Save dir: Results/784/\n",
      "Creating save dir\n",
      "Done generating results dir Results/784/\n",
      "Saving weights to Results/784/weightsCheckpoints/\n",
      "Train on 4982178 samples, validate on 2453910 samples\n",
      "Epoch 1/160\n",
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.2474 - acc: 0.8941 - val_loss: 0.1702 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92840, saving model to Results/784/weightsCheckpoints/weights-checkp-001-0.928.hdf5\n",
      "Epoch 2/160\n",
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.1524 - acc: 0.9370 - val_loss: 0.1353 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92840 to 0.94479, saving model to Results/784/weightsCheckpoints/weights-checkp-002-0.945.hdf5\n",
      "Epoch 3/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.1270 - acc: 0.9483 - val_loss: 0.1240 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94479 to 0.94966, saving model to Results/784/weightsCheckpoints/weights-checkp-003-0.950.hdf5\n",
      "Epoch 4/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.1128 - acc: 0.9544 - val_loss: 0.1101 - val_acc: 0.9554\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94966 to 0.95543, saving model to Results/784/weightsCheckpoints/weights-checkp-004-0.955.hdf5\n",
      "Epoch 5/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.1040 - acc: 0.9583 - val_loss: 0.1074 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.95543 to 0.95720, saving model to Results/784/weightsCheckpoints/weights-checkp-005-0.957.hdf5\n",
      "Epoch 6/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0977 - acc: 0.9611 - val_loss: 0.1036 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95720 to 0.95876, saving model to Results/784/weightsCheckpoints/weights-checkp-006-0.959.hdf5\n",
      "Epoch 7/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0929 - acc: 0.9631 - val_loss: 0.0972 - val_acc: 0.9615\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95876 to 0.96155, saving model to Results/784/weightsCheckpoints/weights-checkp-007-0.962.hdf5\n",
      "Epoch 8/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0892 - acc: 0.9646 - val_loss: 0.0915 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.96155 to 0.96397, saving model to Results/784/weightsCheckpoints/weights-checkp-008-0.964.hdf5\n",
      "Epoch 9/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0861 - acc: 0.9659 - val_loss: 0.0889 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.96397 to 0.96475, saving model to Results/784/weightsCheckpoints/weights-checkp-009-0.965.hdf5\n",
      "Epoch 10/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0836 - acc: 0.9670 - val_loss: 0.0869 - val_acc: 0.9660\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.96475 to 0.96597, saving model to Results/784/weightsCheckpoints/weights-checkp-010-0.966.hdf5\n",
      "Epoch 11/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0813 - acc: 0.9680 - val_loss: 0.0883 - val_acc: 0.9653\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.96597\n",
      "Epoch 12/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0792 - acc: 0.9689 - val_loss: 0.0841 - val_acc: 0.9670\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.96597 to 0.96700, saving model to Results/784/weightsCheckpoints/weights-checkp-012-0.967.hdf5\n",
      "Epoch 13/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0775 - acc: 0.9696 - val_loss: 0.0830 - val_acc: 0.9678\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.96700 to 0.96783, saving model to Results/784/weightsCheckpoints/weights-checkp-013-0.968.hdf5\n",
      "Epoch 14/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0760 - acc: 0.9702 - val_loss: 0.0829 - val_acc: 0.9674\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.96783\n",
      "Epoch 15/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0743 - acc: 0.9710 - val_loss: 0.0806 - val_acc: 0.9687\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.96783 to 0.96875, saving model to Results/784/weightsCheckpoints/weights-checkp-015-0.969.hdf5\n",
      "Epoch 16/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0731 - acc: 0.9714 - val_loss: 0.0792 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.96875 to 0.96914, saving model to Results/784/weightsCheckpoints/weights-checkp-016-0.969.hdf5\n",
      "Epoch 17/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0720 - acc: 0.9720 - val_loss: 0.0813 - val_acc: 0.9683\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.96914\n",
      "Epoch 18/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0709 - acc: 0.9723 - val_loss: 0.0771 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.96914 to 0.97030, saving model to Results/784/weightsCheckpoints/weights-checkp-018-0.970.hdf5\n",
      "Epoch 19/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0698 - acc: 0.9728 - val_loss: 0.0794 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.97030\n",
      "Epoch 20/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0690 - acc: 0.9732 - val_loss: 0.0767 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.97030 to 0.97050, saving model to Results/784/weightsCheckpoints/weights-checkp-020-0.970.hdf5\n",
      "Epoch 21/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0681 - acc: 0.9735 - val_loss: 0.0724 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.97050 to 0.97238, saving model to Results/784/weightsCheckpoints/weights-checkp-021-0.972.hdf5\n",
      "Epoch 22/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0672 - acc: 0.9740 - val_loss: 0.0740 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.97238\n",
      "Epoch 23/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0664 - acc: 0.9744 - val_loss: 0.0732 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97238\n",
      "Epoch 24/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0655 - acc: 0.9746 - val_loss: 0.0719 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.97238 to 0.97253, saving model to Results/784/weightsCheckpoints/weights-checkp-024-0.973.hdf5\n",
      "Epoch 25/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0649 - acc: 0.9749 - val_loss: 0.0754 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.97253\n",
      "Epoch 26/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0642 - acc: 0.9752 - val_loss: 0.0816 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97253\n",
      "Epoch 27/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0636 - acc: 0.9755 - val_loss: 0.0752 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.97253\n",
      "Epoch 28/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0631 - acc: 0.9757 - val_loss: 0.0715 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.97253 to 0.97300, saving model to Results/784/weightsCheckpoints/weights-checkp-028-0.973.hdf5\n",
      "Epoch 29/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0625 - acc: 0.9759 - val_loss: 0.0695 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.97300 to 0.97361, saving model to Results/784/weightsCheckpoints/weights-checkp-029-0.974.hdf5\n",
      "Epoch 30/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0618 - acc: 0.9762 - val_loss: 0.0717 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97361\n",
      "Epoch 31/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0615 - acc: 0.9763 - val_loss: 0.0695 - val_acc: 0.9735\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97361\n",
      "Epoch 32/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0608 - acc: 0.9766 - val_loss: 0.0704 - val_acc: 0.9735\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97361\n",
      "Epoch 33/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0604 - acc: 0.9768 - val_loss: 0.0730 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.97361\n",
      "Epoch 34/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0600 - acc: 0.9770 - val_loss: 0.0674 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.97361 to 0.97437, saving model to Results/784/weightsCheckpoints/weights-checkp-034-0.974.hdf5\n",
      "Epoch 35/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0595 - acc: 0.9772 - val_loss: 0.0685 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.97437\n",
      "Epoch 36/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0591 - acc: 0.9773 - val_loss: 0.0658 - val_acc: 0.9753\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.97437 to 0.97529, saving model to Results/784/weightsCheckpoints/weights-checkp-036-0.975.hdf5\n",
      "Epoch 37/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0588 - acc: 0.9775 - val_loss: 0.0652 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.97529 to 0.97552, saving model to Results/784/weightsCheckpoints/weights-checkp-037-0.976.hdf5\n",
      "Epoch 38/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0582 - acc: 0.9777 - val_loss: 0.0672 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.97552\n",
      "Epoch 39/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0577 - acc: 0.9779 - val_loss: 0.0705 - val_acc: 0.9739\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.97552\n",
      "Epoch 40/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0574 - acc: 0.9781 - val_loss: 0.0677 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.97552\n",
      "Epoch 41/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0569 - acc: 0.9783 - val_loss: 0.0666 - val_acc: 0.9751\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.97552\n",
      "Epoch 42/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0566 - acc: 0.9785 - val_loss: 0.0653 - val_acc: 0.9754\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.97552\n",
      "Epoch 43/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0564 - acc: 0.9784 - val_loss: 0.0644 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.97552 to 0.97605, saving model to Results/784/weightsCheckpoints/weights-checkp-043-0.976.hdf5\n",
      "Epoch 44/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0559 - acc: 0.9787 - val_loss: 0.0649 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.97605\n",
      "Epoch 45/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0557 - acc: 0.9787 - val_loss: 0.0660 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.97605\n",
      "Epoch 46/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0553 - acc: 0.9790 - val_loss: 0.0653 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.97605\n",
      "Epoch 47/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0548 - acc: 0.9792 - val_loss: 0.0634 - val_acc: 0.9763\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.97605 to 0.97631, saving model to Results/784/weightsCheckpoints/weights-checkp-047-0.976.hdf5\n",
      "Epoch 48/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0547 - acc: 0.9792 - val_loss: 0.0619 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.97631 to 0.97686, saving model to Results/784/weightsCheckpoints/weights-checkp-048-0.977.hdf5\n",
      "Epoch 49/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0543 - acc: 0.9794 - val_loss: 0.0672 - val_acc: 0.9751\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.97686\n",
      "Epoch 50/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0541 - acc: 0.9795 - val_loss: 0.0643 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.97686\n",
      "Epoch 51/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0537 - acc: 0.9796 - val_loss: 0.0666 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.97686\n",
      "Epoch 52/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0533 - acc: 0.9798 - val_loss: 0.0632 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.97686\n",
      "Epoch 53/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0530 - acc: 0.9799 - val_loss: 0.0623 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.97686\n",
      "Epoch 54/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0530 - acc: 0.9800 - val_loss: 0.0612 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.97686 to 0.97730, saving model to Results/784/weightsCheckpoints/weights-checkp-054-0.977.hdf5\n",
      "Epoch 55/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0528 - acc: 0.9800 - val_loss: 0.0615 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.97730 to 0.97737, saving model to Results/784/weightsCheckpoints/weights-checkp-055-0.977.hdf5\n",
      "Epoch 56/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0523 - acc: 0.9802 - val_loss: 0.0617 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.97737\n",
      "Epoch 57/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0520 - acc: 0.9803 - val_loss: 0.0660 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.97737\n",
      "Epoch 58/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0518 - acc: 0.9805 - val_loss: 0.0602 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.97737 to 0.97742, saving model to Results/784/weightsCheckpoints/weights-checkp-058-0.977.hdf5\n",
      "Epoch 59/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0514 - acc: 0.9806 - val_loss: 0.0565 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.97742 to 0.97908, saving model to Results/784/weightsCheckpoints/weights-checkp-059-0.979.hdf5\n",
      "Epoch 60/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0514 - acc: 0.9806 - val_loss: 0.0593 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.97908\n",
      "Epoch 61/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0511 - acc: 0.9808 - val_loss: 0.0627 - val_acc: 0.9771\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.97908\n",
      "Epoch 62/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0508 - acc: 0.9809 - val_loss: 0.0593 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.97908\n",
      "Epoch 63/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0505 - acc: 0.9810 - val_loss: 0.0578 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.97908\n",
      "Epoch 64/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0503 - acc: 0.9810 - val_loss: 0.0601 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.97908\n",
      "Epoch 65/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0500 - acc: 0.9812 - val_loss: 0.0577 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.97908\n",
      "Epoch 66/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0497 - acc: 0.9813 - val_loss: 0.0588 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.97908\n",
      "Epoch 67/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0497 - acc: 0.9813 - val_loss: 0.0612 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.97908\n",
      "Epoch 68/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0495 - acc: 0.9814 - val_loss: 0.0602 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.97908\n",
      "Epoch 69/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0491 - acc: 0.9815 - val_loss: 0.0565 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.97908 to 0.97929, saving model to Results/784/weightsCheckpoints/weights-checkp-069-0.979.hdf5\n",
      "Epoch 70/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0490 - acc: 0.9816 - val_loss: 0.0557 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.97929 to 0.97959, saving model to Results/784/weightsCheckpoints/weights-checkp-070-0.980.hdf5\n",
      "Epoch 71/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0488 - acc: 0.9817 - val_loss: 0.0560 - val_acc: 0.9795\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.97959\n",
      "Epoch 72/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0487 - acc: 0.9818 - val_loss: 0.0611 - val_acc: 0.9775\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.97959\n",
      "Epoch 73/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0482 - acc: 0.9819 - val_loss: 0.0576 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.97959\n",
      "Epoch 74/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0482 - acc: 0.9819 - val_loss: 0.0567 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.97959\n",
      "Epoch 75/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0480 - acc: 0.9820 - val_loss: 0.0569 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.97959\n",
      "Epoch 76/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0478 - acc: 0.9821 - val_loss: 0.0596 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.97959\n",
      "Epoch 77/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0477 - acc: 0.9822 - val_loss: 0.0589 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.97959\n",
      "Epoch 78/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0473 - acc: 0.9823 - val_loss: 0.0567 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.97959\n",
      "Epoch 79/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0471 - acc: 0.9824 - val_loss: 0.0605 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.97959\n",
      "Epoch 80/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0470 - acc: 0.9824 - val_loss: 0.0593 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.97959\n",
      "Epoch 81/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0468 - acc: 0.9826 - val_loss: 0.0569 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.97959 to 0.97960, saving model to Results/784/weightsCheckpoints/weights-checkp-081-0.980.hdf5\n",
      "Epoch 82/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0472 - acc: 0.9824 - val_loss: 0.0570 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.97960\n",
      "Epoch 83/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0467 - acc: 0.9826 - val_loss: 0.0574 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.97960\n",
      "Epoch 84/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0465 - acc: 0.9827 - val_loss: 0.0549 - val_acc: 0.9801\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.97960 to 0.98008, saving model to Results/784/weightsCheckpoints/weights-checkp-084-0.980.hdf5\n",
      "Epoch 85/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0464 - acc: 0.9827 - val_loss: 0.0594 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.98008\n",
      "Epoch 86/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0463 - acc: 0.9828 - val_loss: 0.0551 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.98008 to 0.98017, saving model to Results/784/weightsCheckpoints/weights-checkp-086-0.980.hdf5\n",
      "Epoch 87/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0461 - acc: 0.9828 - val_loss: 0.0544 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.98017 to 0.98037, saving model to Results/784/weightsCheckpoints/weights-checkp-087-0.980.hdf5\n",
      "Epoch 88/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0458 - acc: 0.9830 - val_loss: 0.0584 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.98037\n",
      "Epoch 89/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0458 - acc: 0.9829 - val_loss: 0.0527 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.98037 to 0.98100, saving model to Results/784/weightsCheckpoints/weights-checkp-089-0.981.hdf5\n",
      "Epoch 90/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0454 - acc: 0.9832 - val_loss: 0.0527 - val_acc: 0.9810\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.98100 to 0.98104, saving model to Results/784/weightsCheckpoints/weights-checkp-090-0.981.hdf5\n",
      "Epoch 91/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0453 - acc: 0.9831 - val_loss: 0.0596 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.98104\n",
      "Epoch 92/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0452 - acc: 0.9832 - val_loss: 0.0568 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.98104\n",
      "Epoch 93/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0452 - acc: 0.9833 - val_loss: 0.0544 - val_acc: 0.9804\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.98104\n",
      "Epoch 94/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0449 - acc: 0.9833 - val_loss: 0.0558 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.98104\n",
      "Epoch 95/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0448 - acc: 0.9834 - val_loss: 0.0518 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.98104 to 0.98120, saving model to Results/784/weightsCheckpoints/weights-checkp-095-0.981.hdf5\n",
      "Epoch 96/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0447 - acc: 0.9835 - val_loss: 0.0560 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.98120\n",
      "Epoch 97/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0446 - acc: 0.9835 - val_loss: 0.0583 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.98120\n",
      "Epoch 98/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0446 - acc: 0.9835 - val_loss: 0.0554 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.98120\n",
      "Epoch 99/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0443 - acc: 0.9836 - val_loss: 0.0535 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.98120\n",
      "Epoch 100/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0442 - acc: 0.9836 - val_loss: 0.0526 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.98120 to 0.98130, saving model to Results/784/weightsCheckpoints/weights-checkp-100-0.981.hdf5\n",
      "Epoch 101/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0440 - acc: 0.9837 - val_loss: 0.0555 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.98130\n",
      "Epoch 102/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0438 - acc: 0.9838 - val_loss: 0.0530 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.98130\n",
      "Epoch 103/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0438 - acc: 0.9838 - val_loss: 0.0547 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.98130\n",
      "Epoch 104/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0442 - acc: 0.9836 - val_loss: 0.0514 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.98130 to 0.98132, saving model to Results/784/weightsCheckpoints/weights-checkp-104-0.981.hdf5\n",
      "Epoch 105/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0436 - acc: 0.9839 - val_loss: 0.0516 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.98132\n",
      "Epoch 106/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0436 - acc: 0.9840 - val_loss: 0.0517 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.98132 to 0.98143, saving model to Results/784/weightsCheckpoints/weights-checkp-106-0.981.hdf5\n",
      "Epoch 107/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0438 - acc: 0.9838 - val_loss: 0.0560 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.98143\n",
      "Epoch 108/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0432 - acc: 0.9841 - val_loss: 0.0507 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.98143 to 0.98189, saving model to Results/784/weightsCheckpoints/weights-checkp-108-0.982.hdf5\n",
      "Epoch 109/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0436 - acc: 0.9840 - val_loss: 0.0514 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.98189\n",
      "Epoch 110/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0434 - acc: 0.9841 - val_loss: 0.0535 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.98189\n",
      "Epoch 111/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0437 - acc: 0.9839 - val_loss: 0.0505 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.98189\n",
      "Epoch 112/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0434 - acc: 0.9840 - val_loss: 0.0544 - val_acc: 0.9807\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.98189\n",
      "Epoch 113/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0433 - acc: 0.9840 - val_loss: 0.0537 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.98189\n",
      "Epoch 114/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0434 - acc: 0.9840 - val_loss: 0.0511 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.98189\n",
      "Epoch 115/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0427 - acc: 0.9843 - val_loss: 0.0502 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.98189\n",
      "Epoch 116/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0429 - acc: 0.9842 - val_loss: 0.0511 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.98189\n",
      "Epoch 117/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0427 - acc: 0.9843 - val_loss: 0.0536 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.98189\n",
      "Epoch 118/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0427 - acc: 0.9843 - val_loss: 0.0557 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.98189\n",
      "Epoch 119/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0424 - acc: 0.9845 - val_loss: 0.0522 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.98189\n",
      "Epoch 120/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0424 - acc: 0.9845 - val_loss: 0.0503 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00120: val_acc improved from 0.98189 to 0.98218, saving model to Results/784/weightsCheckpoints/weights-checkp-120-0.982.hdf5\n",
      "Epoch 121/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0423 - acc: 0.9845 - val_loss: 0.0490 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.98218 to 0.98246, saving model to Results/784/weightsCheckpoints/weights-checkp-121-0.982.hdf5\n",
      "Epoch 122/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0422 - acc: 0.9845 - val_loss: 0.0495 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.98246\n",
      "Epoch 123/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0420 - acc: 0.9846 - val_loss: 0.0489 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.98246 to 0.98273, saving model to Results/784/weightsCheckpoints/weights-checkp-123-0.983.hdf5\n",
      "Epoch 124/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0418 - acc: 0.9847 - val_loss: 0.0543 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.98273\n",
      "Epoch 125/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0422 - acc: 0.9846 - val_loss: 0.0531 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.98273\n",
      "Epoch 126/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0419 - acc: 0.9846 - val_loss: 0.0500 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.98273\n",
      "Epoch 127/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0428 - acc: 0.9844 - val_loss: 0.0492 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.98273\n",
      "Epoch 128/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0422 - acc: 0.9845 - val_loss: 0.0496 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.98273\n",
      "Epoch 129/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0421 - acc: 0.9846 - val_loss: 0.0535 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.98273\n",
      "Epoch 130/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0421 - acc: 0.9846 - val_loss: 0.0513 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.98273\n",
      "Epoch 131/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0417 - acc: 0.9847 - val_loss: 0.0528 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.98273\n",
      "Epoch 132/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0415 - acc: 0.9848 - val_loss: 0.0588 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.98273\n",
      "Epoch 133/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0415 - acc: 0.9849 - val_loss: 0.0512 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.98273\n",
      "Epoch 134/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0416 - acc: 0.9847 - val_loss: 0.0524 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.98273\n",
      "Epoch 135/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0414 - acc: 0.9848 - val_loss: 0.0497 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.98273\n",
      "Epoch 136/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0411 - acc: 0.9850 - val_loss: 0.0510 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.98273\n",
      "Epoch 137/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0412 - acc: 0.9850 - val_loss: 0.0515 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.98273\n",
      "Epoch 138/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0410 - acc: 0.9850 - val_loss: 0.0535 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.98273\n",
      "Epoch 139/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0409 - acc: 0.9851 - val_loss: 0.0498 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.98273\n",
      "Epoch 140/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0406 - acc: 0.9852 - val_loss: 0.0507 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.98273\n",
      "Epoch 141/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0408 - acc: 0.9851 - val_loss: 0.0495 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.98273\n",
      "Epoch 142/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0406 - acc: 0.9852 - val_loss: 0.0493 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.98273\n",
      "Epoch 143/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0406 - acc: 0.9852 - val_loss: 0.0583 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.98273\n",
      "Epoch 144/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0406 - acc: 0.9852 - val_loss: 0.0528 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.98273\n",
      "Epoch 145/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0402 - acc: 0.9854 - val_loss: 0.0518 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.98273\n",
      "Epoch 146/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0404 - acc: 0.9853 - val_loss: 0.0506 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.98273\n",
      "Epoch 147/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0401 - acc: 0.9854 - val_loss: 0.0508 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.98273\n",
      "Epoch 148/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0402 - acc: 0.9853 - val_loss: 0.0506 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.98273\n",
      "Epoch 149/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0402 - acc: 0.9853 - val_loss: 0.0521 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.98273\n",
      "Epoch 150/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0399 - acc: 0.9855 - val_loss: 0.0462 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.98273 to 0.98342, saving model to Results/784/weightsCheckpoints/weights-checkp-150-0.983.hdf5\n",
      "Epoch 151/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0399 - acc: 0.9856 - val_loss: 0.0533 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.98342\n",
      "Epoch 152/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0402 - acc: 0.9855 - val_loss: 0.0490 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.98342\n",
      "Epoch 153/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0399 - acc: 0.9855 - val_loss: 0.0509 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.98342\n",
      "Epoch 154/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0398 - acc: 0.9855 - val_loss: 0.0538 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.98342\n",
      "Epoch 155/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0397 - acc: 0.9856 - val_loss: 0.0528 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.98342\n",
      "Epoch 156/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0398 - acc: 0.9856 - val_loss: 0.0470 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.98342\n",
      "Epoch 157/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0395 - acc: 0.9857 - val_loss: 0.0511 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.98342\n",
      "Epoch 158/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0397 - acc: 0.9856 - val_loss: 0.0534 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.98342\n",
      "Epoch 159/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0394 - acc: 0.9857 - val_loss: 0.0487 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.98342\n",
      "Epoch 160/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0393 - acc: 0.9857 - val_loss: 0.0520 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.98342\n",
      "Training done\n",
      "Calculating score\n",
      "2453910/2453910 [==============================] - 118s 48us/step\n",
      "(4982178, 4, 8, 8)\n",
      "Evaluated test loss: 0.051954803742672126\n",
      "Evaluated test accuracy: 0.9821554172728422\n",
      "Saving results to dir 784\n",
      "Saving history...\n",
      "Saving weights...\n",
      "Saving figures...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving summary...\n",
      "Saving tensorboard logs...\n",
      "All done saving stuff!\n",
      "__________________________________________________ RUN 1\n",
      "7436088\n",
      "7436088\n",
      "X_train shape: (4982178, 4, 8, 8)\n",
      "y_train shape: (4982178, 1)\n",
      "X_test shape: (2453910, 4, 8, 8)\n",
      "y_test shape: (2453910, 1)\n",
      "4982178 train samples\n",
      "2453910 test samples\n",
      "Done loading dataset\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n",
      "Save dir: Results/785/\n",
      "Creating save dir\n",
      "Done generating results dir Results/785/\n",
      "Saving weights to Results/785/weightsCheckpoints/\n",
      "Train on 4982178 samples, validate on 2453910 samples\n",
      "Epoch 1/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.2467 - acc: 0.8938 - val_loss: 0.1767 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92494, saving model to Results/785/weightsCheckpoints/weights-checkp-001-0.925.hdf5\n",
      "Epoch 2/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.1551 - acc: 0.9348 - val_loss: 0.1400 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92494 to 0.94142, saving model to Results/785/weightsCheckpoints/weights-checkp-002-0.941.hdf5\n",
      "Epoch 3/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.1296 - acc: 0.9466 - val_loss: 0.1241 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.94142 to 0.94953, saving model to Results/785/weightsCheckpoints/weights-checkp-003-0.950.hdf5\n",
      "Epoch 4/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.1148 - acc: 0.9532 - val_loss: 0.1102 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94953 to 0.95500, saving model to Results/785/weightsCheckpoints/weights-checkp-004-0.955.hdf5\n",
      "Epoch 5/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.1049 - acc: 0.9577 - val_loss: 0.1019 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.95500 to 0.95885, saving model to Results/785/weightsCheckpoints/weights-checkp-005-0.959.hdf5\n",
      "Epoch 6/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0974 - acc: 0.9609 - val_loss: 0.1030 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95885 to 0.95892, saving model to Results/785/weightsCheckpoints/weights-checkp-006-0.959.hdf5\n",
      "Epoch 7/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0917 - acc: 0.9634 - val_loss: 0.0930 - val_acc: 0.9632\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95892 to 0.96315, saving model to Results/785/weightsCheckpoints/weights-checkp-007-0.963.hdf5\n",
      "Epoch 8/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0872 - acc: 0.9655 - val_loss: 0.0919 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.96315 to 0.96367, saving model to Results/785/weightsCheckpoints/weights-checkp-008-0.964.hdf5\n",
      "Epoch 9/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0837 - acc: 0.9669 - val_loss: 0.0844 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.96367 to 0.96677, saving model to Results/785/weightsCheckpoints/weights-checkp-009-0.967.hdf5\n",
      "Epoch 10/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0805 - acc: 0.9683 - val_loss: 0.0847 - val_acc: 0.9669\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.96677 to 0.96693, saving model to Results/785/weightsCheckpoints/weights-checkp-010-0.967.hdf5\n",
      "Epoch 11/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0781 - acc: 0.9694 - val_loss: 0.0823 - val_acc: 0.9677\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.96693 to 0.96766, saving model to Results/785/weightsCheckpoints/weights-checkp-011-0.968.hdf5\n",
      "Epoch 12/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0758 - acc: 0.9703 - val_loss: 0.0807 - val_acc: 0.9687\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.96766 to 0.96873, saving model to Results/785/weightsCheckpoints/weights-checkp-012-0.969.hdf5\n",
      "Epoch 13/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0743 - acc: 0.9710 - val_loss: 0.0796 - val_acc: 0.9691\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.96873 to 0.96905, saving model to Results/785/weightsCheckpoints/weights-checkp-013-0.969.hdf5\n",
      "Epoch 14/160\n",
      "4982178/4982178 [==============================] - 159s 32us/step - loss: 0.0724 - acc: 0.9717 - val_loss: 0.0781 - val_acc: 0.9695\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.96905 to 0.96953, saving model to Results/785/weightsCheckpoints/weights-checkp-014-0.970.hdf5\n",
      "Epoch 15/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0710 - acc: 0.9723 - val_loss: 0.0811 - val_acc: 0.9687\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.96953\n",
      "Epoch 16/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0696 - acc: 0.9729 - val_loss: 0.0755 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.96953 to 0.97065, saving model to Results/785/weightsCheckpoints/weights-checkp-016-0.971.hdf5\n",
      "Epoch 17/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0685 - acc: 0.9735 - val_loss: 0.0793 - val_acc: 0.9699\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.97065\n",
      "Epoch 18/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0672 - acc: 0.9740 - val_loss: 0.0739 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.97065 to 0.97161, saving model to Results/785/weightsCheckpoints/weights-checkp-018-0.972.hdf5\n",
      "Epoch 19/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0661 - acc: 0.9745 - val_loss: 0.0701 - val_acc: 0.9731\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.97161 to 0.97308, saving model to Results/785/weightsCheckpoints/weights-checkp-019-0.973.hdf5\n",
      "Epoch 20/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0651 - acc: 0.9749 - val_loss: 0.0704 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97308\n",
      "Epoch 21/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0642 - acc: 0.9752 - val_loss: 0.0717 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.97308\n",
      "Epoch 22/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0630 - acc: 0.9757 - val_loss: 0.0694 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.97308 to 0.97360, saving model to Results/785/weightsCheckpoints/weights-checkp-022-0.974.hdf5\n",
      "Epoch 23/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0622 - acc: 0.9761 - val_loss: 0.0713 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97360\n",
      "Epoch 24/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0615 - acc: 0.9763 - val_loss: 0.0675 - val_acc: 0.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_acc improved from 0.97360 to 0.97440, saving model to Results/785/weightsCheckpoints/weights-checkp-024-0.974.hdf5\n",
      "Epoch 25/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0607 - acc: 0.9768 - val_loss: 0.0683 - val_acc: 0.9743\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.97440\n",
      "Epoch 26/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0601 - acc: 0.9770 - val_loss: 0.0673 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.97440 to 0.97470, saving model to Results/785/weightsCheckpoints/weights-checkp-026-0.975.hdf5\n",
      "Epoch 27/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0594 - acc: 0.9773 - val_loss: 0.0641 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.97470 to 0.97600, saving model to Results/785/weightsCheckpoints/weights-checkp-027-0.976.hdf5\n",
      "Epoch 28/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0587 - acc: 0.9775 - val_loss: 0.0659 - val_acc: 0.9749\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97600\n",
      "Epoch 29/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0580 - acc: 0.9778 - val_loss: 0.0692 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97600\n",
      "Epoch 30/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0577 - acc: 0.9780 - val_loss: 0.0646 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97600\n",
      "Epoch 31/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0571 - acc: 0.9782 - val_loss: 0.0632 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.97600 to 0.97644, saving model to Results/785/weightsCheckpoints/weights-checkp-031-0.976.hdf5\n",
      "Epoch 32/160\n",
      "4982178/4982178 [==============================] - 158s 32us/step - loss: 0.0564 - acc: 0.9784 - val_loss: 0.0625 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97644\n",
      "Epoch 33/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0559 - acc: 0.9788 - val_loss: 0.0669 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.97644\n",
      "Epoch 34/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0555 - acc: 0.9789 - val_loss: 0.0617 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.97644 to 0.97701, saving model to Results/785/weightsCheckpoints/weights-checkp-034-0.977.hdf5\n",
      "Epoch 35/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0550 - acc: 0.9792 - val_loss: 0.0618 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.97701\n",
      "Epoch 36/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0546 - acc: 0.9792 - val_loss: 0.0601 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.97701 to 0.97744, saving model to Results/785/weightsCheckpoints/weights-checkp-036-0.977.hdf5\n",
      "Epoch 37/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0543 - acc: 0.9794 - val_loss: 0.0637 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.97744\n",
      "Epoch 38/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0537 - acc: 0.9796 - val_loss: 0.0617 - val_acc: 0.9771\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.97744\n",
      "Epoch 39/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0533 - acc: 0.9798 - val_loss: 0.0623 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.97744\n",
      "Epoch 40/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0528 - acc: 0.9799 - val_loss: 0.0618 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.97744\n",
      "Epoch 41/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0526 - acc: 0.9801 - val_loss: 0.0600 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.97744 to 0.97787, saving model to Results/785/weightsCheckpoints/weights-checkp-041-0.978.hdf5\n",
      "Epoch 42/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0523 - acc: 0.9802 - val_loss: 0.0605 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.97787\n",
      "Epoch 43/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0522 - acc: 0.9803 - val_loss: 0.0598 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.97787\n",
      "Epoch 44/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0514 - acc: 0.9806 - val_loss: 0.0592 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.97787 to 0.97808, saving model to Results/785/weightsCheckpoints/weights-checkp-044-0.978.hdf5\n",
      "Epoch 45/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0512 - acc: 0.9806 - val_loss: 0.0597 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.97808\n",
      "Epoch 46/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0509 - acc: 0.9808 - val_loss: 0.0588 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.97808 to 0.97812, saving model to Results/785/weightsCheckpoints/weights-checkp-046-0.978.hdf5\n",
      "Epoch 47/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0507 - acc: 0.9809 - val_loss: 0.0603 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.97812\n",
      "Epoch 48/160\n",
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0504 - acc: 0.9811 - val_loss: 0.0582 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.97812 to 0.97847, saving model to Results/785/weightsCheckpoints/weights-checkp-048-0.978.hdf5\n",
      "Epoch 49/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0501 - acc: 0.9812 - val_loss: 0.0585 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.97847\n",
      "Epoch 50/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0497 - acc: 0.9813 - val_loss: 0.0565 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.97847 to 0.97929, saving model to Results/785/weightsCheckpoints/weights-checkp-050-0.979.hdf5\n",
      "Epoch 51/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0494 - acc: 0.9814 - val_loss: 0.0601 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.97929\n",
      "Epoch 52/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0492 - acc: 0.9815 - val_loss: 0.0602 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.97929\n",
      "Epoch 53/160\n",
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0491 - acc: 0.9816 - val_loss: 0.0564 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.97929\n",
      "Epoch 54/160\n",
      "2261760/4982178 [============>.................] - ETA: 1:15 - loss: 0.0481 - acc: 0.9820"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0481 - acc: 0.9820 - val_loss: 0.0564 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.97929 to 0.97932, saving model to Results/785/weightsCheckpoints/weights-checkp-057-0.979.hdf5\n",
      "Epoch 58/160\n",
      " 459776/4982178 [=>............................] - ETA: 2:06 - loss: 0.0458 - acc: 0.9828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2583040/4982178 [==============>...............] - ETA: 1:06 - loss: 0.0466 - acc: 0.9826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0472 - acc: 0.9825 - val_loss: 0.0592 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.98026\n",
      "Epoch 63/160\n",
      " 738304/4982178 [===>..........................] - ETA: 1:58 - loss: 0.0451 - acc: 0.9832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2917120/4982178 [================>.............] - ETA: 57s - loss: 0.0461 - acc: 0.9828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0461 - acc: 0.9828 - val_loss: 0.0554 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.98026\n",
      "Epoch 68/160\n",
      "1069824/4982178 [=====>........................] - ETA: 1:48 - loss: 0.0445 - acc: 0.9835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3168768/4982178 [==================>...........] - ETA: 50s - loss: 0.0454 - acc: 0.9831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0455 - acc: 0.9831 - val_loss: 0.0579 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.98075\n",
      "Epoch 73/160\n",
      "1327872/4982178 [======>.......................] - ETA: 1:41 - loss: 0.0433 - acc: 0.9839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3305984/4982178 [==================>...........] - ETA: 46s - loss: 0.0445 - acc: 0.9835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0446 - acc: 0.9835 - val_loss: 0.0532 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.98142\n",
      "Epoch 78/160\n",
      "1495296/4982178 [========>.....................] - ETA: 1:36 - loss: 0.0434 - acc: 0.9839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3121920/4982178 [=================>............] - ETA: 51s - loss: 0.0437 - acc: 0.9839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0438 - acc: 0.9837 - val_loss: 0.0495 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.98142 to 0.98213, saving model to Results/785/weightsCheckpoints/weights-checkp-082-0.982.hdf5\n",
      "Epoch 83/160\n",
      "1048320/4982178 [=====>........................] - ETA: 1:49 - loss: 0.0421 - acc: 0.9845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2694656/4982178 [===============>..............] - ETA: 1:02 - loss: 0.0428 - acc: 0.9842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0433 - acc: 0.9841 - val_loss: 0.0518 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.98213\n",
      "Epoch 88/160\n",
      "1081600/4982178 [=====>........................] - ETA: 1:48 - loss: 0.0416 - acc: 0.9847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2838272/4982178 [================>.............] - ETA: 59s - loss: 0.0422 - acc: 0.9844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0427 - acc: 0.9843 - val_loss: 0.0593 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.98213\n",
      "Epoch 93/160\n",
      " 868864/4982178 [====>.........................] - ETA: 1:54 - loss: 0.0406 - acc: 0.9850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693376/4982178 [===============>..............] - ETA: 1:03 - loss: 0.0419 - acc: 0.9846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0418 - acc: 0.9846 - val_loss: 0.0527 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.98213\n",
      "Epoch 98/160\n",
      "1063936/4982178 [=====>........................] - ETA: 1:48 - loss: 0.0407 - acc: 0.9851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2682112/4982178 [===============>..............] - ETA: 1:03 - loss: 0.0413 - acc: 0.9848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4576768/4982178 [==========================>...] - ETA: 11s - loss: 0.0414 - acc: 0.9848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0411 - acc: 0.9849 - val_loss: 0.0516 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.98222\n",
      "Epoch 103/160\n",
      " 591872/4982178 [==>...........................] - ETA: 2:03 - loss: 0.0386 - acc: 0.9857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0410 - acc: 0.9850 - val_loss: 0.0507 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.98222\n",
      "Epoch 106/160\n",
      "4076800/4982178 [=======================>......] - ETA: 24s - loss: 0.0409 - acc: 0.9850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0409 - acc: 0.9850 - val_loss: 0.0506 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.98250\n",
      "Epoch 108/160\n",
      " 443392/4982178 [=>............................] - ETA: 2:06 - loss: 0.0382 - acc: 0.9860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0409 - acc: 0.9850 - val_loss: 0.0501 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.98250\n",
      "Epoch 111/160\n",
      "4481280/4982178 [=========================>....] - ETA: 13s - loss: 0.0407 - acc: 0.9851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0405 - acc: 0.9852 - val_loss: 0.0530 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.98265\n",
      "Epoch 113/160\n",
      " 698368/4982178 [===>..........................] - ETA: 1:59 - loss: 0.0387 - acc: 0.9857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0404 - acc: 0.9853 - val_loss: 0.0496 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.98265 to 0.98267, saving model to Results/785/weightsCheckpoints/weights-checkp-115-0.983.hdf5\n",
      "Epoch 116/160\n",
      "4455168/4982178 [=========================>....] - ETA: 14s - loss: 0.0401 - acc: 0.9853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0402 - acc: 0.9853 - val_loss: 0.0512 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.98316\n",
      "Epoch 118/160\n",
      " 727552/4982178 [===>..........................] - ETA: 1:58 - loss: 0.0382 - acc: 0.9861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0401 - acc: 0.9853 - val_loss: 0.0514 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.98316\n",
      "Epoch 121/160\n",
      "4479488/4982178 [=========================>....] - ETA: 13s - loss: 0.0396 - acc: 0.9856"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0399 - acc: 0.9856 - val_loss: 0.0493 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.98316\n",
      "Epoch 123/160\n",
      " 963072/4982178 [====>.........................] - ETA: 1:51 - loss: 0.0383 - acc: 0.9861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0399 - acc: 0.9855 - val_loss: 0.0542 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.98316\n",
      "Epoch 126/160\n",
      "4275200/4982178 [========================>.....] - ETA: 19s - loss: 0.0396 - acc: 0.9857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0394 - acc: 0.9856 - val_loss: 0.0510 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.98316\n",
      "Epoch 128/160\n",
      " 541184/4982178 [==>...........................] - ETA: 2:04 - loss: 0.0376 - acc: 0.9862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0393 - acc: 0.9857 - val_loss: 0.0505 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.98338\n",
      "Epoch 131/160\n",
      "4380672/4982178 [=========================>....] - ETA: 16s - loss: 0.0397 - acc: 0.9857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0392 - acc: 0.9858 - val_loss: 0.0480 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.98338\n",
      "Epoch 133/160\n",
      " 570368/4982178 [==>...........................] - ETA: 2:03 - loss: 0.0369 - acc: 0.9865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0394 - acc: 0.9857 - val_loss: 0.0490 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.98338\n",
      "Epoch 136/160\n",
      "3485184/4982178 [===================>..........] - ETA: 41s - loss: 0.0388 - acc: 0.9860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4842496/4982178 [============================>.] - ETA: 3s - loss: 0.0391 - acc: 0.9858"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0389 - acc: 0.9859 - val_loss: 0.0509 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.98338\n",
      "Epoch 141/160\n",
      "3634176/4982178 [====================>.........] - ETA: 37s - loss: 0.0385 - acc: 0.9860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4704256/4982178 [===========================>..] - ETA: 7s - loss: 0.0386 - acc: 0.9860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0388 - acc: 0.9859 - val_loss: 0.0490 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.98363\n",
      "Epoch 146/160\n",
      "3394816/4982178 [===================>..........] - ETA: 43s - loss: 0.0383 - acc: 0.9862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4804864/4982178 [===========================>..] - ETA: 4s - loss: 0.0385 - acc: 0.9861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0384 - acc: 0.9861 - val_loss: 0.0468 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.98363 to 0.98368, saving model to Results/785/weightsCheckpoints/weights-checkp-150-0.984.hdf5\n",
      "Epoch 151/160\n",
      "3634176/4982178 [====================>.........] - ETA: 37s - loss: 0.0382 - acc: 0.9862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0383 - acc: 0.9861 - val_loss: 0.0505 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.98368\n",
      "Epoch 153/160\n",
      " 199168/4982178 [>.............................] - ETA: 2:16 - loss: 0.0346 - acc: 0.9875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0382 - acc: 0.9862 - val_loss: 0.0499 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.98388\n",
      "Epoch 156/160\n",
      "3627520/4982178 [====================>.........] - ETA: 37s - loss: 0.0379 - acc: 0.9864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 155s 31us/step - loss: 0.0383 - acc: 0.9862 - val_loss: 0.0474 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.98388\n",
      "Epoch 158/160\n",
      " 102656/4982178 [..............................] - ETA: 2:22 - loss: 0.0335 - acc: 0.9877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 156s 31us/step - loss: 0.0381 - acc: 0.9862 - val_loss: 0.0486 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.98388\n",
      "Training done\n",
      "Calculating score\n",
      "1958112/2453910 [======================>.......] - ETA: 24s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.2511 - acc: 0.8924 - val_loss: 0.1773 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92492, saving model to Results/787/weightsCheckpoints/weights-checkp-001-0.925.hdf5\n",
      "Epoch 2/160\n",
      " 826112/4982178 [===>..........................] - ETA: 1:56 - loss: 0.1715 - acc: 0.9282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.1089 - acc: 0.9558 - val_loss: 0.1090 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95140 to 0.95568, saving model to Results/787/weightsCheckpoints/weights-checkp-004-0.956.hdf5\n",
      "Epoch 5/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0978 - acc: 0.9605 - val_loss: 0.0996 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.95568 to 0.96021, saving model to Results/787/weightsCheckpoints/weights-checkp-005-0.960.hdf5\n",
      "Epoch 6/160\n",
      " 545280/4982178 [==>...........................] - ETA: 2:04 - loss: 0.0897 - acc: 0.9643"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0762 - acc: 0.9698 - val_loss: 0.0804 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.96713 to 0.96818, saving model to Results/787/weightsCheckpoints/weights-checkp-009-0.968.hdf5\n",
      "Epoch 10/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0731 - acc: 0.9711 - val_loss: 0.0741 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.96818 to 0.97072, saving model to Results/787/weightsCheckpoints/weights-checkp-010-0.971.hdf5\n",
      "Epoch 11/160\n",
      " 695296/4982178 [===>..........................] - ETA: 1:59 - loss: 0.0686 - acc: 0.9729"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_acc improved from 0.97244 to 0.97370, saving model to Results/787/weightsCheckpoints/weights-checkp-014-0.974.hdf5\n",
      "Epoch 15/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0626 - acc: 0.9755 - val_loss: 0.0697 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.97370\n",
      "Epoch 16/160\n",
      " 823552/4982178 [===>..........................] - ETA: 1:55 - loss: 0.0599 - acc: 0.9765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0579 - acc: 0.9776 - val_loss: 0.0617 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.97574 to 0.97635, saving model to Results/787/weightsCheckpoints/weights-checkp-019-0.976.hdf5\n",
      "Epoch 20/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0570 - acc: 0.9779 - val_loss: 0.0633 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97635\n",
      "Epoch 21/160\n",
      " 396288/4982178 [=>............................] - ETA: 2:10 - loss: 0.0540 - acc: 0.9790"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0539 - acc: 0.9792 - val_loss: 0.0600 - val_acc: 0.9772\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.97635 to 0.97716, saving model to Results/787/weightsCheckpoints/weights-checkp-024-0.977.hdf5\n",
      "Epoch 25/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0531 - acc: 0.9795 - val_loss: 0.0594 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.97716 to 0.97762, saving model to Results/787/weightsCheckpoints/weights-checkp-025-0.978.hdf5\n",
      "Epoch 26/160\n",
      "  38656/4982178 [..............................] - ETA: 2:42 - loss: 0.0468 - acc: 0.9823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0507 - acc: 0.9806 - val_loss: 0.0572 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.97834 to 0.97841, saving model to Results/787/weightsCheckpoints/weights-checkp-029-0.978.hdf5\n",
      "Epoch 30/160\n",
      "4575744/4982178 [==========================>...] - ETA: 11s - loss: 0.0503 - acc: 0.9807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0485 - acc: 0.9814 - val_loss: 0.0560 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.97894 to 0.97897, saving model to Results/787/weightsCheckpoints/weights-checkp-034-0.979.hdf5\n",
      "Epoch 35/160\n",
      "4083456/4982178 [=======================>......] - ETA: 24s - loss: 0.0479 - acc: 0.9817"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0469 - acc: 0.9821 - val_loss: 0.0543 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.97985\n",
      "Epoch 40/160\n",
      "3697408/4982178 [=====================>........] - ETA: 35s - loss: 0.0462 - acc: 0.9824"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0453 - acc: 0.9828 - val_loss: 0.0515 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.98062 to 0.98076, saving model to Results/787/weightsCheckpoints/weights-checkp-044-0.981.hdf5\n",
      "Epoch 45/160\n",
      "2729216/4982178 [===============>..............] - ETA: 1:02 - loss: 0.0443 - acc: 0.9832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0440 - acc: 0.9834 - val_loss: 0.0509 - val_acc: 0.9812\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.98123\n",
      "Epoch 50/160\n",
      "2389504/4982178 [=============>................] - ETA: 1:11 - loss: 0.0429 - acc: 0.9838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0430 - acc: 0.9838 - val_loss: 0.0533 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.98157\n",
      "Epoch 55/160\n",
      "2222080/4982178 [============>.................] - ETA: 1:16 - loss: 0.0418 - acc: 0.9843"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0420 - acc: 0.9843 - val_loss: 0.0531 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.98193\n",
      "Epoch 60/160\n",
      "1701888/4982178 [=========>....................] - ETA: 1:31 - loss: 0.0406 - acc: 0.9847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 152s 30us/step - loss: 0.0413 - acc: 0.9845 - val_loss: 0.0519 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.98193\n",
      "Epoch 65/160\n",
      "3402240/4982178 [===================>..........] - ETA: 41s - loss: 0.0405 - acc: 0.9849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 150s 30us/step - loss: 0.0409 - acc: 0.9847 - val_loss: 0.0526 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.98193\n",
      "Epoch 66/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0408 - acc: 0.9848 - val_loss: 0.0513 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.98193\n",
      "Epoch 67/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0409 - acc: 0.9846 - val_loss: 0.0495 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.98193\n",
      "Epoch 68/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0405 - acc: 0.9848 - val_loss: 0.0485 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.98193 to 0.98241, saving model to Results/787/weightsCheckpoints/weights-checkp-068-0.982.hdf5\n",
      "Epoch 69/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0405 - acc: 0.9849 - val_loss: 0.0554 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.98241\n",
      "Epoch 70/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0405 - acc: 0.9849 - val_loss: 0.0490 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.98241\n",
      "Epoch 71/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0402 - acc: 0.9850 - val_loss: 0.0478 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.98241\n",
      "Epoch 72/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0402 - acc: 0.9850 - val_loss: 0.0489 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.98241\n",
      "Epoch 73/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0399 - acc: 0.9851 - val_loss: 0.0486 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.98241 to 0.98254, saving model to Results/787/weightsCheckpoints/weights-checkp-073-0.983.hdf5\n",
      "Epoch 74/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0396 - acc: 0.9852 - val_loss: 0.0481 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.98254 to 0.98272, saving model to Results/787/weightsCheckpoints/weights-checkp-074-0.983.hdf5\n",
      "Epoch 75/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0397 - acc: 0.9852 - val_loss: 0.0490 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.98272\n",
      "Epoch 76/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0395 - acc: 0.9853 - val_loss: 0.0479 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.98272\n",
      "Epoch 77/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0394 - acc: 0.9854 - val_loss: 0.0454 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.98272 to 0.98341, saving model to Results/787/weightsCheckpoints/weights-checkp-077-0.983.hdf5\n",
      "Epoch 78/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0393 - acc: 0.9853 - val_loss: 0.0465 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.98341\n",
      "Epoch 79/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0392 - acc: 0.9854 - val_loss: 0.0465 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.98341\n",
      "Epoch 80/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0390 - acc: 0.9854 - val_loss: 0.0461 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.98341\n",
      "Epoch 81/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0389 - acc: 0.9856 - val_loss: 0.0494 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.98341\n",
      "Epoch 82/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0386 - acc: 0.9856 - val_loss: 0.0474 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.98341\n",
      "Epoch 83/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0388 - acc: 0.9856 - val_loss: 0.0481 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.98341\n",
      "Epoch 84/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0388 - acc: 0.9856 - val_loss: 0.0489 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.98341\n",
      "Epoch 85/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0384 - acc: 0.9857 - val_loss: 0.0468 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.98341\n",
      "Epoch 86/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0387 - acc: 0.9856 - val_loss: 0.0484 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.98341\n",
      "Epoch 87/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0385 - acc: 0.9857 - val_loss: 0.0486 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.98341\n",
      "Epoch 88/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0382 - acc: 0.9858 - val_loss: 0.0479 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.98341\n",
      "Epoch 89/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0382 - acc: 0.9858 - val_loss: 0.0454 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.98341 to 0.98349, saving model to Results/787/weightsCheckpoints/weights-checkp-089-0.983.hdf5\n",
      "Epoch 90/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0381 - acc: 0.9859 - val_loss: 0.0476 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.98349\n",
      "Epoch 91/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0381 - acc: 0.9859 - val_loss: 0.0489 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.98349\n",
      "Epoch 92/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0379 - acc: 0.9859 - val_loss: 0.0428 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.98349 to 0.98462, saving model to Results/787/weightsCheckpoints/weights-checkp-092-0.985.hdf5\n",
      "Epoch 93/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0379 - acc: 0.9860 - val_loss: 0.0470 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.98462\n",
      "Epoch 94/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0378 - acc: 0.9861 - val_loss: 0.0463 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.98462\n",
      "Epoch 95/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0376 - acc: 0.9861 - val_loss: 0.0483 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.98462\n",
      "Epoch 96/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0376 - acc: 0.9861 - val_loss: 0.0490 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.98462\n",
      "Epoch 97/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0376 - acc: 0.9861 - val_loss: 0.0454 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.98462\n",
      "Epoch 98/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0374 - acc: 0.9863 - val_loss: 0.0463 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.98462\n",
      "Epoch 99/160\n",
      "4982178/4982178 [==============================] - 157s 31us/step - loss: 0.0371 - acc: 0.9863 - val_loss: 0.0454 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.98462\n",
      "Epoch 100/160\n",
      "4982178/4982178 [==============================] - 157s 32us/step - loss: 0.0374 - acc: 0.9862 - val_loss: 0.0475 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.98462\n",
      "Epoch 101/160\n",
      "4849152/4982178 [============================>.] - ETA: 3s - loss: 0.0371 - acc: 0.9864"
     ]
    }
   ],
   "source": [
    "# stuff to save in bengioResults dir\n",
    "# resSaveFile = 'conv3to4-startingAt300epochs'\n",
    "# dictFieldName = 'acc'\n",
    "# saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "# resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "\n",
    "# prepare save file\n",
    "# if os.path.exists(resSaveFileFullPath):\n",
    "#     print(\"Save file exists..., aborting\\n\")\n",
    "#     sys.exit()\n",
    "    \n",
    "for i in range(averageOver):\n",
    "    print(\"__________________________________________________ RUN {}\".format(i))\n",
    "    expDescr = expDescrBase + ' - run {} of {}'.format(i,averageOver)\n",
    "    # load data\n",
    "    X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "    # create model\n",
    "    model, nnStr = createModel()\n",
    "\n",
    "    # create results dir\n",
    "    resID = genNextResultsDir(model)\n",
    "\n",
    "    # train\n",
    "    fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "    # calc score \n",
    "    score = calcScore(model)\n",
    "    if saveEveryRun:\n",
    "        saveTrainResults(resID, model, logDir, score)\n",
    "\n",
    "    # save results \n",
    "#     save_obj(saveDir, resSaveFile, [score[1]])\n",
    "#     with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "#         file.write(str([score[1]]))\n",
    "\n",
    "#     print('\\n Final Results: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 0\n",
    "Converge 3>4 and rnd>4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "# weightsSource = '103' # trained on 3pc from scratch\n",
    "weightsSource = '521' # trained on 3pc then 4pc for 150ep\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "epochs = 10\n",
    "averageOver = 1\n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"converge 3to4 - {} averages - {} epochs\".format(averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dir\n",
    "saveBengioCheckPoints = True\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "compareResultsDuringTraining = False\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 0.0001\n",
    "plotDuringTraining = True\n",
    "loadWeights = True \n",
    "loadCheckpointWeights = False\n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = 'conv3to4-startingAt300epochs'\n",
    "dictFieldName = 'acc'\n",
    "saveDir = 'bengioResults'\n",
    "resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "# resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "# resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "# resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "# resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, {dictFieldName:[]})\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "# model, nnStr = createModel()\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "# resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "# resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "# startTrainingAtLayer = len(results)\n",
    "# print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "startThisRunAt = len(results[dictFieldName])\n",
    "print(\"\\nStarting/restarting TL at average {}\".format(startThisRunAt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# train and average results\n",
    "for a in range(startThisRunAt,averageOver):\n",
    "    print('    ==================================================================================')\n",
    "    print('    =                                                                                =')\n",
    "    print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "    print('    =                                                                                =')\n",
    "    print('    ==================================================================================')\n",
    "    print()\n",
    "\n",
    "    # set experement description test\n",
    "#     expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "    expDescr = expDescrBaseName + '__average_{}_of_{}'.format(a+1, averageOver)\n",
    "\n",
    "    # save current averagePosition to tmp file\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "        file.write('Inner avg loop position: {} out of {}'.format(a+1, averageOver))         \n",
    "\n",
    "    # load Model layers\n",
    "#     model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "    model, nnStr = createModel()\n",
    "\n",
    "    # load data\n",
    "    X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "    \n",
    "    # Prepare save dir\n",
    "    if saveEveryRun:\n",
    "        resID = genNextResultsDir(model)\n",
    "\n",
    "    # train\n",
    "    fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "    # calc score \n",
    "    score = calcScore(model)\n",
    "    results[dictFieldName].append(score[1])\n",
    "    if saveEveryRun:\n",
    "        saveTrainResults(resID, model, logDir, score)\n",
    "\n",
    "    # save checkpoint\n",
    "    if saveBengioCheckPoints:\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "\n",
    "        src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "\n",
    "        src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "\n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "\n",
    "\n",
    "print('\\n Final Results: {}'.format(results))\n",
    "print('\\n Final Results Averate: {}'.format(np.mean(np.array(results[dictFieldName]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "\n",
    "src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "if os.path.exists(src):\n",
    "    shutil.move(src, dest)\n",
    "\n",
    "src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "if os.path.exists(src):\n",
    "    shutil.move(src, dest)\n",
    "\n",
    "# save results \n",
    "save_obj(saveDir, resSaveFile, results)\n",
    "with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "    file.write(str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4\n",
    "Bengio methood\n",
    "4n4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "# sourceNet = '103' # trained on 3pc from scratch\n",
    "sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = True                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 5 \n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 4n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False #only used in createModel function, the loadFirstNLayers always loads weights! \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '4n4'\n",
    "saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "# print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "#     # start accumulated score from load file in case of starting from average run  0\n",
    "#     accumulatedScore = np.sum(resultsThisRun)\n",
    "\n",
    "    # Reset variables\n",
    "    resultsThisRun = []\n",
    "    accumulatedScore = 0\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save bengio checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "    \n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5\n",
    "Bengio methood\n",
    "4n4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp  parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "# sourceNet = '103' # trained on 3pc from scratch\n",
    "sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = True                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 5 \n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 4n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '4n4p'\n",
    "saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "# print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "#     # start accumulated score from load file in case of starting from average run  0\n",
    "#     accumulatedScore = np.sum(resultsThisRun)\n",
    "\n",
    "    # Reset variables\n",
    "    resultsThisRun = []\n",
    "    accumulatedScore = 0\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save bengio checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "    \n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "Bengio methood\n",
    "3n4+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp 1 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = False                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 5 \n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 3n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '3n4'\n",
    "saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "# print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "#     # start accumulated score from load file in case of starting from average run  0\n",
    "#     accumulatedScore = np.sum(resultsThisRun)\n",
    "\n",
    "    # Reset variables\n",
    "    resultsThisRun = []\n",
    "    accumulatedScore = 0\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save bengio checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "    \n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "Bengio methood\n",
    "3n4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp  parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = True                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 5 \n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 3n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '3n4p'\n",
    "saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "# print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "#     # start accumulated score from load file in case of starting from average run  0\n",
    "#     accumulatedScore = np.sum(resultsThisRun)\n",
    "\n",
    "    # Reset variables\n",
    "    resultsThisRun = []\n",
    "    accumulatedScore = 0\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save bengio checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "    \n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "converging 3_8_4+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 3 Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = False                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 10\n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Converging 3n4plus - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = False # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = False # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 0.001\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '3_8_4_plus_Converge'                          ############################### MODIFY\n",
    "saveDir = 'bengioResults'\n",
    "resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "startTrainingAtLayer = 7\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "startThisRunAt = len(resultsThisRun)\n",
    "print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "    # train and average results\n",
    "    accumulatedScore = np.sum(resultsThisRun)\n",
    "#     resultsThisRun = []\n",
    "    for a in range(startThisRunAt,averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        \n",
    "        # save checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "\n",
    "    # to load:\n",
    "    # results = load_obj('temp','3n4.txt')\n",
    "    resultsThisRun = []\n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsThisRun\n",
    "# save_ob('.','x',resultsThisRun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 0\n",
    "test batch size vs time vs validation valley location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 0 Paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "weightsSource = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch\n",
    "# freeze = False\n",
    "epochs = 350\n",
    "expDescrBaseName = \"Batch size test\"\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "# resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "loadCheckpointWeights = False\n",
    "askForConfirmation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "batches = [128, 1024]\n",
    "for batch_size in batches:\n",
    "    \n",
    "    expDescr = expDescrBaseName + '_batchSize{}'.format(batch_size)\n",
    "    \n",
    "    # create model\n",
    "    model, nnStr = createModel()\n",
    "\n",
    "    # Prepare save dir\n",
    "    if saveEveryRun:\n",
    "        resID = genNextResultsDir(model)\n",
    "        \n",
    "    # train\n",
    "    fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "        \n",
    "    # score and save results\n",
    "    score = calcScore(model)\n",
    "    if saveEveryRun:\n",
    "        saveTrainResults(resID, model, logDir, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
