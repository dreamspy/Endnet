{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which GPU to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiGPU = False\n",
    "whichGPU = 1\n",
    " \n",
    "# Select which GPU to use\n",
    "if(multiGPU):\n",
    "    from keras.utils.training_utils import multi_gpu_model\n",
    "else:\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    # The GPU id to use, usually either \"0\" or \"1\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(whichGPU)\n",
    "    \n",
    "# # Do other imports now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# What data to use\n",
    "tableBase = '4PpKk'\n",
    "convertStates = False\n",
    "\n",
    "# Interactive (just in general if one is asked for confirmations, set to False if on autopilot over night f.x.)\n",
    "askForConfirmation = False\n",
    "\n",
    "# NN parameters\n",
    "filters = [16,32,32,64,128,128,128]\n",
    "filterShape = [2,2,2,2,2,2,2]\n",
    "batch_size = 256\n",
    "optimizer = 'Adam'\n",
    "useBatchNorm = False\n",
    "num_classes = 3\n",
    "input_shape = (4,8,8)\n",
    "\n",
    "### DON'T MODIFY BELOW ###\n",
    "# Generate dataset variables\n",
    "fileName = tableBase + '.hdf5'\n",
    "dataSetName = tableBase + '_onlyLegal'\n",
    "if not convertStates: \n",
    "    dataSetName = tableBase + '_onlyLegal_fullStates'\n",
    "dataSetWdlName = tableBase + '_Wdl_onlyLegal_3Values'\n",
    "\n",
    "# Number of Pieces\n",
    "nPi =  int(dataSetName[0])\n",
    "nPa = nPi - 2\n",
    "nWPa = math.ceil(nPa/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 8\n",
    "Converge 3>4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "# weightsSource = '103' # trained on 3pc from scratch\n",
    "# weightsSource = '521' # trained on 3pc then 4pc for 150ep\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "epochs = 160\n",
    "averageOver = 5\n",
    "optimizer = 'Adadelta'\n",
    "\n",
    "                          ############################### MODIFY\n",
    "expDescrBase = \"converge 3 to 4 {} epochs\".format(epochs, optimizer)\n",
    "\n",
    "calcIndvWDLvalues = True\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = True # save chkp in results dir\n",
    "saveBengioCheckPoints = False\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "compareResultsDuringTraining = False\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse =1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "loadCheckpointWeights = False\n",
    "askForConfirmation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________ RUN 0\n",
      "163328\n",
      "163328\n",
      "X_train shape: (109429, 4, 8, 8)\n",
      "y_train shape: (109429, 1)\n",
      "X_test shape: (53899, 4, 8, 8)\n",
      "y_test shape: (53899, 1)\n",
      "109429 train samples\n",
      "53899 test samples\n",
      "Done loading dataset\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n",
      "Save dir: Results/852/\n",
      "Creating save dir\n",
      "Done generating results dir Results/852/\n",
      "Saving weights to Results/852/weightsCheckpoints/\n",
      "Train on 109429 samples, validate on 53899 samples\n",
      "Epoch 1/160\n",
      "109429/109429 [==============================] - 4s 38us/step - loss: 0.4267 - acc: 0.8097 - val_loss: 0.2120 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90584, saving model to Results/852/weightsCheckpoints/weights-checkp-001-0.906.hdf5\n",
      "Epoch 2/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.1594 - acc: 0.9301 - val_loss: 0.1623 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90584 to 0.93317, saving model to Results/852/weightsCheckpoints/weights-checkp-002-0.933.hdf5\n",
      "Epoch 3/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0983 - acc: 0.9591 - val_loss: 0.1008 - val_acc: 0.9585\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93317 to 0.95848, saving model to Results/852/weightsCheckpoints/weights-checkp-003-0.958.hdf5\n",
      "Epoch 4/160\n",
      "109429/109429 [==============================] - 4s 37us/step - loss: 0.0769 - acc: 0.9674 - val_loss: 0.0825 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95848 to 0.96618, saving model to Results/852/weightsCheckpoints/weights-checkp-004-0.966.hdf5\n",
      "Epoch 5/160\n",
      "109429/109429 [==============================] - 4s 37us/step - loss: 0.0661 - acc: 0.9721 - val_loss: 0.0708 - val_acc: 0.9701\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.96618 to 0.97013, saving model to Results/852/weightsCheckpoints/weights-checkp-005-0.970.hdf5\n",
      "Epoch 6/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0582 - acc: 0.9760 - val_loss: 0.0626 - val_acc: 0.9736\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.97013 to 0.97362, saving model to Results/852/weightsCheckpoints/weights-checkp-006-0.974.hdf5\n",
      "Epoch 7/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0531 - acc: 0.9780 - val_loss: 0.0966 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97362\n",
      "Epoch 8/160\n",
      "109429/109429 [==============================] - 4s 37us/step - loss: 0.0483 - acc: 0.9802 - val_loss: 0.0973 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.97362\n",
      "Epoch 9/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0437 - acc: 0.9821 - val_loss: 0.0744 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97362\n",
      "Epoch 10/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0397 - acc: 0.9839 - val_loss: 0.0457 - val_acc: 0.9809\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.97362 to 0.98091, saving model to Results/852/weightsCheckpoints/weights-checkp-010-0.981.hdf5\n",
      "Epoch 11/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0362 - acc: 0.9851 - val_loss: 0.0508 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.98091\n",
      "Epoch 12/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0342 - acc: 0.9862 - val_loss: 0.0493 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98091\n",
      "Epoch 13/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0312 - acc: 0.9876 - val_loss: 0.0536 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98091\n",
      "Epoch 14/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0295 - acc: 0.9884 - val_loss: 0.0361 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.98091 to 0.98625, saving model to Results/852/weightsCheckpoints/weights-checkp-014-0.986.hdf5\n",
      "Epoch 15/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0277 - acc: 0.9893 - val_loss: 0.0468 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.98625\n",
      "Epoch 16/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0253 - acc: 0.9901 - val_loss: 0.0404 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98625\n",
      "Epoch 17/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0239 - acc: 0.9908 - val_loss: 0.0364 - val_acc: 0.9858\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98625\n",
      "Epoch 18/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0222 - acc: 0.9914 - val_loss: 0.0345 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.98625 to 0.98681, saving model to Results/852/weightsCheckpoints/weights-checkp-018-0.987.hdf5\n",
      "Epoch 19/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0200 - acc: 0.9926 - val_loss: 0.0359 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.98681\n",
      "Epoch 20/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0198 - acc: 0.9926 - val_loss: 0.0318 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.98681 to 0.98811, saving model to Results/852/weightsCheckpoints/weights-checkp-020-0.988.hdf5\n",
      "Epoch 21/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0181 - acc: 0.9933 - val_loss: 0.0330 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.98811\n",
      "Epoch 22/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0171 - acc: 0.9937 - val_loss: 0.0305 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.98811\n",
      "Epoch 23/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0167 - acc: 0.9940 - val_loss: 0.0308 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.98811 to 0.98924, saving model to Results/852/weightsCheckpoints/weights-checkp-023-0.989.hdf5\n",
      "Epoch 24/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0153 - acc: 0.9943 - val_loss: 0.0317 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.98924\n",
      "Epoch 25/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0140 - acc: 0.9951 - val_loss: 0.0375 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.98924\n",
      "Epoch 26/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0138 - acc: 0.9951 - val_loss: 0.0442 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.98924\n",
      "Epoch 27/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0121 - acc: 0.9957 - val_loss: 0.0265 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.98924 to 0.99072, saving model to Results/852/weightsCheckpoints/weights-checkp-027-0.991.hdf5\n",
      "Epoch 28/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0117 - acc: 0.9958 - val_loss: 0.0280 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99072\n",
      "Epoch 29/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0118 - acc: 0.9958 - val_loss: 0.0273 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99072\n",
      "Epoch 30/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0104 - acc: 0.9963 - val_loss: 0.0415 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99072\n",
      "Epoch 31/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.0279 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.99072 to 0.99080, saving model to Results/852/weightsCheckpoints/weights-checkp-031-0.991.hdf5\n",
      "Epoch 32/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0408 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99080\n",
      "Epoch 33/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0320 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99080\n",
      "Epoch 34/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0277 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.99080 to 0.99206, saving model to Results/852/weightsCheckpoints/weights-checkp-034-0.992.hdf5\n",
      "Epoch 35/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0309 - val_acc: 0.9911\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99206\n",
      "Epoch 36/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0259 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.99206 to 0.99230, saving model to Results/852/weightsCheckpoints/weights-checkp-036-0.992.hdf5\n",
      "Epoch 37/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0080 - acc: 0.9973 - val_loss: 0.0341 - val_acc: 0.9901\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.99230\n",
      "Epoch 38/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0263 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.99230\n",
      "Epoch 39/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.0259 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.99230\n",
      "Epoch 40/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0555 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.99230\n",
      "Epoch 41/160\n",
      "109429/109429 [==============================] - 4s 37us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0268 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.99230\n",
      "Epoch 42/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0254 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.99230 to 0.99254, saving model to Results/852/weightsCheckpoints/weights-checkp-042-0.993.hdf5\n",
      "Epoch 43/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0378 - val_acc: 0.9901\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.99254\n",
      "Epoch 44/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0275 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.99254 to 0.99304, saving model to Results/852/weightsCheckpoints/weights-checkp-044-0.993.hdf5\n",
      "Epoch 45/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0239 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.99304\n",
      "Epoch 46/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0305 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.99304\n",
      "Epoch 47/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0496 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.99304\n",
      "Epoch 48/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0266 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.99304 to 0.99323, saving model to Results/852/weightsCheckpoints/weights-checkp-048-0.993.hdf5\n",
      "Epoch 49/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0320 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.99323\n",
      "Epoch 50/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0270 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.99323\n",
      "Epoch 51/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0254 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.99323 to 0.99338, saving model to Results/852/weightsCheckpoints/weights-checkp-051-0.993.hdf5\n",
      "Epoch 52/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0309 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.99338\n",
      "Epoch 53/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0261 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.99338\n",
      "Epoch 54/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0788 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.99338\n",
      "Epoch 55/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0336 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.99338\n",
      "Epoch 56/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0266 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.99338 to 0.99345, saving model to Results/852/weightsCheckpoints/weights-checkp-056-0.993.hdf5\n",
      "Epoch 57/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0338 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.99345\n",
      "Epoch 58/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0270 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.99345\n",
      "Epoch 59/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0257 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.99345\n",
      "Epoch 60/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0235 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.99345 to 0.99365, saving model to Results/852/weightsCheckpoints/weights-checkp-060-0.994.hdf5\n",
      "Epoch 61/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0380 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.99365\n",
      "Epoch 62/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0233 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.99365 to 0.99443, saving model to Results/852/weightsCheckpoints/weights-checkp-062-0.994.hdf5\n",
      "Epoch 63/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0343 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.99443\n",
      "Epoch 64/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0299 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.99443\n",
      "Epoch 65/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0367 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.99443\n",
      "Epoch 66/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0351 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.99443\n",
      "Epoch 67/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0236 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.99443\n",
      "Epoch 68/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0310 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.99443\n",
      "Epoch 69/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0319 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.99443\n",
      "Epoch 70/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0389 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.99443\n",
      "Epoch 71/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0296 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.99443\n",
      "Epoch 72/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0254 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.99443\n",
      "Epoch 73/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0360 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.99443\n",
      "Epoch 74/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0386 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.99443\n",
      "Epoch 75/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0340 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.99443\n",
      "Epoch 76/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0568 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.99443\n",
      "Epoch 77/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.0386 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.99443\n",
      "Epoch 78/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0289 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.99443\n",
      "Epoch 79/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0295 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.99443\n",
      "Epoch 80/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0279 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.99443\n",
      "Epoch 81/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0366 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.99443\n",
      "Epoch 82/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0312 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.99443\n",
      "Epoch 83/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0259 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.99443 to 0.99445, saving model to Results/852/weightsCheckpoints/weights-checkp-083-0.994.hdf5\n",
      "Epoch 84/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0310 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.99445\n",
      "Epoch 85/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0414 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.99445\n",
      "Epoch 86/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0459 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.99445\n",
      "Epoch 87/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0343 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.99445\n",
      "Epoch 88/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0473 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.99445\n",
      "Epoch 89/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0505 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.99445\n",
      "Epoch 90/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0295 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.99445\n",
      "Epoch 91/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0292 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.99445\n",
      "Epoch 92/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0431 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.99445\n",
      "Epoch 93/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0259 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.99445 to 0.99475, saving model to Results/852/weightsCheckpoints/weights-checkp-093-0.995.hdf5\n",
      "Epoch 94/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0324 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.99475\n",
      "Epoch 95/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0288 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.99475\n",
      "Epoch 96/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0327 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.99475\n",
      "Epoch 97/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0256 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.99475\n",
      "Epoch 98/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0340 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.99475\n",
      "Epoch 99/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0295 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.99475\n",
      "Epoch 100/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0309 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.99475\n",
      "Epoch 101/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0277 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.99475\n",
      "Epoch 102/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0345 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.99475\n",
      "Epoch 103/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0278 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.99475\n",
      "Epoch 104/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0290 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.99475\n",
      "Epoch 105/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0345 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.99475\n",
      "Epoch 106/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0257 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.99475 to 0.99499, saving model to Results/852/weightsCheckpoints/weights-checkp-106-0.995.hdf5\n",
      "Epoch 107/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0336 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.99499\n",
      "Epoch 108/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0280 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.99499\n",
      "Epoch 109/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0371 - val_acc: 0.9930\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.99499\n",
      "Epoch 110/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0380 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.99499\n",
      "Epoch 111/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0383 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.99499\n",
      "Epoch 112/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0301 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.99499\n",
      "Epoch 113/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0290 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.99499\n",
      "Epoch 114/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0347 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.99499\n",
      "Epoch 115/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0330 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.99499\n",
      "Epoch 116/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0303 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.99499\n",
      "Epoch 117/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0337 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.99499\n",
      "Epoch 118/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0324 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.99499\n",
      "Epoch 119/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0386 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.99499\n",
      "Epoch 120/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0311 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.99499\n",
      "Epoch 121/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0283 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.99499\n",
      "Epoch 122/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 5.8673e-04 - acc: 0.9999 - val_loss: 0.0245 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.99499 to 0.99566, saving model to Results/852/weightsCheckpoints/weights-checkp-122-0.996.hdf5\n",
      "Epoch 123/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 6.0393e-04 - acc: 0.9999 - val_loss: 0.0277 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.99566\n",
      "Epoch 124/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 5.6415e-04 - acc: 0.9999 - val_loss: 0.0247 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.99566\n",
      "Epoch 125/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4565e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.99566\n",
      "Epoch 126/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4384e-04 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.99566\n",
      "Epoch 127/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4350e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.99566 to 0.99596, saving model to Results/852/weightsCheckpoints/weights-checkp-127-0.996.hdf5\n",
      "Epoch 128/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4326e-04 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.99596\n",
      "Epoch 129/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4312e-04 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.99596\n",
      "Epoch 130/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4302e-04 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.99596\n",
      "Epoch 131/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4296e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.99596 to 0.99597, saving model to Results/852/weightsCheckpoints/weights-checkp-131-0.996.hdf5\n",
      "Epoch 132/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4288e-04 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.99597\n",
      "Epoch 133/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4284e-04 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.99597\n",
      "Epoch 134/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4279e-04 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.99597\n",
      "Epoch 135/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4275e-04 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.99597\n",
      "Epoch 136/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4271e-04 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.99597\n",
      "Epoch 137/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4269e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.99597\n",
      "Epoch 138/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4266e-04 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.99597 to 0.99599, saving model to Results/852/weightsCheckpoints/weights-checkp-138-0.996.hdf5\n",
      "Epoch 139/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4263e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.99599\n",
      "Epoch 140/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4261e-04 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.99599 to 0.99605, saving model to Results/852/weightsCheckpoints/weights-checkp-140-0.996.hdf5\n",
      "Epoch 141/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4258e-04 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.99605\n",
      "Epoch 142/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4256e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.99605\n",
      "Epoch 143/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4255e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.99605\n",
      "Epoch 144/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4253e-04 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.99605\n",
      "Epoch 145/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4251e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.99605\n",
      "Epoch 146/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4250e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.99605\n",
      "Epoch 147/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4248e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.99605 to 0.99609, saving model to Results/852/weightsCheckpoints/weights-checkp-147-0.996.hdf5\n",
      "Epoch 148/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4247e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.99609\n",
      "Epoch 149/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4246e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.99609 to 0.99610, saving model to Results/852/weightsCheckpoints/weights-checkp-149-0.996.hdf5\n",
      "Epoch 150/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4244e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.99610\n",
      "Epoch 151/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4243e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.99610\n",
      "Epoch 152/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4242e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.99610\n",
      "Epoch 153/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4241e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.99610\n",
      "Epoch 154/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4240e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.99610\n",
      "Epoch 155/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4240e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.99610\n",
      "Epoch 156/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4239e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.99610\n",
      "Epoch 157/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4238e-04 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.99610\n",
      "Epoch 158/160\n",
      "109429/109429 [==============================] - 4s 35us/step - loss: 4.4237e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.99610\n",
      "Epoch 159/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4236e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.99610\n",
      "Epoch 160/160\n",
      "109429/109429 [==============================] - 4s 36us/step - loss: 4.4236e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.99610\n",
      "Training done\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 orginal X_test\n",
      "(53899, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 orginal y_test\n",
      "(53899, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "Calculating score\n",
      "Calculating accuracy for all WDL values\n",
      "53899/53899 [==============================] - 3s 55us/step\n",
      "Shape of training data: (109429, 4, 8, 8)\n",
      "Evaluated test loss: 0.02373474755505602\n",
      "Evaluated test accuracy: 0.9960296109389785\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 orginal X_test\n",
      "(53899, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 orginal y_test\n",
      "(53899, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "Calculating score\n",
      "Only calculating accuracy for WDL =  -1\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2  X_test\n",
      "(12730, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 modified y_test\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "(12730, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "12730/12730 [==============================] - 1s 54us/step\n",
      "Shape of training data: (109429, 4, 8, 8)\n",
      "Evaluated test loss: 0.04632470142860689\n",
      "Evaluated test accuracy: 0.9919088766692852\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 orginal X_test\n",
      "(53899, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 orginal y_test\n",
      "(53899, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "Calculating score\n",
      "Only calculating accuracy for WDL =  0\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2  X_test\n",
      "(41169, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 modified y_test\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n",
      "(41169, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "41169/41169 [==============================] - 2s 54us/step\n",
      "Shape of training data: (109429, 4, 8, 8)\n",
      "Evaluated test loss: 0.01674963455898525\n",
      "Evaluated test accuracy: 0.9973037965459448\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 orginal X_test\n",
      "(53899, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 orginal y_test\n",
      "(53899, 4, 8, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "Calculating score\n",
      "Only calculating accuracy for WDL =  1\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2  X_test\n",
      "(0,)\n",
      "<class 'numpy.ndarray'>\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@2 modified y_test\n",
      "[]\n",
      "(0,)\n",
      "<class 'numpy.ndarray'>\n",
      "Skipping score calc, no datapoints\n",
      "Shape of training data: (109429, 4, 8, 8)\n",
      "Evaluated test loss: -1\n",
      "Evaluated test accuracy: -1\n",
      "Saving results to dir 852\n",
      "Saving history...\n",
      "Saving weights...\n",
      "Saving figures...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving summary...\n",
      "Saving tensorboard logs...\n",
      "All done saving stuff!\n",
      "7436088\n",
      "7436088\n",
      "X_train shape: (4982178, 4, 8, 8)\n",
      "y_train shape: (4982178, 1)\n",
      "X_test shape: (2453910, 4, 8, 8)\n",
      "y_test shape: (2453910, 1)\n",
      "4982178 train samples\n",
      "2453910 test samples\n",
      "Done loading dataset\n",
      "Save dir: Results/853/\n",
      "Creating save dir\n",
      "Done generating results dir Results/853/\n",
      "Saving weights to Results/853/weightsCheckpoints/\n",
      "Train on 4982178 samples, validate on 2453910 samples\n",
      "Epoch 1/160\n",
      "4982178/4982178 [==============================] - 179s 36us/step - loss: 0.2511 - acc: 0.8961 - val_loss: 0.1824 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92411, saving model to Results/853/weightsCheckpoints/weights-checkp-001-0.924.hdf5\n",
      "Epoch 2/160\n",
      "4982178/4982178 [==============================] - 179s 36us/step - loss: 0.1597 - acc: 0.9337 - val_loss: 0.1505 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92411 to 0.93760, saving model to Results/853/weightsCheckpoints/weights-checkp-002-0.938.hdf5\n",
      "Epoch 3/160\n",
      "4982178/4982178 [==============================] - 179s 36us/step - loss: 0.1326 - acc: 0.9456 - val_loss: 0.1275 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.93760 to 0.94792, saving model to Results/853/weightsCheckpoints/weights-checkp-003-0.948.hdf5\n",
      "Epoch 4/160\n",
      "4982178/4982178 [==============================] - 178s 36us/step - loss: 0.1171 - acc: 0.9524 - val_loss: 0.1183 - val_acc: 0.9523\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.94792 to 0.95226, saving model to Results/853/weightsCheckpoints/weights-checkp-004-0.952.hdf5\n",
      "Epoch 5/160\n",
      "4982178/4982178 [==============================] - 177s 36us/step - loss: 0.1072 - acc: 0.9568 - val_loss: 0.1065 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.95226 to 0.95741, saving model to Results/853/weightsCheckpoints/weights-checkp-005-0.957.hdf5\n",
      "Epoch 6/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.1003 - acc: 0.9598 - val_loss: 0.1024 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.95741 to 0.95914, saving model to Results/853/weightsCheckpoints/weights-checkp-006-0.959.hdf5\n",
      "Epoch 7/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0950 - acc: 0.9622 - val_loss: 0.0992 - val_acc: 0.9604\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.95914 to 0.96037, saving model to Results/853/weightsCheckpoints/weights-checkp-007-0.960.hdf5\n",
      "Epoch 8/160\n",
      "4982178/4982178 [==============================] - 177s 36us/step - loss: 0.0909 - acc: 0.9640 - val_loss: 0.0990 - val_acc: 0.9608\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.96037 to 0.96081, saving model to Results/853/weightsCheckpoints/weights-checkp-008-0.961.hdf5\n",
      "Epoch 9/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0879 - acc: 0.9653 - val_loss: 0.0987 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.96081 to 0.96117, saving model to Results/853/weightsCheckpoints/weights-checkp-009-0.961.hdf5\n",
      "Epoch 10/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0854 - acc: 0.9664 - val_loss: 0.0918 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.96117 to 0.96374, saving model to Results/853/weightsCheckpoints/weights-checkp-010-0.964.hdf5\n",
      "Epoch 11/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0832 - acc: 0.9673 - val_loss: 0.0944 - val_acc: 0.9635\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.96374\n",
      "Epoch 12/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0816 - acc: 0.9681 - val_loss: 0.0900 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.96374 to 0.96577, saving model to Results/853/weightsCheckpoints/weights-checkp-012-0.966.hdf5\n",
      "Epoch 13/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0799 - acc: 0.9688 - val_loss: 0.0863 - val_acc: 0.9667\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.96577 to 0.96670, saving model to Results/853/weightsCheckpoints/weights-checkp-013-0.967.hdf5\n",
      "Epoch 14/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0787 - acc: 0.9694 - val_loss: 0.0887 - val_acc: 0.9666\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.96670\n",
      "Epoch 15/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0772 - acc: 0.9700 - val_loss: 0.0861 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.96670 to 0.96752, saving model to Results/853/weightsCheckpoints/weights-checkp-015-0.968.hdf5\n",
      "Epoch 16/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0760 - acc: 0.9706 - val_loss: 0.0808 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.96752 to 0.96904, saving model to Results/853/weightsCheckpoints/weights-checkp-016-0.969.hdf5\n",
      "Epoch 17/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0753 - acc: 0.9710 - val_loss: 0.0822 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.96904\n",
      "Epoch 18/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0747 - acc: 0.9712 - val_loss: 0.0816 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96904\n",
      "Epoch 19/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0737 - acc: 0.9717 - val_loss: 0.0821 - val_acc: 0.9687\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.96904\n",
      "Epoch 20/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0728 - acc: 0.9720 - val_loss: 0.0846 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.96904\n",
      "Epoch 21/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0721 - acc: 0.9723 - val_loss: 0.0814 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.96904 to 0.96917, saving model to Results/853/weightsCheckpoints/weights-checkp-021-0.969.hdf5\n",
      "Epoch 22/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0717 - acc: 0.9725 - val_loss: 0.0794 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.96917 to 0.97068, saving model to Results/853/weightsCheckpoints/weights-checkp-022-0.971.hdf5\n",
      "Epoch 23/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0711 - acc: 0.9727 - val_loss: 0.0831 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97068\n",
      "Epoch 24/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0703 - acc: 0.9731 - val_loss: 0.0759 - val_acc: 0.9711\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.97068 to 0.97109, saving model to Results/853/weightsCheckpoints/weights-checkp-024-0.971.hdf5\n",
      "Epoch 25/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0699 - acc: 0.9733 - val_loss: 0.0868 - val_acc: 0.9678\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.97109\n",
      "Epoch 26/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0692 - acc: 0.9737 - val_loss: 0.0806 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97109\n",
      "Epoch 27/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0685 - acc: 0.9739 - val_loss: 0.0806 - val_acc: 0.9702\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.97109\n",
      "Epoch 28/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0680 - acc: 0.9742 - val_loss: 0.0801 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97109\n",
      "Epoch 29/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0677 - acc: 0.9743 - val_loss: 0.0806 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97109\n",
      "Epoch 30/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0672 - acc: 0.9745 - val_loss: 0.0778 - val_acc: 0.9716\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.97109 to 0.97163, saving model to Results/853/weightsCheckpoints/weights-checkp-030-0.972.hdf5\n",
      "Epoch 31/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0669 - acc: 0.9747 - val_loss: 0.0777 - val_acc: 0.9711\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97163\n",
      "Epoch 32/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0662 - acc: 0.9749 - val_loss: 0.0764 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97163\n",
      "Epoch 33/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0659 - acc: 0.9750 - val_loss: 0.0755 - val_acc: 0.9721\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.97163 to 0.97208, saving model to Results/853/weightsCheckpoints/weights-checkp-033-0.972.hdf5\n",
      "Epoch 34/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0655 - acc: 0.9753 - val_loss: 0.0764 - val_acc: 0.9715\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.97208\n",
      "Epoch 35/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0653 - acc: 0.9753 - val_loss: 0.0703 - val_acc: 0.9741\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.97208 to 0.97407, saving model to Results/853/weightsCheckpoints/weights-checkp-035-0.974.hdf5\n",
      "Epoch 36/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0648 - acc: 0.9756 - val_loss: 0.0795 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.97407\n",
      "Epoch 37/160\n",
      "4982178/4982178 [==============================] - 177s 35us/step - loss: 0.0645 - acc: 0.9758 - val_loss: 0.0762 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.97407\n",
      "Epoch 38/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0640 - acc: 0.9759 - val_loss: 0.0758 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.97407\n",
      "Epoch 39/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0638 - acc: 0.9760 - val_loss: 0.0734 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.97407\n",
      "Epoch 40/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0636 - acc: 0.9762 - val_loss: 0.0867 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.97407\n",
      "Epoch 41/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0632 - acc: 0.9763 - val_loss: 0.0773 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.97407\n",
      "Epoch 42/160\n",
      "4982178/4982178 [==============================] - 178s 36us/step - loss: 0.0628 - acc: 0.9765 - val_loss: 0.0774 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.97407\n",
      "Epoch 43/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0630 - acc: 0.9764 - val_loss: 0.0766 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.97407\n",
      "Epoch 44/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0625 - acc: 0.9766 - val_loss: 0.0747 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.97407\n",
      "Epoch 45/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0624 - acc: 0.9767 - val_loss: 0.0761 - val_acc: 0.9719\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.97407\n",
      "Epoch 46/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0622 - acc: 0.9767 - val_loss: 0.0751 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.97407\n",
      "Epoch 47/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0617 - acc: 0.9769 - val_loss: 0.0773 - val_acc: 0.9719\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.97407\n",
      "Epoch 48/160\n",
      "4982178/4982178 [==============================] - 178s 36us/step - loss: 0.0612 - acc: 0.9772 - val_loss: 0.0725 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.97407\n",
      "Epoch 49/160\n",
      "4982178/4982178 [==============================] - 177s 36us/step - loss: 0.0611 - acc: 0.9772 - val_loss: 0.0730 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.97407 to 0.97436, saving model to Results/853/weightsCheckpoints/weights-checkp-049-0.974.hdf5\n",
      "Epoch 50/160\n",
      "4982178/4982178 [==============================] - 177s 36us/step - loss: 0.0611 - acc: 0.9773 - val_loss: 0.0760 - val_acc: 0.9733\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.97436\n",
      "Epoch 51/160\n",
      "4982178/4982178 [==============================] - 177s 36us/step - loss: 0.0609 - acc: 0.9774 - val_loss: 0.0719 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.97436\n",
      "Epoch 52/160\n",
      "4982178/4982178 [==============================] - 182s 37us/step - loss: 0.0606 - acc: 0.9775 - val_loss: 0.0736 - val_acc: 0.9728\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.97436\n",
      "Epoch 53/160\n",
      "4982178/4982178 [==============================] - 181s 36us/step - loss: 0.0607 - acc: 0.9774 - val_loss: 0.0697 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.97436 to 0.97483, saving model to Results/853/weightsCheckpoints/weights-checkp-053-0.975.hdf5\n",
      "Epoch 54/160\n",
      "4982178/4982178 [==============================] - 184s 37us/step - loss: 0.0603 - acc: 0.9777 - val_loss: 0.0685 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.97483\n",
      "Epoch 55/160\n",
      "4982178/4982178 [==============================] - 179s 36us/step - loss: 0.0600 - acc: 0.9777 - val_loss: 0.0746 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.97483\n",
      "Epoch 56/160\n",
      "4982178/4982178 [==============================] - 178s 36us/step - loss: 0.0599 - acc: 0.9778 - val_loss: 0.0756 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.97483\n",
      "Epoch 57/160\n",
      "4982178/4982178 [==============================] - 177s 36us/step - loss: 0.0597 - acc: 0.9778 - val_loss: 0.0695 - val_acc: 0.9747\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.97483\n",
      "Epoch 58/160\n",
      "4982178/4982178 [==============================] - 177s 36us/step - loss: 0.0595 - acc: 0.9779 - val_loss: 0.0772 - val_acc: 0.9719\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.97483\n",
      "Epoch 59/160\n",
      "4982178/4982178 [==============================] - 177s 36us/step - loss: 0.0592 - acc: 0.9781 - val_loss: 0.0783 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.97483\n",
      "Epoch 60/160\n",
      "4982178/4982178 [==============================] - 178s 36us/step - loss: 0.0591 - acc: 0.9781 - val_loss: 0.0746 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.97483\n",
      "Epoch 61/160\n",
      "4982178/4982178 [==============================] - 178s 36us/step - loss: 0.0589 - acc: 0.9783 - val_loss: 0.0704 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.97483\n",
      "Epoch 62/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0590 - acc: 0.9782 - val_loss: 0.0826 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.97483\n",
      "Epoch 63/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0590 - acc: 0.9782 - val_loss: 0.0734 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.97483\n",
      "Epoch 64/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0586 - acc: 0.9784 - val_loss: 0.0739 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.97483\n",
      "Epoch 65/160\n",
      "4982178/4982178 [==============================] - 177s 35us/step - loss: 0.0587 - acc: 0.9784 - val_loss: 0.0719 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.97483 to 0.97571, saving model to Results/853/weightsCheckpoints/weights-checkp-065-0.976.hdf5\n",
      "Epoch 66/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0585 - acc: 0.9784 - val_loss: 0.0745 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.97571\n",
      "Epoch 67/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0582 - acc: 0.9785 - val_loss: 0.0697 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.97571\n",
      "Epoch 68/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0581 - acc: 0.9786 - val_loss: 0.0641 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.97571 to 0.97689, saving model to Results/853/weightsCheckpoints/weights-checkp-068-0.977.hdf5\n",
      "Epoch 69/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0579 - acc: 0.9787 - val_loss: 0.0682 - val_acc: 0.9752\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.97689\n",
      "Epoch 70/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0580 - acc: 0.9787 - val_loss: 0.0774 - val_acc: 0.9732\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.97689\n",
      "Epoch 71/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0577 - acc: 0.9788 - val_loss: 0.0658 - val_acc: 0.9763\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.97689\n",
      "Epoch 72/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0575 - acc: 0.9789 - val_loss: 0.0724 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.97689\n",
      "Epoch 73/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0575 - acc: 0.9789 - val_loss: 0.0740 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.97689\n",
      "Epoch 74/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0574 - acc: 0.9789 - val_loss: 0.0671 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.97689\n",
      "Epoch 75/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0571 - acc: 0.9791 - val_loss: 0.0703 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.97689\n",
      "Epoch 76/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0569 - acc: 0.9792 - val_loss: 0.0781 - val_acc: 0.9729\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.97689\n",
      "Epoch 77/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0567 - acc: 0.9792 - val_loss: 0.0692 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.97689\n",
      "Epoch 78/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0568 - acc: 0.9792 - val_loss: 0.0678 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.97689 to 0.97697, saving model to Results/853/weightsCheckpoints/weights-checkp-078-0.977.hdf5\n",
      "Epoch 79/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0566 - acc: 0.9793 - val_loss: 0.0670 - val_acc: 0.9761\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.97697\n",
      "Epoch 80/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0565 - acc: 0.9793 - val_loss: 0.0717 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.97697\n",
      "Epoch 81/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0565 - acc: 0.9794 - val_loss: 0.0781 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.97697\n",
      "Epoch 82/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0562 - acc: 0.9796 - val_loss: 0.0722 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.97697\n",
      "Epoch 83/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0561 - acc: 0.9795 - val_loss: 0.0722 - val_acc: 0.9754\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.97697\n",
      "Epoch 84/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0560 - acc: 0.9796 - val_loss: 0.0683 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.97697\n",
      "Epoch 85/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0557 - acc: 0.9797 - val_loss: 0.0701 - val_acc: 0.9757\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.97697\n",
      "Epoch 86/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0558 - acc: 0.9797 - val_loss: 0.0681 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.97697\n",
      "Epoch 87/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0556 - acc: 0.9798 - val_loss: 0.0631 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.97697 to 0.97758, saving model to Results/853/weightsCheckpoints/weights-checkp-087-0.978.hdf5\n",
      "Epoch 88/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0554 - acc: 0.9800 - val_loss: 0.0713 - val_acc: 0.9758\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.97758\n",
      "Epoch 89/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0552 - acc: 0.9800 - val_loss: 0.0719 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.97758\n",
      "Epoch 90/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0552 - acc: 0.9800 - val_loss: 0.0667 - val_acc: 0.9768\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.97758\n",
      "Epoch 91/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0550 - acc: 0.9801 - val_loss: 0.0655 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.97758\n",
      "Epoch 92/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0550 - acc: 0.9801 - val_loss: 0.0807 - val_acc: 0.9741\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.97758\n",
      "Epoch 93/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0549 - acc: 0.9802 - val_loss: 0.0768 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.97758\n",
      "Epoch 94/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0546 - acc: 0.9802 - val_loss: 0.0696 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.97758\n",
      "Epoch 95/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0546 - acc: 0.9801 - val_loss: 0.0629 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.97758 to 0.97814, saving model to Results/853/weightsCheckpoints/weights-checkp-095-0.978.hdf5\n",
      "Epoch 96/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0543 - acc: 0.9803 - val_loss: 0.0723 - val_acc: 0.9746\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.97814\n",
      "Epoch 97/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0546 - acc: 0.9803 - val_loss: 0.0756 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.97814\n",
      "Epoch 98/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0544 - acc: 0.9803 - val_loss: 0.0717 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.97814\n",
      "Epoch 99/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0539 - acc: 0.9805 - val_loss: 0.0670 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.97814\n",
      "Epoch 100/160\n",
      "4982178/4982178 [==============================] - 175s 35us/step - loss: 0.0543 - acc: 0.9804 - val_loss: 0.0714 - val_acc: 0.9746\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.97814\n",
      "Epoch 101/160\n",
      "4982178/4982178 [==============================] - 176s 35us/step - loss: 0.0539 - acc: 0.9806 - val_loss: 0.0675 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.97814\n",
      "Epoch 102/160\n",
      "1648384/4982178 [========>.....................] - ETA: 1:44 - loss: 0.0526 - acc: 0.9810"
     ]
    }
   ],
   "source": [
    "%run -i arena.py\n",
    "# stuff to save in bengioResults dir\n",
    "# resSaveFile = 'conv3to4-startingAt300epochs'\n",
    "# dictFieldName = 'acc'\n",
    "# saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "# resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "\n",
    "# prepare save file\n",
    "# if os.path.exists(resSaveFileFullPath):\n",
    "#     print(\"Save file exists..., aborting\\n\")\n",
    "#     sys.exit()\n",
    "    \n",
    "for i in range(averageOver):\n",
    "    print(\"__________________________________________________ RUN {}\".format(i))\n",
    "    \n",
    "########################################################## train on 3pc\n",
    "    ############################### set 3pc parameters\n",
    "    # What data to use\n",
    "    tableBase = '3PKk'\n",
    "    \n",
    "    # Generate dataset variables\n",
    "    fileName = tableBase + '.hdf5'\n",
    "    dataSetName = tableBase + '_onlyLegal'\n",
    "    if not convertStates: \n",
    "        dataSetName = tableBase + '_onlyLegal_fullStates'\n",
    "    dataSetWdlName = tableBase + '_Wdl_onlyLegal_3Values'\n",
    "\n",
    "    # Number of Pieces\n",
    "    nPi =  int(dataSetName[0])\n",
    "    nPa = nPi - 2\n",
    "    nWPa = math.ceil(nPa/2)\n",
    "    \n",
    "    # Parameters\n",
    "    expDescrBase = \"converge 3 to 4 - {} epochs - tablebase {}\".format(epochs, tableBase)\n",
    "\n",
    "    ################################# train 3pc\n",
    "    expDescr = expDescrBase + ' - run {} of {}'.format(i,averageOver)\n",
    "    # load data\n",
    "    X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "    # create model\n",
    "    model, nnStr = createModel()\n",
    "\n",
    "    # create results dir\n",
    "    resID = genNextResultsDir(model)\n",
    "\n",
    "    # train\n",
    "    fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "    # calc score \n",
    "    score, scoreCount = calcScore(model, X_test, y_test, returnCount = True)\n",
    "    if calcIndvWDLvalues:\n",
    "        scoreLoss, scoreLossCount= calcScore(model, X_test, y_test,targetWDLvalue = -1, returnCount = True)\n",
    "        scoreDraw, scoreDrawCount = calcScore(model, X_test, y_test,targetWDLvalue = 0, returnCount = True)\n",
    "        scoreWin, scoreWinCount = calcScore(model, X_test, y_test,targetWDLvalue = 1, returnCount = True)\n",
    "    if saveEveryRun:\n",
    "        saveTrainResults(resID, model, logDir, score)\n",
    "        \n",
    "########################################################## transfer to 4pc\n",
    "    ############################### set 4pc parameters\n",
    "    # What data to use\n",
    "    tableBase = '4PpKk'\n",
    "    \n",
    "    ### DON'T MODIFY BELOW ###\n",
    "    # Generate dataset variables\n",
    "    fileName = tableBase + '.hdf5'\n",
    "    dataSetName = tableBase + '_onlyLegal'\n",
    "    if not convertStates: \n",
    "        dataSetName = tableBase + '_onlyLegal_fullStates'\n",
    "    dataSetWdlName = tableBase + '_Wdl_onlyLegal_3Values'\n",
    "\n",
    "    # Number of Pieces\n",
    "    nPi =  int(dataSetName[0])\n",
    "    nPa = nPi - 2\n",
    "    nWPa = math.ceil(nPa/2)\n",
    "    \n",
    "    expDescrBase = \"converge 3 to 4 - {} epochs - tablebase {}\".format(epochs, tableBase)\n",
    "\n",
    "    ### train 4pc\n",
    "    expDescr = expDescrBase + ' - run {} of {}'.format(i,averageOver)\n",
    "    # load data\n",
    "    X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "    # create results dir\n",
    "    resID = genNextResultsDir(model)\n",
    "\n",
    "    # train\n",
    "    fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "    # calc score \n",
    "    score, scoreCount = calcScore(model, X_test, y_test, returnCount = True)\n",
    "    if calcIndvWDLvalues:\n",
    "        scoreLoss, scoreLossCount= calcScore(model, X_test, y_test,targetWDLvalue = -1, returnCount = True)\n",
    "        scoreDraw, scoreDrawCount = calcScore(model, X_test, y_test,targetWDLvalue = 0, returnCount = True)\n",
    "        scoreWin, scoreWinCount = calcScore(model, X_test, y_test,targetWDLvalue = 1, returnCount = True)\n",
    "    if saveEveryRun:\n",
    "        saveTrainResults(resID, model, logDir, score)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frimann/anaconda3/envs/endnetGpu8/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3299: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7436088\n",
      "74360\n",
      "X_train shape: (49821, 4, 8, 8)\n",
      "y_train shape: (49821, 1)\n",
      "X_test shape: (24539, 4, 8, 8)\n",
      "y_test shape: (24539, 1)\n",
      "49821 train samples\n",
      "24539 test samples\n",
      "Done loading dataset\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_330 (Conv2D)          (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_331 (Conv2D)          (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_332 (Conv2D)          (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_333 (Conv2D)          (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_334 (Conv2D)          (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_335 (Conv2D)          (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_336 (Conv2D)          (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n",
      "Calculating score\n",
      "Only calculating accuracy for WDL =  -1\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "6829/6829 [==============================] - 2s 256us/step\n",
      "Shape of training data: (49821, 4, 8, 8)\n",
      "Evaluated test loss: 1.0965252375250105\n",
      "Evaluated test accuracy: 0.8465368282412659\n"
     ]
    }
   ],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "tableBase = '4PpKk'\n",
    "fileName = tableBase + '.hdf5'\n",
    "\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "model, nnStr = createModel()\n",
    "\n",
    "score = calcScore(model, X_test, y_test, targetWDLvalue = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 0\n",
    "Converge 3>4 and rnd>4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "# weightsSource = '103' # trained on 3pc from scratch\n",
    "weightsSource = '521' # trained on 3pc then 4pc for 150ep\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "epochs = 10\n",
    "averageOver = 1\n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"converge 3to4 - {} averages - {} epochs\".format(averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dir\n",
    "saveBengioCheckPoints = True\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "compareResultsDuringTraining = False\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 0.0001\n",
    "plotDuringTraining = True\n",
    "loadWeights = True \n",
    "loadCheckpointWeights = False\n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = 'conv3to4-startingAt300epochs'\n",
    "dictFieldName = 'acc'\n",
    "saveDir = 'bengioResults'\n",
    "resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "# resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "# resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "# resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "# resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, {dictFieldName:[]})\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "# model, nnStr = createModel()\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "# resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "# resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "# startTrainingAtLayer = len(results)\n",
    "# print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "startThisRunAt = len(results[dictFieldName])\n",
    "print(\"\\nStarting/restarting TL at average {}\".format(startThisRunAt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# train and average results\n",
    "for a in range(startThisRunAt,averageOver):\n",
    "    print('    ==================================================================================')\n",
    "    print('    =                                                                                =')\n",
    "    print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "    print('    =                                                                                =')\n",
    "    print('    ==================================================================================')\n",
    "    print()\n",
    "\n",
    "    # set experement description test\n",
    "#     expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "    expDescr = expDescrBaseName + '__average_{}_of_{}'.format(a+1, averageOver)\n",
    "\n",
    "    # save current averagePosition to tmp file\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "        file.write('Inner avg loop position: {} out of {}'.format(a+1, averageOver))         \n",
    "\n",
    "    # load Model layers\n",
    "#     model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "    model, nnStr = createModel()\n",
    "\n",
    "    # load data\n",
    "    X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "    \n",
    "    # Prepare save dir\n",
    "    if saveEveryRun:\n",
    "        resID = genNextResultsDir(model)\n",
    "\n",
    "    # train\n",
    "    fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "    # calc score \n",
    "    score = calcScore(model)\n",
    "    results[dictFieldName].append(score[1])\n",
    "    if saveEveryRun:\n",
    "        saveTrainResults(resID, model, logDir, score)\n",
    "\n",
    "    # save checkpoint\n",
    "    if saveBengioCheckPoints:\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "\n",
    "        src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "\n",
    "        src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "\n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "\n",
    "\n",
    "print('\\n Final Results: {}'.format(results))\n",
    "print('\\n Final Results Averate: {}'.format(np.mean(np.array(results[dictFieldName]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "\n",
    "src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "if os.path.exists(src):\n",
    "    shutil.move(src, dest)\n",
    "\n",
    "src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "if os.path.exists(src):\n",
    "    shutil.move(src, dest)\n",
    "\n",
    "# save results \n",
    "save_obj(saveDir, resSaveFile, results)\n",
    "with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "    file.write(str(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4\n",
    "Bengio methood\n",
    "4n4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "# sourceNet = '103' # trained on 3pc from scratch\n",
    "sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = True                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 5 \n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 4n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False #only used in createModel function, the loadFirstNLayers always loads weights! \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '4n4'\n",
    "saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "# print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "#     # start accumulated score from load file in case of starting from average run  0\n",
    "#     accumulatedScore = np.sum(resultsThisRun)\n",
    "\n",
    "    # Reset variables\n",
    "    resultsThisRun = []\n",
    "    accumulatedScore = 0\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save bengio checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "    \n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5\n",
    "Bengio methood\n",
    "4n4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp  parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "# sourceNet = '103' # trained on 3pc from scratch\n",
    "sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = True                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 5 \n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 4n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '4n4p'\n",
    "saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "# print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "#     # start accumulated score from load file in case of starting from average run  0\n",
    "#     accumulatedScore = np.sum(resultsThisRun)\n",
    "\n",
    "    # Reset variables\n",
    "    resultsThisRun = []\n",
    "    accumulatedScore = 0\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save bengio checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "    \n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "Bengio methood\n",
    "3n4+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp 1 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = False                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 5 \n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 3n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '3n4'\n",
    "saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "# print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "#     # start accumulated score from load file in case of starting from average run  0\n",
    "#     accumulatedScore = np.sum(resultsThisRun)\n",
    "\n",
    "    # Reset variables\n",
    "    resultsThisRun = []\n",
    "    accumulatedScore = 0\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save bengio checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "    \n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "Bengio methood\n",
    "3n4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp  parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = True                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 5 \n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Bengio 3n4 - freeze = {} - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '3n4p'\n",
    "saveDir = 'bengioResults'\n",
    "# resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "# startThisRunAt = len(resultsThisRun)\n",
    "# print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "#     # start accumulated score from load file in case of starting from average run  0\n",
    "#     accumulatedScore = np.sum(resultsThisRun)\n",
    "\n",
    "    # Reset variables\n",
    "    resultsThisRun = []\n",
    "    accumulatedScore = 0\n",
    "    \n",
    "    # train and average results\n",
    "    for a in range(averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # load data\n",
    "        X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        # save bengio checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "    \n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3\n",
    "converging 3_8_4+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 3 Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch ######################## MODIFY\n",
    "freeze = False                           ############################### MODIFY\n",
    "epochs = 10\n",
    "averageOver = 10\n",
    "                          ############################### MODIFY\n",
    "expDescrBaseName = \"Converging 3n4plus - average over {} runs - {} epochs\".format(str(freeze), averageOver, epochs)\n",
    "\n",
    "saveEveryRun = False # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = False # save logs in ./logs dir\n",
    "resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 0.001\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "\n",
    "# stuff to save in bengioResults dir\n",
    "resSaveFile = '3_8_4_plus_Converge'                          ############################### MODIFY\n",
    "saveDir = 'bengioResults'\n",
    "resSaveFile = resSaveFile + '-{}runAverage-{}epochs'.format(averageOver, epochs)\n",
    "resSaveFileFullPath = saveDir + '/' + str(resSaveFile) + '.pkl' \n",
    "resSaveFileAllRuns = resSaveFile + '-allRuns'.format(averageOver, epochs)\n",
    "resSaveFileAllRunsFullPath = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl' \n",
    "resSaveFileThisRun = resSaveFile + '-thisRun'.format(averageOver, epochs)\n",
    "resSaveFileThisRunFullPath = saveDir + '/' + str(resSaveFileThisRun) + '.pkl' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare save file\n",
    "if not os.path.exists(resSaveFileFullPath):\n",
    "    print(\"Save file doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFile, [])\n",
    "else:\n",
    "    print(\"Save file exists...\\n\")\n",
    "    \n",
    "if not os.path.exists(resSaveFileAllRunsFullPath):\n",
    "    print(\"Save file for all runs doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileAllRuns, [])\n",
    "else:\n",
    "    print(\"Save file for all runs exists...\\n\")\n",
    "\n",
    "if not os.path.exists(resSaveFileThisRunFullPath):\n",
    "    print(\"Save file for this run doesn't exists, creating...\\n\")\n",
    "    save_obj(saveDir, resSaveFileThisRun, [])\n",
    "else:\n",
    "    print(\"Save file for this run exists...\\n\")\n",
    "\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n",
    "# create model\n",
    "model, nnStr = createModel()\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "# load old results\n",
    "results = load_obj(saveDir, resSaveFile)\n",
    "resultsAllRuns = load_obj(saveDir, resSaveFileAllRuns)\n",
    "resultsThisRun = load_obj(saveDir, resSaveFileThisRun)\n",
    "\n",
    "# initialize variables wrt old results\n",
    "startTrainingAtLayer = len(results)\n",
    "startTrainingAtLayer = 7\n",
    "print(\"\\nStarting/restarting TL at {} transfered layers\".format(startTrainingAtLayer))\n",
    "startThisRunAt = len(resultsThisRun)\n",
    "print(\"\\nStarting/restarting TL at average {}\".format(startTrainingAtLayer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(resultsThisRun)\n",
    "print(resultsAllRuns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "for copyFirstNLayers in range(startTrainingAtLayer, layersCount):\n",
    "    print('\\n\\n')\n",
    "    print('==========================================================================================')\n",
    "    print('=                                                                                        =')\n",
    "    print('=                    Currently transfering first {} layers, out of {}                      ='.format(copyFirstNLayers, layersCount - 1))\n",
    "    print('=                                                                                        =')\n",
    "    print('==========================================================================================')\n",
    "    print()\n",
    "    \n",
    "    # check if we are at the flatten layer, and skip it if so\n",
    "    if copyFirstNLayers == layersCount - 1:\n",
    "        copyFirstNLayers += 1\n",
    "        \n",
    "    # train and average results\n",
    "    accumulatedScore = np.sum(resultsThisRun)\n",
    "#     resultsThisRun = []\n",
    "    for a in range(startThisRunAt,averageOver):\n",
    "        print('    ==================================================================================')\n",
    "        print('    =                                                                                =')\n",
    "        print('    =                Currently at run {}, out of {}                                   ='.format(a+1,averageOver))\n",
    "        print('    =                                                                                =')\n",
    "        print('    ==================================================================================')\n",
    "        print()\n",
    "        \n",
    "        # set experement description test\n",
    "        expDescr = expDescrBaseName + '__copyLayers_{}__average_{}_of_{}'.format(copyFirstNLayers, a+1, averageOver)\n",
    "        \n",
    "        # save current averagePosition to tmp file\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '_currentPosition.txt','w') as file:\n",
    "            if copyFirstNLayers == layersCount:\n",
    "                location = copyFirstNLayers - 1\n",
    "            else:\n",
    "                location = copyFirstNLayers \n",
    "            file.write('Layers Transfered: {} out of {} \\nInner avg loop position: {} out of {}'.format(location, layersCount-1, a+1, averageOver))         \n",
    "            \n",
    "        # load Model layers\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        # Prepare save dir\n",
    "        if saveEveryRun:\n",
    "            resID = genNextResultsDir(model)\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "        # score and save results\n",
    "        score = calcScore(model)\n",
    "        if saveEveryRun:\n",
    "            saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "\n",
    "        # update Return\n",
    "        accumulatedScore += score[1]\n",
    "        resultsThisRun.append(score[1])\n",
    "        \n",
    "        \n",
    "        # save checkpoint\n",
    "        dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "        \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.pkl'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.pkl'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "            \n",
    "        src = saveDir + '/' + str(resSaveFileThisRun) + '.txt'\n",
    "        dest = saveDir + '/checkpoints/' + str(resSaveFileThisRun) + dateTime + '.txt'\n",
    "        if os.path.exists(src):\n",
    "            shutil.move(src, dest)\n",
    "        \n",
    "        # save results \n",
    "        save_obj(saveDir, resSaveFileThisRun, resultsThisRun)\n",
    "        with open(saveDir + '/' + str(resSaveFileThisRun) + '.txt','w') as file:\n",
    "            file.write(str(resultsThisRun))\n",
    "            \n",
    "    # append averaged results for one set of layers\n",
    "    results.append(accumulatedScore/averageOver)\n",
    "    resultsAllRuns.append(resultsThisRun)\n",
    "\n",
    "    # save old results to checkpoints dir\n",
    "    dateTime = time.strftime('%Y-%m-%d-%H:%M:%S', time.localtime())\n",
    "    \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFile) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFile) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "\n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.txt'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.txt'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    src = saveDir + '/' + str(resSaveFileAllRuns) + '.pkl'\n",
    "    dest = saveDir + '/checkpoints/' + str(resSaveFileAllRuns) + dateTime + '.pkl'\n",
    "    if os.path.exists(src):\n",
    "        shutil.move(src, dest)\n",
    "        \n",
    "    # save results \n",
    "    save_obj(saveDir, resSaveFile, results)\n",
    "    with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "        file.write(str(results))\n",
    "    \n",
    "    save_obj(saveDir, resSaveFileAllRuns, resultsAllRuns)\n",
    "    with open(saveDir + '/' + str(resSaveFileAllRuns) + '.txt','w') as file:\n",
    "        file.write(str(resultsAllRuns))\n",
    "\n",
    "    # to load:\n",
    "    # results = load_obj('temp','3n4.txt')\n",
    "    resultsThisRun = []\n",
    "print('\\n Final Results: {}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsThisRun\n",
    "# save_ob('.','x',resultsThisRun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 0\n",
    "test batch size vs time vs validation valley location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 0 Paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "weightsSource = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '103' # trained on 3pc from scratch\n",
    "# sourceNet = '107' # trained on 4pc from scratch\n",
    "# freeze = False\n",
    "epochs = 350\n",
    "expDescrBaseName = \"Batch size test\"\n",
    "\n",
    "saveEveryRun = True # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = True # save logs in ./logs dir\n",
    "# resID = '---NORESID---' # used when not saving data, but fitModel() still needs a resID\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "loadCheckpointWeights = False\n",
    "askForConfirmation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# load data\n",
    "X_train, X_test, y_train, y_test = loadData(randomState = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%run -i 'arena.py'\n",
    "\n",
    "batches = [128, 1024]\n",
    "for batch_size in batches:\n",
    "    \n",
    "    expDescr = expDescrBaseName + '_batchSize{}'.format(batch_size)\n",
    "    \n",
    "    # create model\n",
    "    model, nnStr = createModel()\n",
    "\n",
    "    # Prepare save dir\n",
    "    if saveEveryRun:\n",
    "        resID = genNextResultsDir(model)\n",
    "        \n",
    "    # train\n",
    "    fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "        \n",
    "    # score and save results\n",
    "    score = calcScore(model)\n",
    "    if saveEveryRun:\n",
    "        saveTrainResults(resID, model, logDir, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
