{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "    - Test if small batch is better\n",
    "        - Exp 1\n",
    "            - Save to 006\n",
    "            - starting from 005, and shring batch size to 512\n",
    "            - Results: after 183 epochs, the accuracy was actually lower than before training. \n",
    "              Batch size is probably not to big at 4096.\n",
    "        - Exp 2\n",
    "            - Starting from 012, a 100.000 pm net trained for 1600 epochs at bs 4096\n",
    "            - Switching to bs 32 created horrible results, network totally failed to perform, lost acc from \n",
    "              0.95 to 0.85 in 17 epochs. Plus, super slow to train\n",
    "                 \n",
    "    - Test Adam\n",
    "        - Results\n",
    "            - 007 Adam, final accuracy 0.939 after 500\n",
    "            - 005 Adadelta, final accuracy 0.952 after 1000 epochs\n",
    "            - Adam not performing better than Adadelta\n",
    "            \n",
    "    - Test 2x2 and 3x3 filters for performance\n",
    "        - 2x2 5 layers (005)\n",
    "        - 3x3 3 layers (003)\n",
    "        - ~50.000 parameters\n",
    "        - Results\n",
    "            - 005 vs 008\n",
    "            - Same performance after 331 epochs\n",
    "            \n",
    "    - Test float16\n",
    "        - 005 float32\n",
    "        - 010 float16\n",
    "        - Results\n",
    "            - float16 scored lower\n",
    "            - float16 is 40% longer per epoch (35sec vs 50sec per epoch\n",
    "            - float32 is the way to go!\n",
    "            \n",
    "    - Try Batch Normalization\n",
    "        - model.add(BatchNormalization())\n",
    "        - Results:\n",
    "            - Comparing with 005, no batch norm\n",
    "            - Saved to 011, with batch norm\n",
    "            - ~same number of weights...\n",
    "            - Batch Normalization is performing worse after ~40 epochs\n",
    "            \n",
    "    - Try different initial weights\n",
    "        - keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "        - Results\n",
    "            - Tried for a few epochs, similar curve as for 005\n",
    "            \n",
    "    - Test different size model\n",
    "        - Experiments\n",
    "            - 005\n",
    "                - 50kpm\n",
    "                - 500 epochs\n",
    "                - 0.952 acc\n",
    "                - still learning\n",
    "                - 2048bs > 37s/epoch\n",
    "                - 4096bs > 29s/epoch\n",
    "            - 013\n",
    "                - 188kpm\n",
    "                - 350 epochs\n",
    "                - 0.968 acc\n",
    "                - 150-200 epochs > stalled\n",
    "                - 0.968 after 350 epochs\n",
    "                - 6 hours\n",
    "            - 014\n",
    "                - 388kpm\n",
    "                - epochs\n",
    "                - 0.974 after 243 epochs\n",
    "            - xxx not saved\n",
    "                - 500kpm\n",
    "                - 143 epochs\n",
    "                - 0.972\n",
    "                - slightly worse performance than 014, possibly slower to converge, but taking to long to train\n",
    "            - 016\n",
    "                - 10kpm\n",
    "                - 500 epochs\n",
    "                - 0.91 acc\n",
    "            - 01\n",
    "                - \n",
    "        - Results\n",
    "            - 014 is best, 005 probably good enough\n",
    "            - 017 is best for fast training, maybe?\n",
    "            \n",
    "    - Measure kpm and batch size effect on calc speed\n",
    "        - not much difference\n",
    "            - #016:0.913  10kpm 2048:30                  8192:23:38% 32768:17:52% \n",
    "            - #005:0.952  50kpm 2048:37s    4096:28:50% \n",
    "                - 0.94 after 100epoch = 3000s ~ 1 hour \n",
    "            - #013:0.968 188kpm 2048:50s    4096:40s:61%             32768:46s:80% 65536:42s:99% \n",
    "                - 0.96 after 50 epoch = 41m\n",
    "            - #014:0.974 388kpm 2048:3m:91%\n",
    "                - 0.97 after 60 epoch =180m\n",
    "            \n",
    "    - Test effect of bigger batch size\n",
    "        - Faster calculations, but much worse performance\n",
    "            - see 017 and 018\n",
    "            \n",
    "    - Try smaller batch size\n",
    "        - source 014\n",
    "            - 2048 batch size\n",
    "        - dest\n",
    "            - 256 bs\n",
    "        -Results\n",
    "            - started to forget, \n",
    "            \n",
    "     - Test if increased training after validation lággildi is doing any good\n",
    "         - 022 = 388 kpm\n",
    "         - Laggildi at 70 epochs, accuracy 0.970\n",
    "         - Trained up to 250 epochs, accuracy 0.972\n",
    "         - Results\n",
    "             - it's no use to train after the 70 epoch mark\n",
    "     \n",
    "     - Do transfer learning\n",
    "         - Decide whats the best net\n",
    "            - 188kpm from #013, stalled at 60 epoch 4pc. 41m for 60 epochs.\n",
    "                - 2x32-2x64-2x128-2x160-2x256\n",
    "         - Train on 3pc\n",
    "             - 024:0.998\n",
    "         - Transfer to 4pc\n",
    "             - 026:\n",
    "         - Train 4pc from scratch\n",
    "         \n",
    "         - How to transfer only n layers\n",
    "         - How to freeze layers\n",
    "         - Do n-transfer with and without freeze\n",
    "             - Save tensorboard logs\n",
    "             - Save results\n",
    "             - Save best performance\n",
    "             - Use average of m runs (add average later...)\n",
    "     \n",
    "     \n",
    "     \n",
    "     \n",
    "     \n",
    "     \n",
    "     \n",
    "     - Test if increased training after validation lággildi is doing any good\n",
    "         - Same test as above, but with smaller net (188 kpm which is MUCH faster to train)\n",
    "             - Train both with early stopping and without, and see where it stops\n",
    "                 - keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0,\n",
    "                   patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    - Do tree fold testing on 014, and focus on lággildi in loss at 50epochs\n",
    "    \n",
    "    - Transfer learning\n",
    "        - Read article again\n",
    "        - Make function for measurements\n",
    "            - Copy on n first layers\n",
    "            - freeze layers\n",
    "            - Average\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "    - Test Checkpoints feature\n",
    "    \n",
    "    - Three fold splitting\n",
    "        - model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)\n",
    "        - https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test\n",
    "        \n",
    "    - cross validation\n",
    "        - https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "        \n",
    "    - Train longer....\n",
    "\n",
    "    - Try opther optimizers\n",
    "\n",
    "    - Make histogram of WDL values\n",
    "    \n",
    "    - Do TL experiment\n",
    "        - Take into account data split effect on TL (split 4pc at x, and then transfer to 5pc)\n",
    "        - Three split data, training, validation and testing\n",
    "        - Results\n",
    "        \n",
    "    - Finish 5pc dataset\n",
    "\n",
    "\n",
    "\n",
    "# WDL score count\n",
    "#### 3PKk-WDL-Seq\n",
    "[0, 0, 125024, 0, 124960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#\n",
    "#    PARAMETERS \n",
    "#\n",
    "##############################\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "# What data to use\n",
    "tableBase = '4PpKk'\n",
    "convertStates = False\n",
    "fractionOfDataToUse = 1 # [0,1]\n",
    "\n",
    "# Transfer Learning\n",
    "loadWeights = False \n",
    "weightsSource = '012'\n",
    "\n",
    "# Save results\n",
    "saveResults = True\n",
    "\n",
    "# Compare with other result during training\n",
    "compareResultsDuringTraining = True\n",
    "compareWith = '005' # orginal net structure, trained from random on 4pc dataset\n",
    "\n",
    "\n",
    "# NN parameters\n",
    "useBatchNorm = False\n",
    "filters = [8,16,32,64,128]\n",
    "filterShape = [2,2,2,2,2]\n",
    "batch_size = 4096\n",
    "epochs = 500\n",
    "multiGPU = False\n",
    "whichGPU = 0\n",
    "# optimizer = 'Adam'\n",
    "optimizer = 'Adadelta'\n",
    "\n",
    "\n",
    "\n",
    "### NO NEED TO MODIFY BELOW ###\n",
    "# Generate dataset variables\n",
    "fileName = tableBase + '.hdf5'\n",
    "dataSetName = tableBase + '_onlyLegal'\n",
    "if not convertStates: \n",
    "    dataSetName = tableBase + '_onlyLegal_fullState'\n",
    "dataSetWdlName = tableBase + '_Wdl_onlyLegal'\n",
    "\n",
    "# Number of Pieces\n",
    "nPi =  int(dataSetName[0])\n",
    "nPa = nPi - 2\n",
    "nWPa = math.ceil(nPa/2)\n",
    "\n",
    "# Other NN stuff\n",
    "num_classes = 5\n",
    "input_shape = (4,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#\n",
    "#    IMPORTS \n",
    "#\n",
    "##############################\n",
    "\n",
    "# ### To select which GPU to use, import these before importing Keras or Tensorflow\n",
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# # The GPU id to use, usually either &quot;0&quot; or &quot;1&quot;\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  \n",
    " \n",
    "# # Do other imports now...\n",
    "\n",
    "import os\n",
    "    \n",
    "if(multiGPU):\n",
    "    from keras.utils.training_utils import multi_gpu_model\n",
    "else:\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    # The GPU id to use, usually either \"0\" or \"1\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(whichGPU)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# from __future__ import print_function\n",
    "import keras\n",
    "# from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "from keras import backend as K\n",
    "# import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#Tensorboard\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "# Weight Checkpoints\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#\n",
    "#    Misc Functions\n",
    "#\n",
    "##############################\n",
    "\n",
    "def loadWeightsReturnModel(model, resultNr):\n",
    "    model.load_weights('Results/' + resultNr + '/weights.hdf5')\n",
    "    return model\n",
    "    \n",
    "def createDir(dir):\n",
    "    if os.path.exists(dir):\n",
    "        if confirmDirOverwrite:\n",
    "            a = input(\"Error, directory \" + str(dir) + \" already exists, continue? [y/n] \")\n",
    "            if a[0] == \"y\" or a[0] == \"Y\":\n",
    "                pass\n",
    "            else:\n",
    "                sys.exit()\n",
    "    else:\n",
    "        os.makedirs(dir)\n",
    "        \n",
    "def save_obj(saveDir, saveName, obj ):\n",
    "    if not os.path.exists(saveDir):\n",
    "        os.makedirs(saveDir)\n",
    "    with open(saveDir + '/' + saveName + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(dir, fileName ):\n",
    "    with open(dir + '/' + fileName + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "# compareResultsDuringTraining = True\n",
    "# compareWith = '005'\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Reshape input vector to fit on graph\n",
    "        def reshapeVector(vec):\n",
    "            l = len(vec)\n",
    "            L = epochs - l\n",
    "            if L>=0:\n",
    "                tail = np.ones((L), dtype = int) * vec[-1]\n",
    "                vec = np.hstack((vec,tail))\n",
    "            return vec\n",
    "                \n",
    "        \n",
    "        # Load data to compare with \n",
    "        if compareResultsDuringTraining:\n",
    "            self.compareData = load_obj('Results/' + compareWith, 'fitHistory')\n",
    "            self.compAcc = reshapeVector(self.compareData['acc'])\n",
    "            self.compValAcc = reshapeVector(self.compareData['val_acc'])\n",
    "            self.compLoss = reshapeVector(self.compareData['loss'])\n",
    "            self.compValLoss = reshapeVector(self.compareData['val_loss'])\n",
    "        \n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "        self.fig = plt.figure()\n",
    "        self.logs = {'acc':[], 'val_acc':[], 'loss':[], 'val_loss':[]}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.x.append(self.i)\n",
    "        self.loss.append(logs['loss'])\n",
    "        self.val_loss.append(logs['val_loss'])\n",
    "        self.acc.append(logs['acc'])\n",
    "        self.val_acc.append(logs['val_acc'])\n",
    "        self.logs = {'acc':self.acc, 'val_acc':self.val_acc, 'loss':self.loss, 'val_loss':self.val_loss}\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "    \n",
    "        # Create plots\n",
    "        f = plt.figure(figsize=(15,7))\n",
    "        ax = f.add_subplot(121)\n",
    "        ax2 = f.add_subplot(122)\n",
    "        \n",
    "        \n",
    "        # Plot Loss \n",
    "        ax.plot(self.x, self.loss, color='blue', label=\"Train\", linewidth = 1)\n",
    "        ax.plot(self.x, self.val_loss, color='deepskyblue', label=\"Validation\", linewidth = 1)\n",
    "        if compareResultsDuringTraining:\n",
    "            ax.plot(self.x, self.compLoss[:len(self.loss)], color='black', label=compareWith + \" Training\", linewidth = 1)\n",
    "            ax.plot(self.x, self.compValLoss[:len(self.loss)], color='gray', label=compareWith + \" Validation\", linewidth = 1)\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.legend()\n",
    "        ax.set_ylim(bottom=0)\n",
    "        ax.grid(True)\n",
    "        \n",
    "#         # Plot Accuracy\n",
    "        ax2.plot(self.x, self.acc, 'b-', label=\"Train\", linewidth = 1)\n",
    "        ax2.plot(self.x, self.val_acc, color = 'deepskyblue', label=\"Validation\", linewidth = 1)\n",
    "        if compareResultsDuringTraining:\n",
    "            ax2.plot(self.x, self.compAcc[:len(self.acc)], color='black', label=compareWith + \" Training\", linewidth = 1)\n",
    "            ax2.plot(self.x, self.compValAcc[:len(self.acc)], color='silver', label=compareWith + \" Validation\", linewidth = 1)\n",
    "        ax.set\n",
    "        ax2.set_xlabel('Epochs')\n",
    "        ax2.set_ylabel('Accuracty')\n",
    "        ax2.legend()\n",
    "        ax2.set_ylim(top=1)\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        # Show and save plot\n",
    "# #         plt.tight_layout()\n",
    "        plt.savefig('fitTemp/currentAccAndLoss')\n",
    "        plt.show();\n",
    "\n",
    "#         # Plot Loss\n",
    "#         plt.subplot(1,2,1)\n",
    "#         plt.figure(figsize=(8,8))\n",
    "#         plt.plot(self.x, self.loss, 'b-', label=\"Train\", linewidth = 1)\n",
    "#         plt.plot(self.x, self.val_loss, 'r-', label=\"Validation\", linewidth = 1)\n",
    "#         plt.plot(self.x, self.compLoss[:len(self.loss)], 'b--', label=compareWith + \" Training\")\n",
    "#         plt.plot(self.x, self.compValLoss[:len(self.loss)], 'r--', label=compareWith + \" Validation\")\n",
    "#         plt.xlabel('Epochs')\n",
    "#         plt.ylabel('Loss')\n",
    "#         plt.legend()\n",
    "#         plt.ylim(bottom=0)\n",
    "#         plt.grid(True)\n",
    "# #         plt.savefig('fitTemp/currentLoss')\n",
    "# #         plt.show();\n",
    "        \n",
    "#         # Plot Accuracy\n",
    "#         plt.subplot(1,2,2)\n",
    "#         plt.figure(figsize=(8,8))\n",
    "#         plt.plot(self.x, self.acc, 'b-', label=\"Train\", linewidth = 1)\n",
    "#         plt.plot(self.x, self.val_acc, 'r-', label=\"Validation\", linewidth = 1)\n",
    "#         plt.plot(self.x, self.compAcc[:len(self.acc)], 'b--', label=compareWith + \" Training\")\n",
    "#         plt.plot(self.x, self.compValAcc[:len(self.acc)], 'r--', label=compareWith + \" Validation\")\n",
    "#         plt.xlabel('Epochs')\n",
    "#         plt.ylabel('Accuracty')\n",
    "#         plt.legend()\n",
    "#         plt.ylim(top=1)\n",
    "#         plt.grid(True)\n",
    "        \n",
    "#         # Show and save plot\n",
    "# #         plt.tight_layout()\n",
    "# #         plt.savefig('fitTemp/currentAccAndLoss')\n",
    "#         plt.show();\n",
    "        \n",
    "        print(\"Train Accuracy of last epoch: \", logs['acc'])\n",
    "        print(\"Validation Accuracy of last epoch: \", logs['val_acc'])\n",
    "        print(\"Train Loss of last epoch: \", logs['loss'])\n",
    "        print(\"Validation Loss of last epoch: \", logs['val_loss'])\n",
    "        \n",
    "        with open('fitTemp/logs.txt','w') as file:\n",
    "            file.write(str(self.logs))\n",
    "            \n",
    "        with open('fitTemp/atEpochNr.txt','w') as file:\n",
    "            file.write(str(epoch))\n",
    "        \n",
    "plot_losses = PlotLosses()\n",
    "\n",
    "def sq2hnit(sq):\n",
    "    col = sq%8\n",
    "    row = (sq - col)//8\n",
    "    return col,row\n",
    "\n",
    "# 0: pawns\n",
    "# 1: kings\n",
    "def vecSt2fullSt(vecSt, nPi, nPa, nWPa):\n",
    "    fullSt = np.zeros((4,8,8), dtype = 'bool')\n",
    "    for i in range(nPi - 2):\n",
    "        sq = vecSt[i]\n",
    "        col,row = sq2hnit(sq)\n",
    "        if i < nWPa:\n",
    "            fullSt[0][row][col] = True\n",
    "        else:\n",
    "            fullSt[1][row][col] = True\n",
    "    col,row = sq2hnit(vecSt[-2])\n",
    "    fullSt[2][row][col] = True\n",
    "    col,row = sq2hnit(vecSt[-1])\n",
    "    fullSt[3][row][col] = True\n",
    "    return fullSt \n",
    "\n",
    "def vecSt2fullSt_8x8x2(vecSt, nPi, nPa, nWPa):\n",
    "    fullSt = np.zeros((8,8,2), dtype = 'int8')\n",
    "    for i in range(nPi - 2):\n",
    "        sq = vecSt[i]\n",
    "        col,row = sq2hnit(sq)\n",
    "        if i < nWPa:\n",
    "            fullSt[row][col][0] = 1\n",
    "        else:\n",
    "            fullSt[row][col][0] = -1\n",
    "    col,row = sq2hnit(vecSt[-2])\n",
    "    fullSt[row][col][1] = 1\n",
    "    col,row = sq2hnit(vecSt[-1])\n",
    "    fullSt[row][col][1] = -1\n",
    "    return fullSt \n",
    "\n",
    "# count nr of each score instance\n",
    "# wdlCounter placeholders: [-2, -1, 0, 1 ,2]\n",
    "\n",
    "def wdlCountingMachine(ds):\n",
    "    wdlCounter = [0,0,0,0,0]\n",
    "    l = len(ds)\n",
    "    i = 0\n",
    "    intv = l//100\n",
    "    for wdl in ds:\n",
    "        i += 1\n",
    "        if i%intv == 0:\n",
    "            sys.stdout.write(str((i*100)//l) + \" percentage\")\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.flush()\n",
    "        wdlCounter[wdl[0] + 2] += 1\n",
    "    print(wdlCounter)\n",
    "    return wdlCounter\n",
    "# wdlCountingMachine(d3t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#\n",
    "#    LOAD DATA\n",
    "#\n",
    "##############################\n",
    "# load datasets\n",
    "def loadData(randomState = 42):\n",
    "    with h5py.File(fileName, 'r') as f:\n",
    "        d = f[dataSetName]\n",
    "        dt = f[dataSetWdlName]\n",
    "        l = len(d)\n",
    "        loadLength = int(l * fractionOfDataToUse)\n",
    "\n",
    "        if convertStates:\n",
    "            X = np.array([vecSt2fullSt(vecSt,nPi, nPa, nWPa) for vecSt in d[:loadLength]])\n",
    "        else:\n",
    "            X = d[:loadLength]\n",
    "\n",
    "        y = dt[:loadLength]\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=randomState)\n",
    "\n",
    "    del X\n",
    "    del y\n",
    "\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print('y_train shape:', y_train.shape)\n",
    "    print('X_test shape:', X_test.shape)\n",
    "    print('y_test shape:', y_test.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#X_train, X_test, y_train, y_test = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#\n",
    "#    CREATE MODEL\n",
    "#\n",
    "##############################\n",
    "def createModel(filters, filterShape, loadWeights = False, weightsSource = None):\n",
    "    # import keras.backend as K\n",
    "    # K.set_floatx('float16')\n",
    "    # K.set_epsilon(1e-4) #default is 1e-7\n",
    "    # K.set_floatx('float32')\n",
    "    # K.set_epsilon(1e-7) #default is 1e-7\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    nnStr = ''\n",
    "    for i in range(len(filters)):\n",
    "        s = str(filterShape[i])\n",
    "        filter = str(filters[i])\n",
    "        nnStr += s + 'x' + filter + '-'\n",
    "    nnStr = nnStr[:-1]\n",
    "\n",
    "    assert (len(filters) == len(filterShape)),\"Error, len(filters) != len(filterShape)\"\n",
    "    if useBatchNorm:\n",
    "        for i in range(len(filters)):\n",
    "            if i  == 0:\n",
    "                model.add(Conv2D(filters[i], kernel_size=(filterShape[i], filterShape[i]),\n",
    "                                 padding='valid',\n",
    "                                 data_format = \"channels_first\",\n",
    "                                 use_bias = False,\n",
    "                #                  kernel_initializer = \n",
    "                                 input_shape=input_shape))\n",
    "            else:\n",
    "                model.add(Conv2D(filters[i], kernel_size=(filterShape[i], filterShape[i]),\n",
    "                                 use_bias = False,\n",
    "                                 padding='valid'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation(\"relu\"))\n",
    "    else:\n",
    "        for i in range(len(filters)):\n",
    "            if i  == 0:\n",
    "                model.add(Conv2D(filters[i], kernel_size=(filterShape[i], filterShape[i]),\n",
    "                                 padding='valid',\n",
    "                                 activation='relu',\n",
    "                                 data_format = \"channels_first\",\n",
    "    #                              kernel_initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0, seed=None),\n",
    "                                 input_shape=input_shape))\n",
    "            else:\n",
    "                model.add(Conv2D(filters[i], kernel_size=(filterShape[i], filterShape[i]),\n",
    "                                 padding='valid',\n",
    "    #                              kernel_initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0, seed=None),\n",
    "                                 activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    if multiGPU: \n",
    "        model = keras.utils.multi_gpu_model(model, gpus=2)\n",
    "    model.summary()\n",
    "    \n",
    "    if loadWeights:\n",
    "        model.load_weights('Results/' + weightsSource + '/weights.hdf5')\n",
    "\n",
    "\n",
    "    if optimizer == \"Adadelta\":\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adadelta(),\n",
    "                      metrics=['accuracy'])\n",
    "    elif optimizer == 'Adam':\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "                      metrics=['accuracy'])\n",
    "    else:\n",
    "        sys.exit(\"Error, invalid optimizer.\")\n",
    "        \n",
    "#     tensorboard = TensorBoard(log_dir=\"logs{}\".format(time()))\n",
    "#     return model, nnStr, tensorboard\n",
    "    return model, nnStr\n",
    "\n",
    "#filters = [8,32,64,128,256]\n",
    "#filterShape = [2,2,2,2,2]\n",
    "#model = createModel(filters, filterShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#\n",
    "#    TRAIN MODEL\n",
    "#\n",
    "##############################\n",
    "def trainModel():\n",
    "    with open('Results/lastFitId.txt','r') as file:\n",
    "        lastId = file.read()\n",
    "    fitId = str(int(lastId) + 1).zfill(3)\n",
    "    # save weight checkpoint\n",
    "    saveWeigthPath = \"Results/\" + fitId + '/weightsCheckpoints/'\n",
    "    createDir(saveWeigthPath)\n",
    "    filepath = saveWeigthPath + \"weights-improvement-{epoch:02d}-{val_acc:.3f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    fitHistory = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              callbacks=[checkpoint, \n",
    "                         plot_losses, \n",
    "                         keras.callbacks.TensorBoard(log_dir='./logs/{}-{}'.format(fitId, time()))],\n",
    "              validation_data=(X_test, y_test))\n",
    "    return fitHistory\n",
    "#fitHistory = trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#\n",
    "#    CALCULATE SCORE\n",
    "#\n",
    "##############################\n",
    "def calcScore():\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Evaluated test loss:', score[0])\n",
    "    print('Evaluated test accuracy:', score[1])\n",
    "    return score\n",
    "#score = calcScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#\n",
    "#    SAVE RESULTS\n",
    "#\n",
    "##############################\n",
    "def saveTrainResults():\n",
    "    #Get next fitID\n",
    "    with open('Results/lastFitId.txt','r') as file:\n",
    "        lastId = file.read()\n",
    "    fitId = str(int(lastId) + 1).zfill(3)\n",
    "\n",
    "    # Generate save dir\n",
    "    saveDir = 'Results/' + str(fitId)\n",
    "    print('Save dir: ' + saveDir)\n",
    "    print(\"Creating save dir\")\n",
    "    createDir(saveDir)\n",
    "\n",
    "    # Save info directories\n",
    "    ep = len(model.history.history['acc'])\n",
    "    if loadWeights:\n",
    "        initWeightsId = weightsSource\n",
    "    else:\n",
    "        initWeightsId = 'RND'\n",
    "    createDir(saveDir + '/_' +  '1.numberOfPieces-------' + str(nPi)) \n",
    "    createDir(saveDir + '/_' +  '2.neuralNetStructure---' + str(nnStr) )\n",
    "    createDir(saveDir + '/_' +  '3.loadedWeightsFrom----' +  str(initWeightsId) )\n",
    "    createDir(saveDir + '/_' +  '4.epochs---------------' +  str(ep) + '_of_' + str(epochs) )\n",
    "    createDir(saveDir + '/_' +  '5.batchSize------------' +  str(batch_size) )\n",
    "    createDir(saveDir + '/_' +  '6.optimizer------------' +  str(optimizer) )\n",
    "    createDir(saveDir + '/_' +  '7.finalAccuracy--------' +  str(round(score[1],3)))\n",
    "\n",
    "    #save history\n",
    "    print(\"Saving history...\")\n",
    "    hist = model.history.history\n",
    "    saveName = 'fitHistory'\n",
    "    save_obj(saveDir, saveName, hist)\n",
    "\n",
    "    #save weights\n",
    "    print(\"Saving weights...\")\n",
    "    model.save_weights(saveDir + '/' + 'weights.hdf5')\n",
    "\n",
    "    #save figures\n",
    "    print(\"Saving figures...\")\n",
    "    acc = hist['acc']\n",
    "    loss = hist['loss']\n",
    "    val_acc = hist['val_acc']\n",
    "    val_loss = hist['val_loss']\n",
    "    x = [i for i in range(len(acc))]\n",
    "\n",
    "    # Create plots\n",
    "    f = plt.figure(figsize=(15,7))\n",
    "    ax = f.add_subplot(121)\n",
    "    ax2 = f.add_subplot(122)\n",
    "\n",
    "    # Plot Loss \n",
    "    ax.plot(x, loss, color='blue', label=\"Train\", linewidth = 1)\n",
    "    ax.plot(x, val_loss, color='deepskyblue', label=\"Validation\", linewidth = 1)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Plot Accuracy\n",
    "    ax2.plot(x, acc, 'b-', label=\"Train\", linewidth = 1)\n",
    "    ax2.plot(x, val_acc, color = 'deepskyblue', label=\"Validation\", linewidth = 1)\n",
    "    ax.set\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracty')\n",
    "    ax2.legend()\n",
    "    ax2.set_ylim(top=1)\n",
    "    ax2.grid(True)\n",
    "\n",
    "    # Save plots\n",
    "    plt.savefig(saveDir + '/performance')\n",
    "    plt.show();\n",
    "\n",
    "    #save summary\n",
    "    print(\"Saving summary...\")\n",
    "    from contextlib import redirect_stdout\n",
    "\n",
    "    with open(saveDir + '/modelsummary.txt', 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            model.summary()\n",
    "            \n",
    "    with open('Results/lastFitId.txt','w') as file:\n",
    "        file.write(fitId)\n",
    "    print(\"All done!\")\n",
    "#saveTrainResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#\n",
    "#    COMPARE RESULTS\n",
    "#\n",
    "##############################\n",
    "def compareResults(res1, res2, label1 = '', label2 = '', metric1 = 'acc', metric2 = 'acc', saveFigName = '', makeEqual = False):\n",
    "    # Reshape input vector to fit on graph\n",
    "    def makeEqualLength(vec1, vec2):\n",
    "        l1 = len(vec1)\n",
    "        l2 = len(vec2)\n",
    "        if l1 == l2:\n",
    "             pass\n",
    "        elif l1 > l2: \n",
    "            l = l1 - l2\n",
    "            tail = np.ones((l), dtype = int) * vec2[-1]\n",
    "            vec2 = np.hstack((vec2,tail))\n",
    "        else:\n",
    "            l = l2 - l1\n",
    "            tail = np.ones((l), dtype = int) * vec1[-1]\n",
    "            vec1 = np.hstack((vec1,tail))\n",
    "        return vec1, vec2\n",
    "     \n",
    "    y1 = load_obj('Results/' + res1,'fitHistory')\n",
    "    y2 = load_obj('Results/' + res2,'fitHistory')\n",
    "    acc1 = y1[metric1]\n",
    "    acc2 = y2[metric2]\n",
    "    \n",
    "    if makeEqual:\n",
    "        acc1, acc2 = makeEqualLength(acc1, acc2)\n",
    "    \n",
    "    if label1 == '' :\n",
    "        label1 = res1\n",
    "    if label2 == '' :\n",
    "        label2 = res2\n",
    "        \n",
    "    bottom, top = plt.ylim()  # return the current ylim\n",
    "    if \"acc\" in metric1:\n",
    "        print('plotting accuracy')\n",
    "        yname = \"Accuracy\"\n",
    "        plt.ylim(bottom = bottom, top=1)\n",
    "    else:\n",
    "        print('plotting loss')\n",
    "        plt.ylim(bottom = 0, top=top)\n",
    "        yname = \"Loss\"\n",
    "    \n",
    "    x = [i for i in range(len(acc1))]\n",
    "    plt.plot(x,acc1, label = label1)\n",
    "    x = [i for i in range(len(acc2))]\n",
    "    plt.plot(x,acc2, label = label2)\n",
    "    bottom, top = plt.ylim()  # return the current ylim\n",
    "    if \"acc\" in metric1:\n",
    "        print('plotting accuracy')\n",
    "        yname = \"Accuracy\"\n",
    "        plt.ylim(bottom = bottom, top=1)\n",
    "    else:\n",
    "        print('plotting loss')\n",
    "        plt.ylim(bottom = 0, top=top)\n",
    "        yname = \"Loss\"\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(yname)\n",
    "    plt.legend()\n",
    "    if saveFigName != '': plt.savefig(saveFigName)\n",
    "    plt.show()\n",
    "\n",
    "#compareResults('005','011', label1='test1', label2='test2', metric1='loss', metric2='loss', saveFigName = 'testmynd', makeEqual = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING TEMPLATE CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 8, 7, 7)           136       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 6, 16)          464       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 5, 16)          1040      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 5, 4, 32)          2080      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 3, 32)          4128      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1925      \n",
      "=================================================================\n",
      "Total params: 9,773\n",
      "Trainable params: 9,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "X_train shape: (4982178, 4, 8, 8)\n",
      "y_train shape: (4982178, 1)\n",
      "X_test shape: (2453910, 4, 8, 8)\n",
      "y_test shape: (2453910, 1)\n",
      "4982178 train samples\n",
      "2453910 test samples\n",
      "Train on 4982178 samples, validate on 2453910 samples\n",
      "Epoch 1/500\n",
      " 544768/4982178 [==>...........................] - ETA: 29s - loss: 0.8784 - acc: 0.5901"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f2347d4270aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mfitHistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e1290a318e54>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mcustom_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./logs/{}-{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m               validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfitHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#fitHistory = trainModel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TRAINING TEMPLATE CODE\n",
    "import math\n",
    "\n",
    "# What data to use\n",
    "tableBase = '4PpKk'\n",
    "convertStates = False\n",
    "fractionOfDataToUse = 1 # [0,1]\n",
    "\n",
    "# Transfer Learning\n",
    "loadWeights = False \n",
    "weightsSource = '014'\n",
    "\n",
    "# Compare with other result during training\n",
    "compareResultsDuringTraining = True\n",
    "compareWith = '014' # orginal net structure, trained from random on 4pc dataset\n",
    "\n",
    "\n",
    "# NN parameters\n",
    "filters = [8,16,16,32,32]\n",
    "filterShape = [2,2,2,2,2]\n",
    "batch_size = 2048\n",
    "epochs = 500 \n",
    "\n",
    "# Other paramters\n",
    "confirmDirOverwrite = False\n",
    "\n",
    "model, nnStr = createModel(filters, filterShape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = loadData()\n",
    "\n",
    "fitHistory = trainModel()\n",
    "\n",
    "score = calcScore()\n",
    "\n",
    "saveTrainResults()\n",
    "\n",
    "compareResults('005','013', metric1='acc', metric2='acc', saveFigName = 'testmynd', makeEqual = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO test 70 epoch notch of 188kpm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 8, 7, 7)           136       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 7, 6, 32)          928       \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 6, 5, 64)          8256      \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 5, 4, 128)         32896     \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 4, 3, 256)         131328    \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 15365     \n",
      "=================================================================\n",
      "Total params: 188,909\n",
      "Trainable params: 188,909\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "X_train shape: (49821, 4, 8, 8)\n",
      "y_train shape: (49821, 1)\n",
      "X_test shape: (24539, 4, 8, 8)\n",
      "y_test shape: (24539, 1)\n",
      "49821 train samples\n",
      "24539 test samples\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# What data to use\n",
    "tableBase = '4PpKk'\n",
    "convertStates = False\n",
    "fractionOfDataToUse = 0.01 # [0,1]\n",
    "\n",
    "# Transfer Learning\n",
    "loadWeights = False \n",
    "weightsSource = '014'\n",
    "\n",
    "# Compare with other result during training\n",
    "compareResultsDuringTraining = True\n",
    "compareWith = '014'\n",
    "\n",
    "\n",
    "# NN parameters\n",
    "# filters = [8,16,16,32,32]    #016:0.913  10kpm 2048:30                  8192:23:38% 32768:17:52% \n",
    "# filters = [8,16,32,64,128]   #005:0.952  50kpm 2048:37s    4096:28:50% \n",
    "filters = [8,32,64,128,256]  #013:0.968 188kpm 2048:50s    4096:40s:61%             32768:46s:80% 65536:42s:99% \n",
    "# filters = [32,64,128,160,256]#014:0.974 388kpm 2048:3m:91% \n",
    "filterShape = [2,2,2,2,2]\n",
    "batch_size = 2048\n",
    "epochs = 10 \n",
    "\n",
    "model, nnStr = createModel(filters, filterShape)\n",
    "X_train, X_test, y_train, y_test = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of last epoch:  0.7095602256447632\n",
      "Validation Accuracy of last epoch:  0.7091976049438102\n",
      "Train Loss of last epoch:  0.6636543754031439\n",
      "Validation Loss of last epoch:  0.6618899171663004\n",
      "24539/24539 [==============================] - 1s 47us/step\n",
      "Evaluated test loss: 0.6618899029203555\n",
      "Evaluated test accuracy: 0.7091976037949046\n",
      "Save dir: Results/023\n",
      "Creating save dir\n",
      "Saving history...\n",
      "Saving weights...\n",
      "Saving figures...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving summary...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "fitHistory = trainModel()\n",
    "score = calcScore()\n",
    "saveTrainResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Results/022/weights_70epochs.hdf5')\n",
    "score = calcScore()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('Results/022/weights.hdf5')\n",
    "score = calcScore()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 3PC on 188kpm net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **train on 3pc**\n",
    "2. transfer to 4pc\n",
    "3. train 4pc from start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING TEMPLATE CODE\n",
    "import math\n",
    "\n",
    "# What data to use\n",
    "tableBase = '3PKk'\n",
    "convertStates = True\n",
    "fractionOfDataToUse = 1 # [0,1]\n",
    "\n",
    "# Transfer Learning\n",
    "loadWeights = False \n",
    "weightsSource = '014'\n",
    "\n",
    "# Compare with other result during training\n",
    "compareResultsDuringTraining = False\n",
    "compareWith = '014' # orginal net structure, trained from random on 4pc dataset\n",
    "\n",
    "\n",
    "# NN parameters\n",
    "# filters = [8,16,16,32,32]    #016:0.913  10kpm 2048:30                  8192:23:38% 32768:17:52% \n",
    "# filters = [8,16,32,64,128]   #005:0.952  50kpm 2048:37s    4096:28:50% \n",
    "filters = [8,32,64,128,256]  #013:0.968 188kpm 2048:50s    4096:40s:61%             32768:46s:80% 65536:42s:99% \n",
    "# filters = [32,64,128,160,256]#014:0.974 388kpm 2048:3m:91% \n",
    "filterShape = [2,2,2,2,2]\n",
    "batch_size = 2048\n",
    "epochs = 1000 \n",
    "\n",
    "\n",
    "# Other paramters\n",
    "confirmDirOverwrite = False\n",
    "\n",
    "### NO NEED TO MODIFY BELOW ###\n",
    "# Generate dataset variables\n",
    "fileName = tableBase + '.hdf5'\n",
    "dataSetName = tableBase + '_onlyLegal'\n",
    "if not convertStates: \n",
    "    dataSetName = tableBase + '_onlyLegal_fullState'\n",
    "dataSetWdlName = tableBase + '_Wdl_onlyLegal'\n",
    "\n",
    "# Number of Pieces\n",
    "nPi =  int(dataSetName[0])\n",
    "nPa = nPi - 2\n",
    "nWPa = math.ceil(nPa/2)\n",
    "\n",
    "# Other NN stuff\n",
    "num_classes = 5\n",
    "input_shape = (4,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 8, 7, 7)           136       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 7, 6, 32)          928       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 5, 64)          8256      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 5, 4, 128)         32896     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 3, 256)         131328    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 15365     \n",
      "=================================================================\n",
      "Total params: 188,909\n",
      "Trainable params: 188,909\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "X_train shape: (109429, 4, 8, 8)\n",
      "y_train shape: (109429, 1)\n",
      "X_test shape: (53899, 4, 8, 8)\n",
      "y_test shape: (53899, 1)\n",
      "109429 train samples\n",
      "53899 test samples\n",
      "Error, directory Results/024/weights/ already exists, continue? [y/n] y\n",
      "Train on 109429 samples, validate on 53899 samples\n",
      "Epoch 1/1000\n",
      "109429/109429 [==============================] - 2s 19us/step - loss: 0.6537 - acc: 0.7560 - val_loss: 0.5465 - val_acc: 0.7633\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.76328, saving model to Results/024/weights/weights-improvement-01-0.76.hdf5\n",
      "Epoch 2/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.5197 - acc: 0.7682 - val_loss: 0.4656 - val_acc: 0.7918\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.76328 to 0.79183, saving model to Results/024/weights/weights-improvement-02-0.79.hdf5\n",
      "Epoch 3/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.4376 - acc: 0.7968 - val_loss: 0.4270 - val_acc: 0.8024\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.79183 to 0.80245, saving model to Results/024/weights/weights-improvement-03-0.80.hdf5\n",
      "Epoch 4/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.3922 - acc: 0.8087 - val_loss: 0.3604 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.80245 to 0.81729, saving model to Results/024/weights/weights-improvement-04-0.82.hdf5\n",
      "Epoch 5/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.3536 - acc: 0.8220 - val_loss: 0.3447 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.81729 to 0.81920, saving model to Results/024/weights/weights-improvement-05-0.82.hdf5\n",
      "Epoch 6/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.3182 - acc: 0.8389 - val_loss: 0.3273 - val_acc: 0.8293\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.81920 to 0.82925, saving model to Results/024/weights/weights-improvement-06-0.83.hdf5\n",
      "Epoch 7/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.2769 - acc: 0.8639 - val_loss: 0.2845 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.82925 to 0.85326, saving model to Results/024/weights/weights-improvement-07-0.85.hdf5\n",
      "Epoch 8/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.2531 - acc: 0.8788 - val_loss: 0.2083 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.85326 to 0.90493, saving model to Results/024/weights/weights-improvement-08-0.90.hdf5\n",
      "Epoch 9/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.2059 - acc: 0.9050 - val_loss: 0.2019 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.90493 to 0.90723, saving model to Results/024/weights/weights-improvement-09-0.91.hdf5\n",
      "Epoch 10/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.1858 - acc: 0.9164 - val_loss: 0.1867 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.90723 to 0.91855, saving model to Results/024/weights/weights-improvement-10-0.92.hdf5\n",
      "Epoch 11/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.1666 - acc: 0.9262 - val_loss: 0.1523 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.91855 to 0.93389, saving model to Results/024/weights/weights-improvement-11-0.93.hdf5\n",
      "Epoch 12/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.1559 - acc: 0.9322 - val_loss: 0.1651 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93389\n",
      "Epoch 13/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.1401 - acc: 0.9392 - val_loss: 0.1279 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.93389 to 0.94527, saving model to Results/024/weights/weights-improvement-13-0.95.hdf5\n",
      "Epoch 14/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.1289 - acc: 0.9450 - val_loss: 0.1240 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.94527 to 0.94688, saving model to Results/024/weights/weights-improvement-14-0.95.hdf5\n",
      "Epoch 15/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.1179 - acc: 0.9498 - val_loss: 0.1120 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.94688 to 0.95247, saving model to Results/024/weights/weights-improvement-15-0.95.hdf5\n",
      "Epoch 16/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.1068 - acc: 0.9546 - val_loss: 0.1007 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.95247 to 0.95813, saving model to Results/024/weights/weights-improvement-16-0.96.hdf5\n",
      "Epoch 17/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.1040 - acc: 0.9552 - val_loss: 0.0952 - val_acc: 0.9604\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.95813 to 0.96035, saving model to Results/024/weights/weights-improvement-17-0.96.hdf5\n",
      "Epoch 18/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0952 - acc: 0.9598 - val_loss: 0.0942 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.96035\n",
      "Epoch 19/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0893 - acc: 0.9626 - val_loss: 0.0857 - val_acc: 0.9645\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.96035 to 0.96447, saving model to Results/024/weights/weights-improvement-19-0.96.hdf5\n",
      "Epoch 20/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0840 - acc: 0.9648 - val_loss: 0.0912 - val_acc: 0.9613\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.96447\n",
      "Epoch 21/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0836 - acc: 0.9647 - val_loss: 0.1045 - val_acc: 0.9545\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.96447\n",
      "Epoch 22/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0800 - acc: 0.9664 - val_loss: 0.0971 - val_acc: 0.9579\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.96447\n",
      "Epoch 23/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0763 - acc: 0.9679 - val_loss: 0.0835 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.96447 to 0.96508, saving model to Results/024/weights/weights-improvement-23-0.97.hdf5\n",
      "Epoch 24/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0737 - acc: 0.9684 - val_loss: 0.0702 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.96508 to 0.97026, saving model to Results/024/weights/weights-improvement-24-0.97.hdf5\n",
      "Epoch 25/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0690 - acc: 0.9710 - val_loss: 0.0736 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.97026\n",
      "Epoch 26/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0683 - acc: 0.9708 - val_loss: 0.0843 - val_acc: 0.9645\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97026\n",
      "Epoch 27/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0658 - acc: 0.9724 - val_loss: 0.0698 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.97026\n",
      "Epoch 28/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0656 - acc: 0.9724 - val_loss: 0.0775 - val_acc: 0.9676\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97026\n",
      "Epoch 29/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0613 - acc: 0.9740 - val_loss: 0.0631 - val_acc: 0.9732\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.97026 to 0.97317, saving model to Results/024/weights/weights-improvement-29-0.97.hdf5\n",
      "Epoch 30/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0590 - acc: 0.9758 - val_loss: 0.0635 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97317\n",
      "Epoch 31/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0564 - acc: 0.9766 - val_loss: 0.0877 - val_acc: 0.9635\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97317\n",
      "Epoch 32/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0571 - acc: 0.9760 - val_loss: 0.0684 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97317\n",
      "Epoch 33/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0578 - acc: 0.9760 - val_loss: 0.0731 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.97317\n",
      "Epoch 34/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0532 - acc: 0.9780 - val_loss: 0.0685 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.97317\n",
      "Epoch 35/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0556 - acc: 0.9762 - val_loss: 0.1185 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.97317\n",
      "Epoch 36/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0530 - acc: 0.9779 - val_loss: 0.0913 - val_acc: 0.9608\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.97317\n",
      "Epoch 37/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0471 - acc: 0.9806 - val_loss: 0.0597 - val_acc: 0.9746\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.97317 to 0.97460, saving model to Results/024/weights/weights-improvement-37-0.97.hdf5\n",
      "Epoch 38/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0510 - acc: 0.9790 - val_loss: 0.0602 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.97460 to 0.97503, saving model to Results/024/weights/weights-improvement-38-0.98.hdf5\n",
      "Epoch 39/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0460 - acc: 0.9810 - val_loss: 0.0581 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.97503 to 0.97555, saving model to Results/024/weights/weights-improvement-39-0.98.hdf5\n",
      "Epoch 40/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0445 - acc: 0.9815 - val_loss: 0.0577 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.97555\n",
      "Epoch 41/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0452 - acc: 0.9811 - val_loss: 0.0547 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.97555 to 0.97729, saving model to Results/024/weights/weights-improvement-41-0.98.hdf5\n",
      "Epoch 42/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0484 - acc: 0.9793 - val_loss: 0.0501 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.97729 to 0.97839, saving model to Results/024/weights/weights-improvement-42-0.98.hdf5\n",
      "Epoch 43/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0438 - acc: 0.9820 - val_loss: 0.0515 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.97839\n",
      "Epoch 44/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0419 - acc: 0.9828 - val_loss: 0.0624 - val_acc: 0.9741\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.97839\n",
      "Epoch 45/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0432 - acc: 0.9817 - val_loss: 0.0468 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.97839 to 0.98065, saving model to Results/024/weights/weights-improvement-45-0.98.hdf5\n",
      "Epoch 46/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0416 - acc: 0.9824 - val_loss: 0.0520 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.98065\n",
      "Epoch 47/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0404 - acc: 0.9834 - val_loss: 0.0537 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.98065\n",
      "Epoch 48/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0388 - acc: 0.9841 - val_loss: 0.0540 - val_acc: 0.9772\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.98065\n",
      "Epoch 49/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0384 - acc: 0.9841 - val_loss: 0.0498 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.98065\n",
      "Epoch 50/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0376 - acc: 0.9847 - val_loss: 0.0542 - val_acc: 0.9771\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.98065\n",
      "Epoch 51/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0379 - acc: 0.9845 - val_loss: 0.0506 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.98065\n",
      "Epoch 52/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0354 - acc: 0.9858 - val_loss: 0.0457 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.98065 to 0.98109, saving model to Results/024/weights/weights-improvement-52-0.98.hdf5\n",
      "Epoch 53/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0402 - acc: 0.9835 - val_loss: 0.0527 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.98109\n",
      "Epoch 54/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0340 - acc: 0.9860 - val_loss: 0.0423 - val_acc: 0.9827\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.98109 to 0.98273, saving model to Results/024/weights/weights-improvement-54-0.98.hdf5\n",
      "Epoch 55/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0326 - acc: 0.9868 - val_loss: 0.0612 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.98273\n",
      "Epoch 56/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0355 - acc: 0.9855 - val_loss: 0.0579 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.98273\n",
      "Epoch 57/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0323 - acc: 0.9871 - val_loss: 0.0654 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.98273\n",
      "Epoch 58/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0346 - acc: 0.9858 - val_loss: 0.0420 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.98273\n",
      "Epoch 59/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0311 - acc: 0.9875 - val_loss: 0.0392 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.98273 to 0.98375, saving model to Results/024/weights/weights-improvement-59-0.98.hdf5\n",
      "Epoch 60/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0305 - acc: 0.9877 - val_loss: 0.0473 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.98375\n",
      "Epoch 61/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0301 - acc: 0.9876 - val_loss: 0.0458 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.98375\n",
      "Epoch 62/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0299 - acc: 0.9879 - val_loss: 0.0774 - val_acc: 0.9709\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.98375\n",
      "Epoch 63/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0329 - acc: 0.9870 - val_loss: 0.0487 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.98375\n",
      "Epoch 64/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0279 - acc: 0.9889 - val_loss: 0.0441 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.98375\n",
      "Epoch 65/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0300 - acc: 0.9880 - val_loss: 0.0492 - val_acc: 0.9795\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.98375\n",
      "Epoch 66/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0296 - acc: 0.9878 - val_loss: 0.1060 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.98375\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0291 - acc: 0.9885 - val_loss: 0.0558 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.98375\n",
      "Epoch 68/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0265 - acc: 0.9894 - val_loss: 0.0432 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.98375\n",
      "Epoch 69/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0298 - acc: 0.9877 - val_loss: 0.0451 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.98375\n",
      "Epoch 70/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0258 - acc: 0.9897 - val_loss: 0.0369 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.98375 to 0.98462, saving model to Results/024/weights/weights-improvement-70-0.98.hdf5\n",
      "Epoch 71/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0262 - acc: 0.9898 - val_loss: 0.0421 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.98462\n",
      "Epoch 72/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0243 - acc: 0.9902 - val_loss: 0.0584 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.98462\n",
      "Epoch 73/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0257 - acc: 0.9897 - val_loss: 0.0425 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.98462\n",
      "Epoch 74/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0250 - acc: 0.9900 - val_loss: 0.0426 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.98462\n",
      "Epoch 75/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0249 - acc: 0.9903 - val_loss: 0.0483 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.98462\n",
      "Epoch 76/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0266 - acc: 0.9894 - val_loss: 0.0619 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.98462\n",
      "Epoch 77/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0249 - acc: 0.9903 - val_loss: 0.0385 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.98462\n",
      "Epoch 78/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0215 - acc: 0.9916 - val_loss: 0.0398 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.98462\n",
      "Epoch 79/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0289 - acc: 0.9886 - val_loss: 0.0449 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.98462\n",
      "Epoch 80/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0205 - acc: 0.9920 - val_loss: 0.0429 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.98462\n",
      "Epoch 81/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0232 - acc: 0.9905 - val_loss: 0.0397 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.98462\n",
      "Epoch 82/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0221 - acc: 0.9913 - val_loss: 0.0610 - val_acc: 0.9788\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.98462\n",
      "Epoch 83/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0215 - acc: 0.9918 - val_loss: 0.1079 - val_acc: 0.9688\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.98462\n",
      "Epoch 84/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0236 - acc: 0.9911 - val_loss: 0.0382 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.98462\n",
      "Epoch 85/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0187 - acc: 0.9931 - val_loss: 0.0390 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.98462\n",
      "Epoch 86/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0272 - acc: 0.9898 - val_loss: 0.0605 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.98462\n",
      "Epoch 87/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0199 - acc: 0.9919 - val_loss: 0.0386 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.98462\n",
      "Epoch 88/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0183 - acc: 0.9931 - val_loss: 0.0361 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.98462 to 0.98532, saving model to Results/024/weights/weights-improvement-88-0.99.hdf5\n",
      "Epoch 89/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0203 - acc: 0.9922 - val_loss: 0.0452 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.98532\n",
      "Epoch 90/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0195 - acc: 0.9923 - val_loss: 0.0464 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.98532\n",
      "Epoch 91/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0244 - acc: 0.9904 - val_loss: 0.0415 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.98532\n",
      "Epoch 92/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0190 - acc: 0.9931 - val_loss: 0.0411 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.98532\n",
      "Epoch 93/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0182 - acc: 0.9929 - val_loss: 0.0492 - val_acc: 0.9816\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.98532\n",
      "Epoch 94/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0199 - acc: 0.9923 - val_loss: 0.0601 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.98532\n",
      "Epoch 95/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0218 - acc: 0.9917 - val_loss: 0.0470 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.98532\n",
      "Epoch 96/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0169 - acc: 0.9936 - val_loss: 0.0578 - val_acc: 0.9791\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.98532\n",
      "Epoch 97/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0192 - acc: 0.9924 - val_loss: 0.0417 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.98532\n",
      "Epoch 98/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0180 - acc: 0.9931 - val_loss: 0.0586 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.98532\n",
      "Epoch 99/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0176 - acc: 0.9934 - val_loss: 0.0425 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.98532\n",
      "Epoch 100/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0182 - acc: 0.9928 - val_loss: 0.0362 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.98532 to 0.98609, saving model to Results/024/weights/weights-improvement-100-0.99.hdf5\n",
      "Epoch 101/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0183 - acc: 0.9931 - val_loss: 0.0455 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.98609\n",
      "Epoch 102/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0147 - acc: 0.9943 - val_loss: 0.0381 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.98609\n",
      "Epoch 103/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0172 - acc: 0.9934 - val_loss: 0.0342 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.98609 to 0.98618, saving model to Results/024/weights/weights-improvement-103-0.99.hdf5\n",
      "Epoch 104/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0163 - acc: 0.9937 - val_loss: 0.0455 - val_acc: 0.9828\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.98618\n",
      "Epoch 105/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0246 - acc: 0.9912 - val_loss: 0.0434 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.98618\n",
      "Epoch 106/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0146 - acc: 0.9945 - val_loss: 0.0406 - val_acc: 0.9847\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.98618\n",
      "Epoch 107/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0146 - acc: 0.9945 - val_loss: 0.0384 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.98618\n",
      "Epoch 108/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0157 - acc: 0.9940 - val_loss: 0.0498 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.98618\n",
      "Epoch 109/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0278 - acc: 0.9901 - val_loss: 0.0363 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.98618\n",
      "Epoch 110/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0139 - acc: 0.9950 - val_loss: 0.0359 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.98618\n",
      "Epoch 111/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0181 - acc: 0.9936 - val_loss: 0.0381 - val_acc: 0.9858\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.98618\n",
      "Epoch 112/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0133 - acc: 0.9953 - val_loss: 0.0444 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.98618\n",
      "Epoch 113/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0148 - acc: 0.9943 - val_loss: 0.0359 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.98618 to 0.98625, saving model to Results/024/weights/weights-improvement-113-0.99.hdf5\n",
      "Epoch 114/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0181 - acc: 0.9927 - val_loss: 0.0385 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.98625\n",
      "Epoch 115/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0138 - acc: 0.9947 - val_loss: 0.0336 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.98625 to 0.98699, saving model to Results/024/weights/weights-improvement-115-0.99.hdf5\n",
      "Epoch 116/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0167 - acc: 0.9938 - val_loss: 0.0333 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.98699 to 0.98724, saving model to Results/024/weights/weights-improvement-116-0.99.hdf5\n",
      "Epoch 117/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0128 - acc: 0.9954 - val_loss: 0.0487 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.98724\n",
      "Epoch 118/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0159 - acc: 0.9939 - val_loss: 0.0449 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.98724\n",
      "Epoch 119/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0130 - acc: 0.9952 - val_loss: 0.0341 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.98724 to 0.98737, saving model to Results/024/weights/weights-improvement-119-0.99.hdf5\n",
      "Epoch 120/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0135 - acc: 0.9950 - val_loss: 0.0396 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.98737\n",
      "Epoch 121/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0195 - acc: 0.9926 - val_loss: 0.0371 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.98737\n",
      "Epoch 122/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0130 - acc: 0.9951 - val_loss: 0.0392 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.98737\n",
      "Epoch 123/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0125 - acc: 0.9956 - val_loss: 0.0340 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.98737 to 0.98744, saving model to Results/024/weights/weights-improvement-123-0.99.hdf5\n",
      "Epoch 124/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0130 - acc: 0.9949 - val_loss: 0.0347 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.98744\n",
      "Epoch 125/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0188 - acc: 0.9934 - val_loss: 0.0335 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.98744\n",
      "Epoch 126/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0121 - acc: 0.9954 - val_loss: 0.0343 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.98744 to 0.98748, saving model to Results/024/weights/weights-improvement-126-0.99.hdf5\n",
      "Epoch 127/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0126 - acc: 0.9952 - val_loss: 0.0384 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.98748\n",
      "Epoch 128/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0141 - acc: 0.9946 - val_loss: 0.0356 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.98748\n",
      "Epoch 129/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0199 - acc: 0.9931 - val_loss: 0.0433 - val_acc: 0.9831\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.98748\n",
      "Epoch 130/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0115 - acc: 0.9957 - val_loss: 0.0338 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.98748\n",
      "Epoch 131/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0118 - acc: 0.9954 - val_loss: 0.0351 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.98748\n",
      "Epoch 132/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0169 - acc: 0.9938 - val_loss: 0.0340 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.98748 to 0.98759, saving model to Results/024/weights/weights-improvement-132-0.99.hdf5\n",
      "Epoch 133/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0125 - acc: 0.9953 - val_loss: 0.0349 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00133: val_acc improved from 0.98759 to 0.98787, saving model to Results/024/weights/weights-improvement-133-0.99.hdf5\n",
      "Epoch 134/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0121 - acc: 0.9955 - val_loss: 0.0358 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.98787\n",
      "Epoch 135/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0124 - acc: 0.9953 - val_loss: 0.0373 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.98787\n",
      "Epoch 136/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0127 - acc: 0.9954 - val_loss: 0.0406 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.98787\n",
      "Epoch 137/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0129 - acc: 0.9951 - val_loss: 0.0378 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.98787\n",
      "Epoch 138/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0189 - acc: 0.9933 - val_loss: 0.0356 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.98787\n",
      "Epoch 139/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0111 - acc: 0.9959 - val_loss: 0.0391 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.98787\n",
      "Epoch 140/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0110 - acc: 0.9958 - val_loss: 0.0384 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.98787\n",
      "Epoch 141/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0117 - acc: 0.9955 - val_loss: 0.0342 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.98787\n",
      "Epoch 142/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0114 - acc: 0.9957 - val_loss: 0.0350 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.98787\n",
      "Epoch 143/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0157 - acc: 0.9938 - val_loss: 0.0338 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.98787\n",
      "Epoch 144/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0111 - acc: 0.9959 - val_loss: 0.0402 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.98787\n",
      "Epoch 145/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0116 - acc: 0.9955 - val_loss: 0.0381 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.98787\n",
      "Epoch 146/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0122 - acc: 0.9954 - val_loss: 0.0328 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.98787\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0132 - acc: 0.9949 - val_loss: 0.0377 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.98787\n",
      "Epoch 148/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0111 - acc: 0.9957 - val_loss: 0.0388 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.98787\n",
      "Epoch 149/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0109 - acc: 0.9960 - val_loss: 0.0370 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.98787\n",
      "Epoch 150/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0122 - acc: 0.9953 - val_loss: 0.0431 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.98787\n",
      "Epoch 151/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0216 - acc: 0.9929 - val_loss: 0.0341 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00151: val_acc improved from 0.98787 to 0.98787, saving model to Results/024/weights/weights-improvement-151-0.99.hdf5\n",
      "Epoch 152/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0103 - acc: 0.9962 - val_loss: 0.0338 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.98787 to 0.98796, saving model to Results/024/weights/weights-improvement-152-0.99.hdf5\n",
      "Epoch 153/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0135 - acc: 0.9948 - val_loss: 0.0344 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00153: val_acc improved from 0.98796 to 0.98816, saving model to Results/024/weights/weights-improvement-153-0.99.hdf5\n",
      "Epoch 154/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0103 - acc: 0.9962 - val_loss: 0.0409 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.98816\n",
      "Epoch 155/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0105 - acc: 0.9960 - val_loss: 0.0375 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.98816\n",
      "Epoch 156/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0126 - acc: 0.9949 - val_loss: 0.0326 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.98816 to 0.98827, saving model to Results/024/weights/weights-improvement-156-0.99.hdf5\n",
      "Epoch 157/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0104 - acc: 0.9958 - val_loss: 0.0388 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.98827\n",
      "Epoch 158/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0109 - acc: 0.9958 - val_loss: 0.0435 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.98827\n",
      "Epoch 159/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0123 - acc: 0.9953 - val_loss: 0.0442 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.98827\n",
      "Epoch 160/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0121 - acc: 0.9951 - val_loss: 0.0382 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.98827\n",
      "Epoch 161/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0104 - acc: 0.9960 - val_loss: 0.0468 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.98827\n",
      "Epoch 162/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0108 - acc: 0.9958 - val_loss: 0.0415 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.98827\n",
      "Epoch 163/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0261 - acc: 0.9921 - val_loss: 0.0342 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.98827\n",
      "Epoch 164/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0093 - acc: 0.9965 - val_loss: 0.0349 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.98827\n",
      "Epoch 165/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0096 - acc: 0.9963 - val_loss: 0.0354 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.98827\n",
      "Epoch 166/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0107 - acc: 0.9959 - val_loss: 0.0435 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.98827\n",
      "Epoch 167/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0111 - acc: 0.9956 - val_loss: 0.0364 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.98827\n",
      "Epoch 168/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0104 - acc: 0.9959 - val_loss: 0.0385 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.98827\n",
      "Epoch 169/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0228 - acc: 0.9926 - val_loss: 0.0343 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.98827\n",
      "Epoch 170/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.0344 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.98827\n",
      "Epoch 171/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0094 - acc: 0.9964 - val_loss: 0.0346 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.98827\n",
      "Epoch 172/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0101 - acc: 0.9961 - val_loss: 0.0371 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.98827\n",
      "Epoch 173/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0103 - acc: 0.9961 - val_loss: 0.0359 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.98827\n",
      "Epoch 174/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0101 - acc: 0.9961 - val_loss: 0.0371 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.98827\n",
      "Epoch 175/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0110 - acc: 0.9958 - val_loss: 0.0419 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.98827\n",
      "Epoch 176/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0105 - acc: 0.9959 - val_loss: 0.0396 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.98827\n",
      "Epoch 177/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0226 - acc: 0.9921 - val_loss: 0.0324 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.98827\n",
      "Epoch 178/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0092 - acc: 0.9966 - val_loss: 0.0341 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.98827\n",
      "Epoch 179/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0096 - acc: 0.9962 - val_loss: 0.0347 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.98827\n",
      "Epoch 180/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0091 - acc: 0.9965 - val_loss: 0.0423 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.98827\n",
      "Epoch 181/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0097 - acc: 0.9965 - val_loss: 0.0391 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.98827\n",
      "Epoch 182/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0154 - acc: 0.9947 - val_loss: 0.0352 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.98827\n",
      "Epoch 183/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0087 - acc: 0.9966 - val_loss: 0.0336 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00183: val_acc improved from 0.98827 to 0.98848, saving model to Results/024/weights/weights-improvement-183-0.99.hdf5\n",
      "Epoch 184/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0090 - acc: 0.9964 - val_loss: 0.0424 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.98848\n",
      "Epoch 185/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0101 - acc: 0.9961 - val_loss: 0.0340 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.98848\n",
      "Epoch 186/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0099 - acc: 0.9960 - val_loss: 0.0399 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.98848\n",
      "Epoch 187/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0106 - acc: 0.9958 - val_loss: 0.0522 - val_acc: 0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00187: val_acc did not improve from 0.98848\n",
      "Epoch 188/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0093 - acc: 0.9964 - val_loss: 0.0371 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.98848\n",
      "Epoch 189/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0103 - acc: 0.9960 - val_loss: 0.0496 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.98848\n",
      "Epoch 190/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0269 - acc: 0.9911 - val_loss: 0.0316 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00190: val_acc improved from 0.98848 to 0.98879, saving model to Results/024/weights/weights-improvement-190-0.99.hdf5\n",
      "Epoch 191/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.0346 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.98879\n",
      "Epoch 192/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0090 - acc: 0.9963 - val_loss: 0.0398 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.98879\n",
      "Epoch 193/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0095 - acc: 0.9963 - val_loss: 0.0331 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.98879\n",
      "Epoch 194/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0096 - acc: 0.9962 - val_loss: 0.0345 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.98879\n",
      "Epoch 195/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9966 - val_loss: 0.0338 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00195: val_acc improved from 0.98879 to 0.98902, saving model to Results/024/weights/weights-improvement-195-0.99.hdf5\n",
      "Epoch 196/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0094 - acc: 0.9963 - val_loss: 0.0516 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.98902\n",
      "Epoch 197/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0173 - acc: 0.9940 - val_loss: 0.0339 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.98902\n",
      "Epoch 198/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0089 - acc: 0.9965 - val_loss: 0.0344 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.98902\n",
      "Epoch 199/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9966 - val_loss: 0.0370 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.98902\n",
      "Epoch 200/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0092 - acc: 0.9964 - val_loss: 0.0366 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.98902\n",
      "Epoch 201/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0091 - acc: 0.9963 - val_loss: 0.0485 - val_acc: 0.9849\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.98902\n",
      "Epoch 202/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0099 - acc: 0.9960 - val_loss: 0.0323 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.98902\n",
      "Epoch 203/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.0396 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.98902\n",
      "Epoch 204/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0094 - acc: 0.9962 - val_loss: 0.0362 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.98902\n",
      "Epoch 205/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0241 - acc: 0.9924 - val_loss: 0.0380 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.98902\n",
      "Epoch 206/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0089 - acc: 0.9965 - val_loss: 0.0351 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.98902\n",
      "Epoch 207/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0087 - acc: 0.9966 - val_loss: 0.0356 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.98902\n",
      "Epoch 208/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0092 - acc: 0.9965 - val_loss: 0.0346 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.98902\n",
      "Epoch 209/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0090 - acc: 0.9964 - val_loss: 0.0378 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.98902\n",
      "Epoch 210/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0093 - acc: 0.9963 - val_loss: 0.0406 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.98902\n",
      "Epoch 211/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0086 - acc: 0.9964 - val_loss: 0.0370 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.98902\n",
      "Epoch 212/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0099 - acc: 0.9961 - val_loss: 0.0366 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.98902\n",
      "Epoch 213/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.0357 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.98902\n",
      "Epoch 214/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0090 - acc: 0.9965 - val_loss: 0.0348 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.98902\n",
      "Epoch 215/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0087 - acc: 0.9964 - val_loss: 0.0368 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.98902\n",
      "Epoch 216/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.0430 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.98902\n",
      "Epoch 217/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0118 - acc: 0.9954 - val_loss: 0.0348 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.98902\n",
      "Epoch 218/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0082 - acc: 0.9967 - val_loss: 0.0366 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.98902\n",
      "Epoch 219/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9963 - val_loss: 0.0407 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.98902\n",
      "Epoch 220/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0089 - acc: 0.9963 - val_loss: 0.0408 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.98902\n",
      "Epoch 221/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.0384 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.98902\n",
      "Epoch 222/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0087 - acc: 0.9965 - val_loss: 0.0357 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.98902\n",
      "Epoch 223/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0090 - acc: 0.9964 - val_loss: 0.0370 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.98902\n",
      "Epoch 224/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.0366 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.98902\n",
      "Epoch 225/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.0391 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.98902\n",
      "Epoch 226/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0086 - acc: 0.9965 - val_loss: 0.0389 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.98902\n",
      "Epoch 227/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0374 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.98902\n",
      "Epoch 228/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0091 - acc: 0.9962 - val_loss: 0.0527 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.98902\n",
      "Epoch 229/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0093 - acc: 0.9962 - val_loss: 0.0422 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.98902\n",
      "Epoch 230/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0091 - acc: 0.9965 - val_loss: 0.0371 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.98902\n",
      "Epoch 231/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0084 - acc: 0.9967 - val_loss: 0.0423 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.98902\n",
      "Epoch 232/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0086 - acc: 0.9966 - val_loss: 0.0367 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.98902\n",
      "Epoch 233/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0083 - acc: 0.9966 - val_loss: 0.0395 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.98902\n",
      "Epoch 234/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0083 - acc: 0.9965 - val_loss: 0.0454 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.98902\n",
      "Epoch 235/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0088 - acc: 0.9965 - val_loss: 0.0438 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.98902\n",
      "Epoch 236/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0084 - acc: 0.9966 - val_loss: 0.0401 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.98902\n",
      "Epoch 237/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0083 - acc: 0.9966 - val_loss: 0.0439 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.98902\n",
      "Epoch 238/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0089 - acc: 0.9964 - val_loss: 0.0384 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.98902\n",
      "Epoch 239/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0087 - acc: 0.9964 - val_loss: 0.0415 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.98902\n",
      "Epoch 240/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0087 - acc: 0.9965 - val_loss: 0.0364 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.98902\n",
      "Epoch 241/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0083 - acc: 0.9966 - val_loss: 0.0394 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.98902\n",
      "Epoch 242/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0084 - acc: 0.9966 - val_loss: 0.0406 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.98902\n",
      "Epoch 243/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0086 - acc: 0.9966 - val_loss: 0.0351 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.98902\n",
      "Epoch 244/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0085 - acc: 0.9965 - val_loss: 0.0434 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.98902\n",
      "Epoch 245/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0086 - acc: 0.9964 - val_loss: 0.0468 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.98902\n",
      "Epoch 246/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0158 - acc: 0.9943 - val_loss: 0.0409 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.98902\n",
      "Epoch 247/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0344 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.98902\n",
      "Epoch 248/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0080 - acc: 0.9967 - val_loss: 0.0355 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.98902\n",
      "Epoch 249/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9968 - val_loss: 0.0372 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.98902\n",
      "Epoch 250/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0081 - acc: 0.9969 - val_loss: 0.0374 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.98902\n",
      "Epoch 251/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0084 - acc: 0.9966 - val_loss: 0.0377 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.98902\n",
      "Epoch 252/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0081 - acc: 0.9966 - val_loss: 0.0436 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.98902\n",
      "Epoch 253/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0082 - acc: 0.9967 - val_loss: 0.0414 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.98902\n",
      "Epoch 254/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0231 - acc: 0.9931 - val_loss: 0.0373 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.98902\n",
      "Epoch 255/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 0.0358 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.98902\n",
      "Epoch 256/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9966 - val_loss: 0.0382 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.98902\n",
      "Epoch 257/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0078 - acc: 0.9968 - val_loss: 0.0376 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.98902\n",
      "Epoch 258/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0084 - acc: 0.9965 - val_loss: 0.0346 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.98902\n",
      "Epoch 259/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0388 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.98902\n",
      "Epoch 260/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9969 - val_loss: 0.0342 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.98902\n",
      "Epoch 261/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0083 - acc: 0.9967 - val_loss: 0.0566 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.98902\n",
      "Epoch 262/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0081 - acc: 0.9968 - val_loss: 0.0446 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.98902\n",
      "Epoch 263/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0082 - acc: 0.9966 - val_loss: 0.0358 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.98902\n",
      "Epoch 264/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9969 - val_loss: 0.0393 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.98902\n",
      "Epoch 265/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0083 - acc: 0.9968 - val_loss: 0.0345 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00265: val_acc improved from 0.98902 to 0.98948, saving model to Results/024/weights/weights-improvement-265-0.99.hdf5\n",
      "Epoch 266/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0081 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.98948\n",
      "Epoch 267/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0082 - acc: 0.9967 - val_loss: 0.0380 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.98948\n",
      "Epoch 268/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0081 - acc: 0.9965 - val_loss: 0.0406 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.98948\n",
      "Epoch 269/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0083 - acc: 0.9966 - val_loss: 0.0424 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.98948\n",
      "Epoch 270/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0086 - acc: 0.9966 - val_loss: 0.0557 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.98948\n",
      "Epoch 271/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0078 - acc: 0.9968 - val_loss: 0.0386 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.98948\n",
      "Epoch 272/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0363 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.98948\n",
      "Epoch 273/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0080 - acc: 0.9966 - val_loss: 0.0413 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.98948\n",
      "Epoch 274/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9968 - val_loss: 0.0366 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.98948\n",
      "Epoch 275/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0083 - acc: 0.9966 - val_loss: 0.0407 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.98948\n",
      "Epoch 276/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9970 - val_loss: 0.0422 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.98948\n",
      "Epoch 277/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9970 - val_loss: 0.0379 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.98948\n",
      "Epoch 278/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0080 - acc: 0.9967 - val_loss: 0.0415 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.98948\n",
      "Epoch 279/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0079 - acc: 0.9968 - val_loss: 0.0396 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.98948\n",
      "Epoch 280/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0079 - acc: 0.9966 - val_loss: 0.0370 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.98948\n",
      "Epoch 281/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0080 - acc: 0.9966 - val_loss: 0.0422 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.98948\n",
      "Epoch 282/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0375 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.98948\n",
      "Epoch 283/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0079 - acc: 0.9968 - val_loss: 0.0358 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.98948\n",
      "Epoch 284/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0081 - acc: 0.9966 - val_loss: 0.0441 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.98948\n",
      "Epoch 285/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0079 - acc: 0.9968 - val_loss: 0.0445 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.98948\n",
      "Epoch 286/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0083 - acc: 0.9968 - val_loss: 0.0354 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.98948\n",
      "Epoch 287/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 0.0423 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.98948\n",
      "Epoch 288/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0080 - acc: 0.9968 - val_loss: 0.0394 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.98948\n",
      "Epoch 289/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0358 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.98948\n",
      "Epoch 290/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0369 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.98948\n",
      "Epoch 291/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0080 - acc: 0.9968 - val_loss: 0.0365 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.98948\n",
      "Epoch 292/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0383 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.98948\n",
      "Epoch 293/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0079 - acc: 0.9966 - val_loss: 0.0376 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.98948\n",
      "Epoch 294/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9969 - val_loss: 0.0385 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.98948\n",
      "Epoch 295/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0076 - acc: 0.9968 - val_loss: 0.0373 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.98948\n",
      "Epoch 296/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0164 - acc: 0.9945 - val_loss: 0.0345 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.98948\n",
      "Epoch 297/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0073 - acc: 0.9970 - val_loss: 0.0343 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.98948\n",
      "Epoch 298/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0075 - acc: 0.9968 - val_loss: 0.0390 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.98948\n",
      "Epoch 299/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0403 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.98948\n",
      "Epoch 300/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0076 - acc: 0.9969 - val_loss: 0.0357 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.98948\n",
      "Epoch 301/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9967 - val_loss: 0.0381 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00301: val_acc did not improve from 0.98948\n",
      "Epoch 302/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 0.0382 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00302: val_acc did not improve from 0.98948\n",
      "Epoch 303/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9965 - val_loss: 0.0369 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00303: val_acc did not improve from 0.98948\n",
      "Epoch 304/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0076 - acc: 0.9967 - val_loss: 0.0386 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00304: val_acc did not improve from 0.98948\n",
      "Epoch 305/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9969 - val_loss: 0.0348 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00305: val_acc did not improve from 0.98948\n",
      "Epoch 306/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0341 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00306: val_acc did not improve from 0.98948\n",
      "Epoch 307/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0410 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00307: val_acc did not improve from 0.98948\n",
      "Epoch 308/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9968 - val_loss: 0.0431 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00308: val_acc did not improve from 0.98948\n",
      "Epoch 309/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0076 - acc: 0.9968 - val_loss: 0.0381 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00309: val_acc did not improve from 0.98948\n",
      "Epoch 310/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 0.0388 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00310: val_acc did not improve from 0.98948\n",
      "Epoch 311/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9968 - val_loss: 0.0378 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00311: val_acc did not improve from 0.98948\n",
      "Epoch 312/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0075 - acc: 0.9969 - val_loss: 0.0355 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00312: val_acc did not improve from 0.98948\n",
      "Epoch 313/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0366 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00313: val_acc did not improve from 0.98948\n",
      "Epoch 314/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9967 - val_loss: 0.0375 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00314: val_acc did not improve from 0.98948\n",
      "Epoch 315/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9967 - val_loss: 0.0369 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00315: val_acc did not improve from 0.98948\n",
      "Epoch 316/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0149 - acc: 0.9950 - val_loss: 0.0832 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00316: val_acc did not improve from 0.98948\n",
      "Epoch 317/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0096 - acc: 0.9962 - val_loss: 0.0401 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00317: val_acc did not improve from 0.98948\n",
      "Epoch 318/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0358 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00318: val_acc did not improve from 0.98948\n",
      "Epoch 319/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9970 - val_loss: 0.0372 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00319: val_acc did not improve from 0.98948\n",
      "Epoch 320/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9968 - val_loss: 0.0411 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00320: val_acc did not improve from 0.98948\n",
      "Epoch 321/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0075 - acc: 0.9969 - val_loss: 0.0405 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00321: val_acc did not improve from 0.98948\n",
      "Epoch 322/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9969 - val_loss: 0.0360 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00322: val_acc did not improve from 0.98948\n",
      "Epoch 323/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0075 - acc: 0.9968 - val_loss: 0.0366 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00323: val_acc did not improve from 0.98948\n",
      "Epoch 324/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9968 - val_loss: 0.0378 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00324: val_acc did not improve from 0.98948\n",
      "Epoch 325/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0075 - acc: 0.9969 - val_loss: 0.0366 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00325: val_acc did not improve from 0.98948\n",
      "Epoch 326/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0377 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00326: val_acc did not improve from 0.98948\n",
      "Epoch 327/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0075 - acc: 0.9968 - val_loss: 0.0390 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00327: val_acc did not improve from 0.98948\n",
      "Epoch 328/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9969 - val_loss: 0.0418 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00328: val_acc did not improve from 0.98948\n",
      "Epoch 329/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0079 - acc: 0.9966 - val_loss: 0.0387 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00329: val_acc did not improve from 0.98948\n",
      "Epoch 330/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9970 - val_loss: 0.0376 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00330: val_acc did not improve from 0.98948\n",
      "Epoch 331/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9968 - val_loss: 0.0362 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00331: val_acc did not improve from 0.98948\n",
      "Epoch 332/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0072 - acc: 0.9971 - val_loss: 0.0351 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00332: val_acc did not improve from 0.98948\n",
      "Epoch 333/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9967 - val_loss: 0.0375 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00333: val_acc did not improve from 0.98948\n",
      "Epoch 334/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9971 - val_loss: 0.0361 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00334: val_acc did not improve from 0.98948\n",
      "Epoch 335/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9968 - val_loss: 0.0449 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00335: val_acc did not improve from 0.98948\n",
      "Epoch 336/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9967 - val_loss: 0.0369 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00336: val_acc did not improve from 0.98948\n",
      "Epoch 337/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9969 - val_loss: 0.0359 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00337: val_acc did not improve from 0.98948\n",
      "Epoch 338/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9969 - val_loss: 0.0388 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00338: val_acc did not improve from 0.98948\n",
      "Epoch 339/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0076 - acc: 0.9969 - val_loss: 0.0360 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00339: val_acc did not improve from 0.98948\n",
      "Epoch 340/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9968 - val_loss: 0.0360 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00340: val_acc did not improve from 0.98948\n",
      "Epoch 341/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0076 - acc: 0.9968 - val_loss: 0.0373 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00341: val_acc did not improve from 0.98948\n",
      "Epoch 342/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0078 - acc: 0.9966 - val_loss: 0.0373 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00342: val_acc did not improve from 0.98948\n",
      "Epoch 343/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9971 - val_loss: 0.0399 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00343: val_acc did not improve from 0.98948\n",
      "Epoch 344/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9971 - val_loss: 0.0360 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00344: val_acc did not improve from 0.98948\n",
      "Epoch 345/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9970 - val_loss: 0.0356 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00345: val_acc did not improve from 0.98948\n",
      "Epoch 346/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9968 - val_loss: 0.0369 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00346: val_acc did not improve from 0.98948\n",
      "Epoch 347/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0382 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00347: val_acc did not improve from 0.98948\n",
      "Epoch 348/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9970 - val_loss: 0.0393 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00348: val_acc did not improve from 0.98948\n",
      "Epoch 349/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0077 - acc: 0.9967 - val_loss: 0.0379 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00349: val_acc did not improve from 0.98948\n",
      "Epoch 350/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9969 - val_loss: 0.0372 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00350: val_acc did not improve from 0.98948\n",
      "Epoch 351/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9969 - val_loss: 0.0388 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00351: val_acc did not improve from 0.98948\n",
      "Epoch 352/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9970 - val_loss: 0.0397 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00352: val_acc did not improve from 0.98948\n",
      "Epoch 353/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0076 - acc: 0.9969 - val_loss: 0.0384 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00353: val_acc did not improve from 0.98948\n",
      "Epoch 354/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9971 - val_loss: 0.0380 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00354: val_acc did not improve from 0.98948\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9968 - val_loss: 0.0385 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00355: val_acc did not improve from 0.98948\n",
      "Epoch 356/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9968 - val_loss: 0.0398 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00356: val_acc did not improve from 0.98948\n",
      "Epoch 357/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00357: val_acc did not improve from 0.98948\n",
      "Epoch 358/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0076 - acc: 0.9968 - val_loss: 0.0397 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00358: val_acc did not improve from 0.98948\n",
      "Epoch 359/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9970 - val_loss: 0.0379 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00359: val_acc did not improve from 0.98948\n",
      "Epoch 360/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9969 - val_loss: 0.0418 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00360: val_acc did not improve from 0.98948\n",
      "Epoch 361/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0075 - acc: 0.9967 - val_loss: 0.0382 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00361: val_acc did not improve from 0.98948\n",
      "Epoch 362/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9968 - val_loss: 0.0403 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00362: val_acc did not improve from 0.98948\n",
      "Epoch 363/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0074 - acc: 0.9969 - val_loss: 0.0464 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00363: val_acc did not improve from 0.98948\n",
      "Epoch 364/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0071 - acc: 0.9970 - val_loss: 0.0423 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00364: val_acc did not improve from 0.98948\n",
      "Epoch 365/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0075 - acc: 0.9968 - val_loss: 0.0390 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00365: val_acc did not improve from 0.98948\n",
      "Epoch 366/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00366: val_acc did not improve from 0.98948\n",
      "Epoch 367/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9968 - val_loss: 0.0383 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00367: val_acc did not improve from 0.98948\n",
      "Epoch 368/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9968 - val_loss: 0.0375 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00368: val_acc did not improve from 0.98948\n",
      "Epoch 369/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9970 - val_loss: 0.0380 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00369: val_acc did not improve from 0.98948\n",
      "Epoch 370/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9969 - val_loss: 0.0387 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00370: val_acc did not improve from 0.98948\n",
      "Epoch 371/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9967 - val_loss: 0.0430 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00371: val_acc did not improve from 0.98948\n",
      "Epoch 372/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9970 - val_loss: 0.0350 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00372: val_acc did not improve from 0.98948\n",
      "Epoch 373/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9970 - val_loss: 0.0398 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00373: val_acc did not improve from 0.98948\n",
      "Epoch 374/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9968 - val_loss: 0.0434 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00374: val_acc did not improve from 0.98948\n",
      "Epoch 375/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9969 - val_loss: 0.0407 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00375: val_acc did not improve from 0.98948\n",
      "Epoch 376/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0073 - acc: 0.9968 - val_loss: 0.0412 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00376: val_acc did not improve from 0.98948\n",
      "Epoch 377/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9970 - val_loss: 0.0366 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00377: val_acc did not improve from 0.98948\n",
      "Epoch 378/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9969 - val_loss: 0.0361 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00378: val_acc did not improve from 0.98948\n",
      "Epoch 379/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9969 - val_loss: 0.0391 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00379: val_acc did not improve from 0.98948\n",
      "Epoch 380/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0408 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00380: val_acc did not improve from 0.98948\n",
      "Epoch 381/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0231 - acc: 0.9933 - val_loss: 0.0352 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00381: val_acc did not improve from 0.98948\n",
      "Epoch 382/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0371 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00382: val_acc did not improve from 0.98948\n",
      "Epoch 383/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0378 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00383: val_acc did not improve from 0.98948\n",
      "Epoch 384/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9969 - val_loss: 0.0367 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00384: val_acc did not improve from 0.98948\n",
      "Epoch 385/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9969 - val_loss: 0.0411 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00385: val_acc did not improve from 0.98948\n",
      "Epoch 386/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0073 - acc: 0.9969 - val_loss: 0.0383 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00386: val_acc did not improve from 0.98948\n",
      "Epoch 387/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9969 - val_loss: 0.0379 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00387: val_acc did not improve from 0.98948\n",
      "Epoch 388/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.0366 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00388: val_acc did not improve from 0.98948\n",
      "Epoch 389/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0404 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00389: val_acc did not improve from 0.98948\n",
      "Epoch 390/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0406 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00390: val_acc did not improve from 0.98948\n",
      "Epoch 391/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9968 - val_loss: 0.0380 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00391: val_acc did not improve from 0.98948\n",
      "Epoch 392/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9969 - val_loss: 0.0384 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00392: val_acc did not improve from 0.98948\n",
      "Epoch 393/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0072 - acc: 0.9967 - val_loss: 0.0383 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00393: val_acc did not improve from 0.98948\n",
      "Epoch 394/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0377 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00394: val_acc did not improve from 0.98948\n",
      "Epoch 395/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9971 - val_loss: 0.0366 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00395: val_acc did not improve from 0.98948\n",
      "Epoch 396/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0406 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00396: val_acc did not improve from 0.98948\n",
      "Epoch 397/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0073 - acc: 0.9968 - val_loss: 0.0368 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00397: val_acc did not improve from 0.98948\n",
      "Epoch 398/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9968 - val_loss: 0.0365 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00398: val_acc did not improve from 0.98948\n",
      "Epoch 399/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9970 - val_loss: 0.0369 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00399: val_acc did not improve from 0.98948\n",
      "Epoch 400/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9971 - val_loss: 0.0414 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00400: val_acc did not improve from 0.98948\n",
      "Epoch 401/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9971 - val_loss: 0.0414 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00401: val_acc did not improve from 0.98948\n",
      "Epoch 402/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9970 - val_loss: 0.0379 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00402: val_acc did not improve from 0.98948\n",
      "Epoch 403/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9968 - val_loss: 0.0411 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00403: val_acc did not improve from 0.98948\n",
      "Epoch 404/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0381 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00404: val_acc did not improve from 0.98948\n",
      "Epoch 405/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0400 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00405: val_acc did not improve from 0.98948\n",
      "Epoch 406/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0373 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00406: val_acc did not improve from 0.98948\n",
      "Epoch 407/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.0395 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00407: val_acc did not improve from 0.98948\n",
      "Epoch 408/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0071 - acc: 0.9969 - val_loss: 0.0406 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00408: val_acc did not improve from 0.98948\n",
      "Epoch 409/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0411 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00409: val_acc did not improve from 0.98948\n",
      "Epoch 410/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0401 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00410: val_acc did not improve from 0.98948\n",
      "Epoch 411/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0363 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00411: val_acc did not improve from 0.98948\n",
      "Epoch 412/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.0381 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00412: val_acc did not improve from 0.98948\n",
      "Epoch 413/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9970 - val_loss: 0.0433 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00413: val_acc did not improve from 0.98948\n",
      "Epoch 414/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9969 - val_loss: 0.0375 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00414: val_acc did not improve from 0.98948\n",
      "Epoch 415/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9971 - val_loss: 0.0361 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00415: val_acc did not improve from 0.98948\n",
      "Epoch 416/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0446 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00416: val_acc did not improve from 0.98948\n",
      "Epoch 417/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9969 - val_loss: 0.0384 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00417: val_acc did not improve from 0.98948\n",
      "Epoch 418/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9968 - val_loss: 0.0426 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00418: val_acc did not improve from 0.98948\n",
      "Epoch 419/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0404 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00419: val_acc did not improve from 0.98948\n",
      "Epoch 420/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9970 - val_loss: 0.0363 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00420: val_acc did not improve from 0.98948\n",
      "Epoch 421/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9968 - val_loss: 0.0373 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00421: val_acc did not improve from 0.98948\n",
      "Epoch 422/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9970 - val_loss: 0.0384 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00422: val_acc did not improve from 0.98948\n",
      "Epoch 423/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 0.0375 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00423: val_acc did not improve from 0.98948\n",
      "Epoch 424/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0378 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00424: val_acc did not improve from 0.98948\n",
      "Epoch 425/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0394 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00425: val_acc did not improve from 0.98948\n",
      "Epoch 426/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0530 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00426: val_acc did not improve from 0.98948\n",
      "Epoch 427/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9969 - val_loss: 0.0398 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00427: val_acc did not improve from 0.98948\n",
      "Epoch 428/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0380 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00428: val_acc did not improve from 0.98948\n",
      "Epoch 429/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0386 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00429: val_acc did not improve from 0.98948\n",
      "Epoch 430/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0386 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00430: val_acc did not improve from 0.98948\n",
      "Epoch 431/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0405 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00431: val_acc did not improve from 0.98948\n",
      "Epoch 432/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0429 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00432: val_acc did not improve from 0.98948\n",
      "Epoch 433/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.0408 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00433: val_acc did not improve from 0.98948\n",
      "Epoch 434/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 0.0404 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00434: val_acc did not improve from 0.98948\n",
      "Epoch 435/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0384 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00435: val_acc did not improve from 0.98948\n",
      "Epoch 436/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.0364 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00436: val_acc did not improve from 0.98948\n",
      "Epoch 437/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0390 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00437: val_acc did not improve from 0.98948\n",
      "Epoch 438/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.0392 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00438: val_acc did not improve from 0.98948\n",
      "Epoch 439/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9970 - val_loss: 0.0468 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00439: val_acc did not improve from 0.98948\n",
      "Epoch 440/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0385 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00440: val_acc did not improve from 0.98948\n",
      "Epoch 441/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9968 - val_loss: 0.0377 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00441: val_acc did not improve from 0.98948\n",
      "Epoch 442/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0379 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00442: val_acc did not improve from 0.98948\n",
      "Epoch 443/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9969 - val_loss: 0.0426 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00443: val_acc did not improve from 0.98948\n",
      "Epoch 444/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9967 - val_loss: 0.0393 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00444: val_acc did not improve from 0.98948\n",
      "Epoch 445/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9969 - val_loss: 0.0379 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00445: val_acc did not improve from 0.98948\n",
      "Epoch 446/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 0.0392 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00446: val_acc did not improve from 0.98948\n",
      "Epoch 447/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0463 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00447: val_acc did not improve from 0.98948\n",
      "Epoch 448/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9971 - val_loss: 0.0384 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00448: val_acc did not improve from 0.98948\n",
      "Epoch 449/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0376 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00449: val_acc did not improve from 0.98948\n",
      "Epoch 450/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9971 - val_loss: 0.0369 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00450: val_acc did not improve from 0.98948\n",
      "Epoch 451/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0419 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00451: val_acc did not improve from 0.98948\n",
      "Epoch 452/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9969 - val_loss: 0.0441 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00452: val_acc did not improve from 0.98948\n",
      "Epoch 453/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0066 - acc: 0.9972 - val_loss: 0.0377 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00453: val_acc did not improve from 0.98948\n",
      "Epoch 454/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0391 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00454: val_acc did not improve from 0.98948\n",
      "Epoch 455/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0424 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00455: val_acc did not improve from 0.98948\n",
      "Epoch 456/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0389 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00456: val_acc did not improve from 0.98948\n",
      "Epoch 457/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0394 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00457: val_acc did not improve from 0.98948\n",
      "Epoch 458/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9969 - val_loss: 0.0382 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00458: val_acc did not improve from 0.98948\n",
      "Epoch 459/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0370 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00459: val_acc did not improve from 0.98948\n",
      "Epoch 460/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9969 - val_loss: 0.0418 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00460: val_acc did not improve from 0.98948\n",
      "Epoch 461/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9970 - val_loss: 0.0408 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00461: val_acc did not improve from 0.98948\n",
      "Epoch 462/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0068 - acc: 0.9969 - val_loss: 0.0397 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00462: val_acc did not improve from 0.98948\n",
      "Epoch 463/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.0385 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00463: val_acc did not improve from 0.98948\n",
      "Epoch 464/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9969 - val_loss: 0.0447 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00464: val_acc did not improve from 0.98948\n",
      "Epoch 465/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0071 - acc: 0.9968 - val_loss: 0.0368 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00465: val_acc did not improve from 0.98948\n",
      "Epoch 466/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0418 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00466: val_acc did not improve from 0.98948\n",
      "Epoch 467/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 0.0414 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00467: val_acc did not improve from 0.98948\n",
      "Epoch 468/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0398 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00468: val_acc did not improve from 0.98948\n",
      "Epoch 469/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9972 - val_loss: 0.0388 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00469: val_acc did not improve from 0.98948\n",
      "Epoch 470/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0070 - acc: 0.9968 - val_loss: 0.0403 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00470: val_acc did not improve from 0.98948\n",
      "Epoch 471/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9968 - val_loss: 0.0383 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00471: val_acc did not improve from 0.98948\n",
      "Epoch 472/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9971 - val_loss: 0.0373 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00472: val_acc did not improve from 0.98948\n",
      "Epoch 473/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0406 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00473: val_acc did not improve from 0.98948\n",
      "Epoch 474/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9972 - val_loss: 0.0374 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00474: val_acc did not improve from 0.98948\n",
      "Epoch 475/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0389 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00475: val_acc did not improve from 0.98948\n",
      "Epoch 476/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0069 - acc: 0.9969 - val_loss: 0.0399 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00476: val_acc did not improve from 0.98948\n",
      "Epoch 477/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9968 - val_loss: 0.0393 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00477: val_acc did not improve from 0.98948\n",
      "Epoch 478/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0068 - acc: 0.9969 - val_loss: 0.0371 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00478: val_acc did not improve from 0.98948\n",
      "Epoch 479/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9971 - val_loss: 0.0416 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00479: val_acc did not improve from 0.98948\n",
      "Epoch 480/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9972 - val_loss: 0.0414 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00480: val_acc did not improve from 0.98948\n",
      "Epoch 481/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9969 - val_loss: 0.0395 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00481: val_acc did not improve from 0.98948\n",
      "Epoch 482/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0387 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00482: val_acc did not improve from 0.98948\n",
      "Epoch 483/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9968 - val_loss: 0.0418 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00483: val_acc did not improve from 0.98948\n",
      "Epoch 484/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0384 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00484: val_acc did not improve from 0.98948\n",
      "Epoch 485/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0064 - acc: 0.9972 - val_loss: 0.0396 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00485: val_acc did not improve from 0.98948\n",
      "Epoch 486/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9969 - val_loss: 0.0392 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00486: val_acc did not improve from 0.98948\n",
      "Epoch 487/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0413 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00487: val_acc did not improve from 0.98948\n",
      "Epoch 488/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0419 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00488: val_acc did not improve from 0.98948\n",
      "Epoch 489/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0391 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00489: val_acc did not improve from 0.98948\n",
      "Epoch 490/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0383 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00490: val_acc did not improve from 0.98948\n",
      "Epoch 491/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9971 - val_loss: 0.0402 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00491: val_acc did not improve from 0.98948\n",
      "Epoch 492/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00492: val_acc did not improve from 0.98948\n",
      "Epoch 493/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9970 - val_loss: 0.0413 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00493: val_acc did not improve from 0.98948\n",
      "Epoch 494/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0382 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00494: val_acc did not improve from 0.98948\n",
      "Epoch 495/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0411 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00495: val_acc did not improve from 0.98948\n",
      "Epoch 496/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9972 - val_loss: 0.0405 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00496: val_acc did not improve from 0.98948\n",
      "Epoch 497/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0377 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00497: val_acc did not improve from 0.98948\n",
      "Epoch 498/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0400 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00498: val_acc did not improve from 0.98948\n",
      "Epoch 499/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0387 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00499: val_acc did not improve from 0.98948\n",
      "Epoch 500/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0380 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00500: val_acc did not improve from 0.98948\n",
      "Epoch 501/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 0.0389 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00501: val_acc did not improve from 0.98948\n",
      "Epoch 502/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9969 - val_loss: 0.0376 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00502: val_acc did not improve from 0.98948\n",
      "Epoch 503/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0422 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00503: val_acc did not improve from 0.98948\n",
      "Epoch 504/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0374 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00504: val_acc did not improve from 0.98948\n",
      "Epoch 505/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0432 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00505: val_acc did not improve from 0.98948\n",
      "Epoch 506/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9972 - val_loss: 0.0406 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00506: val_acc did not improve from 0.98948\n",
      "Epoch 507/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0400 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00507: val_acc did not improve from 0.98948\n",
      "Epoch 508/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0384 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00508: val_acc did not improve from 0.98948\n",
      "Epoch 509/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0391 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00509: val_acc did not improve from 0.98948\n",
      "Epoch 510/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0120 - acc: 0.9958 - val_loss: 0.1710 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00510: val_acc did not improve from 0.98948\n",
      "Epoch 511/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0093 - acc: 0.9964 - val_loss: 0.0384 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00511: val_acc did not improve from 0.98948\n",
      "Epoch 512/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0370 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00512: val_acc did not improve from 0.98948\n",
      "Epoch 513/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9972 - val_loss: 0.0383 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00513: val_acc did not improve from 0.98948\n",
      "Epoch 514/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0385 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00514: val_acc did not improve from 0.98948\n",
      "Epoch 515/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9968 - val_loss: 0.0364 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00515: val_acc did not improve from 0.98948\n",
      "Epoch 516/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0378 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00516: val_acc did not improve from 0.98948\n",
      "Epoch 517/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0401 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00517: val_acc did not improve from 0.98948\n",
      "Epoch 518/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9972 - val_loss: 0.0381 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00518: val_acc did not improve from 0.98948\n",
      "Epoch 519/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0068 - acc: 0.9971 - val_loss: 0.0378 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00519: val_acc did not improve from 0.98948\n",
      "Epoch 520/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0381 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00520: val_acc did not improve from 0.98948\n",
      "Epoch 521/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0378 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00521: val_acc did not improve from 0.98948\n",
      "Epoch 522/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0397 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00522: val_acc did not improve from 0.98948\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9969 - val_loss: 0.0410 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00523: val_acc did not improve from 0.98948\n",
      "Epoch 524/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0392 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00524: val_acc did not improve from 0.98948\n",
      "Epoch 525/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0404 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00525: val_acc did not improve from 0.98948\n",
      "Epoch 526/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0382 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00526: val_acc did not improve from 0.98948\n",
      "Epoch 527/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0401 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00527: val_acc did not improve from 0.98948\n",
      "Epoch 528/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0410 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00528: val_acc did not improve from 0.98948\n",
      "Epoch 529/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9973 - val_loss: 0.0408 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00529: val_acc did not improve from 0.98948\n",
      "Epoch 530/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9969 - val_loss: 0.0390 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00530: val_acc did not improve from 0.98948\n",
      "Epoch 531/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0373 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00531: val_acc did not improve from 0.98948\n",
      "Epoch 532/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0418 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00532: val_acc did not improve from 0.98948\n",
      "Epoch 533/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9969 - val_loss: 0.0400 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00533: val_acc did not improve from 0.98948\n",
      "Epoch 534/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0421 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00534: val_acc did not improve from 0.98948\n",
      "Epoch 535/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9969 - val_loss: 0.0432 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00535: val_acc did not improve from 0.98948\n",
      "Epoch 536/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9972 - val_loss: 0.0394 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00536: val_acc did not improve from 0.98948\n",
      "Epoch 537/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9969 - val_loss: 0.0390 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00537: val_acc did not improve from 0.98948\n",
      "Epoch 538/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0407 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00538: val_acc did not improve from 0.98948\n",
      "Epoch 539/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0401 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00539: val_acc did not improve from 0.98948\n",
      "Epoch 540/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0390 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00540: val_acc did not improve from 0.98948\n",
      "Epoch 541/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0383 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00541: val_acc did not improve from 0.98948\n",
      "Epoch 542/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0444 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00542: val_acc did not improve from 0.98948\n",
      "Epoch 543/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0381 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00543: val_acc did not improve from 0.98948\n",
      "Epoch 544/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0413 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00544: val_acc did not improve from 0.98948\n",
      "Epoch 545/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0427 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00545: val_acc did not improve from 0.98948\n",
      "Epoch 546/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9969 - val_loss: 0.0415 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00546: val_acc did not improve from 0.98948\n",
      "Epoch 547/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0381 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00547: val_acc did not improve from 0.98948\n",
      "Epoch 548/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0376 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00548: val_acc did not improve from 0.98948\n",
      "Epoch 549/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0399 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00549: val_acc did not improve from 0.98948\n",
      "Epoch 550/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0389 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00550: val_acc did not improve from 0.98948\n",
      "Epoch 551/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0427 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00551: val_acc did not improve from 0.98948\n",
      "Epoch 552/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0393 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00552: val_acc did not improve from 0.98948\n",
      "Epoch 553/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0386 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00553: val_acc did not improve from 0.98948\n",
      "Epoch 554/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0363 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00554: val_acc did not improve from 0.98948\n",
      "Epoch 555/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0378 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00555: val_acc did not improve from 0.98948\n",
      "Epoch 556/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0399 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00556: val_acc did not improve from 0.98948\n",
      "Epoch 557/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0413 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00557: val_acc did not improve from 0.98948\n",
      "Epoch 558/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0399 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00558: val_acc did not improve from 0.98948\n",
      "Epoch 559/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0422 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00559: val_acc did not improve from 0.98948\n",
      "Epoch 560/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9972 - val_loss: 0.0443 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00560: val_acc did not improve from 0.98948\n",
      "Epoch 561/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0067 - acc: 0.9969 - val_loss: 0.0396 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00561: val_acc did not improve from 0.98948\n",
      "Epoch 562/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0437 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00562: val_acc did not improve from 0.98948\n",
      "Epoch 563/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9969 - val_loss: 0.0433 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00563: val_acc did not improve from 0.98948\n",
      "Epoch 564/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0388 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00564: val_acc did not improve from 0.98948\n",
      "Epoch 565/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0464 - val_acc: 0.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00565: val_acc did not improve from 0.98948\n",
      "Epoch 566/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00566: val_acc did not improve from 0.98948\n",
      "Epoch 567/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0390 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00567: val_acc did not improve from 0.98948\n",
      "Epoch 568/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0408 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00568: val_acc did not improve from 0.98948\n",
      "Epoch 569/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9972 - val_loss: 0.0432 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00569: val_acc did not improve from 0.98948\n",
      "Epoch 570/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9969 - val_loss: 0.0392 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00570: val_acc did not improve from 0.98948\n",
      "Epoch 571/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0390 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00571: val_acc did not improve from 0.98948\n",
      "Epoch 572/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0387 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00572: val_acc did not improve from 0.98948\n",
      "Epoch 573/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.0382 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00573: val_acc did not improve from 0.98948\n",
      "Epoch 574/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0387 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00574: val_acc did not improve from 0.98948\n",
      "Epoch 575/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0401 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00575: val_acc did not improve from 0.98948\n",
      "Epoch 576/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0419 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00576: val_acc did not improve from 0.98948\n",
      "Epoch 577/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0240 - acc: 0.9933 - val_loss: 0.0370 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00577: val_acc did not improve from 0.98948\n",
      "Epoch 578/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0380 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00578: val_acc did not improve from 0.98948\n",
      "Epoch 579/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0379 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00579: val_acc did not improve from 0.98948\n",
      "Epoch 580/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0369 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00580: val_acc improved from 0.98948 to 0.98948, saving model to Results/024/weights/weights-improvement-580-0.99.hdf5\n",
      "Epoch 581/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0383 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00581: val_acc did not improve from 0.98948\n",
      "Epoch 582/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0396 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00582: val_acc did not improve from 0.98948\n",
      "Epoch 583/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0386 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00583: val_acc did not improve from 0.98948\n",
      "Epoch 584/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0385 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00584: val_acc did not improve from 0.98948\n",
      "Epoch 585/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00585: val_acc did not improve from 0.98948\n",
      "Epoch 586/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9972 - val_loss: 0.0430 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00586: val_acc did not improve from 0.98948\n",
      "Epoch 587/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0404 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00587: val_acc did not improve from 0.98948\n",
      "Epoch 588/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9971 - val_loss: 0.0375 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00588: val_acc did not improve from 0.98948\n",
      "Epoch 589/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9969 - val_loss: 0.0383 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00589: val_acc did not improve from 0.98948\n",
      "Epoch 590/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0390 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00590: val_acc did not improve from 0.98948\n",
      "Epoch 591/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9972 - val_loss: 0.0404 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00591: val_acc did not improve from 0.98948\n",
      "Epoch 592/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0425 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00592: val_acc did not improve from 0.98948\n",
      "Epoch 593/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0428 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00593: val_acc did not improve from 0.98948\n",
      "Epoch 594/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0394 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00594: val_acc did not improve from 0.98948\n",
      "Epoch 595/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9969 - val_loss: 0.0418 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00595: val_acc did not improve from 0.98948\n",
      "Epoch 596/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0375 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00596: val_acc did not improve from 0.98948\n",
      "Epoch 597/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0065 - acc: 0.9968 - val_loss: 0.0384 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00597: val_acc did not improve from 0.98948\n",
      "Epoch 598/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9972 - val_loss: 0.0388 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00598: val_acc did not improve from 0.98948\n",
      "Epoch 599/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9969 - val_loss: 0.0383 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00599: val_acc did not improve from 0.98948\n",
      "Epoch 600/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0396 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00600: val_acc did not improve from 0.98948\n",
      "Epoch 601/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0386 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00601: val_acc did not improve from 0.98948\n",
      "Epoch 602/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0388 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00602: val_acc did not improve from 0.98948\n",
      "Epoch 603/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0403 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00603: val_acc did not improve from 0.98948\n",
      "Epoch 604/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0428 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00604: val_acc did not improve from 0.98948\n",
      "Epoch 605/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0391 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00605: val_acc did not improve from 0.98948\n",
      "Epoch 606/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0378 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00606: val_acc did not improve from 0.98948\n",
      "Epoch 607/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0416 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00607: val_acc did not improve from 0.98948\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9969 - val_loss: 0.0385 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00608: val_acc did not improve from 0.98948\n",
      "Epoch 609/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0423 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00609: val_acc did not improve from 0.98948\n",
      "Epoch 610/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0383 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00610: val_acc did not improve from 0.98948\n",
      "Epoch 611/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0370 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00611: val_acc did not improve from 0.98948\n",
      "Epoch 612/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0407 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00612: val_acc did not improve from 0.98948\n",
      "Epoch 613/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0435 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00613: val_acc did not improve from 0.98948\n",
      "Epoch 614/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0394 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00614: val_acc did not improve from 0.98948\n",
      "Epoch 615/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0393 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00615: val_acc did not improve from 0.98948\n",
      "Epoch 616/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0392 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00616: val_acc did not improve from 0.98948\n",
      "Epoch 617/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0393 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00617: val_acc did not improve from 0.98948\n",
      "Epoch 618/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9973 - val_loss: 0.0394 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00618: val_acc did not improve from 0.98948\n",
      "Epoch 619/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0431 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00619: val_acc did not improve from 0.98948\n",
      "Epoch 620/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0402 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00620: val_acc did not improve from 0.98948\n",
      "Epoch 621/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0409 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00621: val_acc did not improve from 0.98948\n",
      "Epoch 622/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9972 - val_loss: 0.0403 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00622: val_acc did not improve from 0.98948\n",
      "Epoch 623/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9968 - val_loss: 0.0397 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00623: val_acc did not improve from 0.98948\n",
      "Epoch 624/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0397 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00624: val_acc did not improve from 0.98948\n",
      "Epoch 625/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0394 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00625: val_acc did not improve from 0.98948\n",
      "Epoch 626/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9969 - val_loss: 0.0399 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00626: val_acc did not improve from 0.98948\n",
      "Epoch 627/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0440 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00627: val_acc did not improve from 0.98948\n",
      "Epoch 628/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0399 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00628: val_acc did not improve from 0.98948\n",
      "Epoch 629/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0384 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00629: val_acc did not improve from 0.98948\n",
      "Epoch 630/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0405 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00630: val_acc did not improve from 0.98948\n",
      "Epoch 631/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9969 - val_loss: 0.0431 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00631: val_acc did not improve from 0.98948\n",
      "Epoch 632/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9969 - val_loss: 0.0381 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00632: val_acc did not improve from 0.98948\n",
      "Epoch 633/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9969 - val_loss: 0.0477 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00633: val_acc did not improve from 0.98948\n",
      "Epoch 634/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9972 - val_loss: 0.0414 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00634: val_acc did not improve from 0.98948\n",
      "Epoch 635/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0481 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00635: val_acc did not improve from 0.98948\n",
      "Epoch 636/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0394 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00636: val_acc did not improve from 0.98948\n",
      "Epoch 637/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0399 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00637: val_acc did not improve from 0.98948\n",
      "Epoch 638/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0398 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00638: val_acc did not improve from 0.98948\n",
      "Epoch 639/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0387 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00639: val_acc did not improve from 0.98948\n",
      "Epoch 640/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0406 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00640: val_acc did not improve from 0.98948\n",
      "Epoch 641/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9972 - val_loss: 0.0388 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00641: val_acc did not improve from 0.98948\n",
      "Epoch 642/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0388 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00642: val_acc did not improve from 0.98948\n",
      "Epoch 643/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0434 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00643: val_acc did not improve from 0.98948\n",
      "Epoch 644/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0425 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00644: val_acc did not improve from 0.98948\n",
      "Epoch 645/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0405 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00645: val_acc did not improve from 0.98948\n",
      "Epoch 646/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00646: val_acc did not improve from 0.98948\n",
      "Epoch 647/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0525 - val_acc: 0.9851\n",
      "\n",
      "Epoch 00647: val_acc did not improve from 0.98948\n",
      "Epoch 648/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0412 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00648: val_acc did not improve from 0.98948\n",
      "Epoch 649/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0379 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00649: val_acc did not improve from 0.98948\n",
      "Epoch 650/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0401 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00650: val_acc did not improve from 0.98948\n",
      "Epoch 651/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00651: val_acc did not improve from 0.98948\n",
      "Epoch 652/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0426 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00652: val_acc did not improve from 0.98948\n",
      "Epoch 653/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0415 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00653: val_acc did not improve from 0.98948\n",
      "Epoch 654/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0392 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00654: val_acc did not improve from 0.98948\n",
      "Epoch 655/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0455 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00655: val_acc did not improve from 0.98948\n",
      "Epoch 656/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00656: val_acc did not improve from 0.98948\n",
      "Epoch 657/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0446 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00657: val_acc did not improve from 0.98948\n",
      "Epoch 658/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0394 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00658: val_acc did not improve from 0.98948\n",
      "Epoch 659/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0393 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00659: val_acc did not improve from 0.98948\n",
      "Epoch 660/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0410 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00660: val_acc did not improve from 0.98948\n",
      "Epoch 661/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0396 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00661: val_acc did not improve from 0.98948\n",
      "Epoch 662/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0411 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00662: val_acc did not improve from 0.98948\n",
      "Epoch 663/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9968 - val_loss: 0.0391 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00663: val_acc did not improve from 0.98948\n",
      "Epoch 664/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0420 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00664: val_acc did not improve from 0.98948\n",
      "Epoch 665/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9972 - val_loss: 0.0394 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00665: val_acc did not improve from 0.98948\n",
      "Epoch 666/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9972 - val_loss: 0.0409 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00666: val_acc did not improve from 0.98948\n",
      "Epoch 667/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9971 - val_loss: 0.0390 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00667: val_acc did not improve from 0.98948\n",
      "Epoch 668/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0407 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00668: val_acc did not improve from 0.98948\n",
      "Epoch 669/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0413 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00669: val_acc did not improve from 0.98948\n",
      "Epoch 670/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0065 - acc: 0.9970 - val_loss: 0.0435 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00670: val_acc did not improve from 0.98948\n",
      "Epoch 671/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0398 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00671: val_acc did not improve from 0.98948\n",
      "Epoch 672/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9972 - val_loss: 0.0415 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00672: val_acc did not improve from 0.98948\n",
      "Epoch 673/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0407 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00673: val_acc did not improve from 0.98948\n",
      "Epoch 674/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9972 - val_loss: 0.0390 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00674: val_acc did not improve from 0.98948\n",
      "Epoch 675/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0442 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00675: val_acc did not improve from 0.98948\n",
      "Epoch 676/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9972 - val_loss: 0.0454 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00676: val_acc did not improve from 0.98948\n",
      "Epoch 677/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0393 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00677: val_acc did not improve from 0.98948\n",
      "Epoch 678/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0412 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00678: val_acc did not improve from 0.98948\n",
      "Epoch 679/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9972 - val_loss: 0.0392 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00679: val_acc did not improve from 0.98948\n",
      "Epoch 680/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0399 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00680: val_acc did not improve from 0.98948\n",
      "Epoch 681/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0391 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00681: val_acc did not improve from 0.98948\n",
      "Epoch 682/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0389 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00682: val_acc did not improve from 0.98948\n",
      "Epoch 683/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0448 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00683: val_acc did not improve from 0.98948\n",
      "Epoch 684/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0402 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00684: val_acc did not improve from 0.98948\n",
      "Epoch 685/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0395 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00685: val_acc did not improve from 0.98948\n",
      "Epoch 686/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0397 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00686: val_acc did not improve from 0.98948\n",
      "Epoch 687/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0417 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00687: val_acc did not improve from 0.98948\n",
      "Epoch 688/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0406 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00688: val_acc did not improve from 0.98948\n",
      "Epoch 689/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0420 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00689: val_acc did not improve from 0.98948\n",
      "Epoch 690/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0432 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00690: val_acc did not improve from 0.98948\n",
      "Epoch 691/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0408 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00691: val_acc did not improve from 0.98948\n",
      "Epoch 692/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0400 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00692: val_acc did not improve from 0.98948\n",
      "Epoch 693/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0456 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00693: val_acc did not improve from 0.98948\n",
      "Epoch 694/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0420 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00694: val_acc did not improve from 0.98948\n",
      "Epoch 695/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0398 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00695: val_acc did not improve from 0.98948\n",
      "Epoch 696/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0394 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00696: val_acc did not improve from 0.98948\n",
      "Epoch 697/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9971 - val_loss: 0.0429 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00697: val_acc did not improve from 0.98948\n",
      "Epoch 698/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0381 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00698: val_acc did not improve from 0.98948\n",
      "Epoch 699/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0396 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00699: val_acc did not improve from 0.98948\n",
      "Epoch 700/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0406 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00700: val_acc did not improve from 0.98948\n",
      "Epoch 701/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0413 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00701: val_acc did not improve from 0.98948\n",
      "Epoch 702/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0390 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00702: val_acc did not improve from 0.98948\n",
      "Epoch 703/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0445 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00703: val_acc did not improve from 0.98948\n",
      "Epoch 704/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0410 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00704: val_acc did not improve from 0.98948\n",
      "Epoch 705/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9969 - val_loss: 0.0413 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00705: val_acc did not improve from 0.98948\n",
      "Epoch 706/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0399 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00706: val_acc did not improve from 0.98948\n",
      "Epoch 707/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9973 - val_loss: 0.0389 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00707: val_acc did not improve from 0.98948\n",
      "Epoch 708/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9972 - val_loss: 0.0380 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00708: val_acc did not improve from 0.98948\n",
      "Epoch 709/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0400 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00709: val_acc did not improve from 0.98948\n",
      "Epoch 710/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9969 - val_loss: 0.0404 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00710: val_acc did not improve from 0.98948\n",
      "Epoch 711/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0392 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00711: val_acc did not improve from 0.98948\n",
      "Epoch 712/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0477 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00712: val_acc did not improve from 0.98948\n",
      "Epoch 713/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0437 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00713: val_acc did not improve from 0.98948\n",
      "Epoch 714/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0390 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00714: val_acc did not improve from 0.98948\n",
      "Epoch 715/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9972 - val_loss: 0.0410 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00715: val_acc did not improve from 0.98948\n",
      "Epoch 716/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0474 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00716: val_acc did not improve from 0.98948\n",
      "Epoch 717/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0393 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00717: val_acc did not improve from 0.98948\n",
      "Epoch 718/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0390 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00718: val_acc did not improve from 0.98948\n",
      "Epoch 719/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0406 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00719: val_acc did not improve from 0.98948\n",
      "Epoch 720/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9972 - val_loss: 0.0491 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00720: val_acc did not improve from 0.98948\n",
      "Epoch 721/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0066 - acc: 0.9970 - val_loss: 0.0388 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00721: val_acc did not improve from 0.98948\n",
      "Epoch 722/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00722: val_acc did not improve from 0.98948\n",
      "Epoch 723/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0495 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00723: val_acc did not improve from 0.98948\n",
      "Epoch 724/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0394 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00724: val_acc did not improve from 0.98948\n",
      "Epoch 725/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0064 - acc: 0.9970 - val_loss: 0.0410 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00725: val_acc did not improve from 0.98948\n",
      "Epoch 726/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0419 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00726: val_acc did not improve from 0.98948\n",
      "Epoch 727/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0406 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00727: val_acc did not improve from 0.98948\n",
      "Epoch 728/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0414 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00728: val_acc did not improve from 0.98948\n",
      "Epoch 729/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9969 - val_loss: 0.0404 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00729: val_acc did not improve from 0.98948\n",
      "Epoch 730/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0403 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00730: val_acc did not improve from 0.98948\n",
      "Epoch 731/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00731: val_acc did not improve from 0.98948\n",
      "Epoch 732/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0411 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00732: val_acc did not improve from 0.98948\n",
      "Epoch 733/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00733: val_acc did not improve from 0.98948\n",
      "Epoch 734/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9969 - val_loss: 0.0441 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00734: val_acc did not improve from 0.98948\n",
      "Epoch 735/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0401 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00735: val_acc did not improve from 0.98948\n",
      "Epoch 736/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0398 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00736: val_acc did not improve from 0.98948\n",
      "Epoch 737/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0410 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00737: val_acc did not improve from 0.98948\n",
      "Epoch 738/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0439 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00738: val_acc did not improve from 0.98948\n",
      "Epoch 739/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9969 - val_loss: 0.0408 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00739: val_acc did not improve from 0.98948\n",
      "Epoch 740/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0404 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00740: val_acc did not improve from 0.98948\n",
      "Epoch 741/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9972 - val_loss: 0.0437 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00741: val_acc did not improve from 0.98948\n",
      "Epoch 742/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0406 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00742: val_acc did not improve from 0.98948\n",
      "Epoch 743/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9973 - val_loss: 0.0414 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00743: val_acc did not improve from 0.98948\n",
      "Epoch 744/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0407 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00744: val_acc did not improve from 0.98948\n",
      "Epoch 745/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0415 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00745: val_acc did not improve from 0.98948\n",
      "Epoch 746/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9972 - val_loss: 0.0439 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00746: val_acc did not improve from 0.98948\n",
      "Epoch 747/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0399 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00747: val_acc did not improve from 0.98948\n",
      "Epoch 748/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0487 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00748: val_acc did not improve from 0.98948\n",
      "Epoch 749/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0424 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00749: val_acc did not improve from 0.98948\n",
      "Epoch 750/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0427 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00750: val_acc did not improve from 0.98948\n",
      "Epoch 751/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0412 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00751: val_acc did not improve from 0.98948\n",
      "Epoch 752/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0390 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00752: val_acc did not improve from 0.98948\n",
      "Epoch 753/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0413 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00753: val_acc did not improve from 0.98948\n",
      "Epoch 754/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0397 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00754: val_acc did not improve from 0.98948\n",
      "Epoch 755/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0429 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00755: val_acc did not improve from 0.98948\n",
      "Epoch 756/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0397 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00756: val_acc did not improve from 0.98948\n",
      "Epoch 757/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0421 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00757: val_acc did not improve from 0.98948\n",
      "Epoch 758/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00758: val_acc did not improve from 0.98948\n",
      "Epoch 759/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9972 - val_loss: 0.0408 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00759: val_acc did not improve from 0.98948\n",
      "Epoch 760/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0386 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00760: val_acc did not improve from 0.98948\n",
      "Epoch 761/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0418 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00761: val_acc did not improve from 0.98948\n",
      "Epoch 762/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0449 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00762: val_acc did not improve from 0.98948\n",
      "Epoch 763/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0438 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00763: val_acc did not improve from 0.98948\n",
      "Epoch 764/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0416 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00764: val_acc did not improve from 0.98948\n",
      "Epoch 765/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0401 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00765: val_acc did not improve from 0.98948\n",
      "Epoch 766/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0410 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00766: val_acc did not improve from 0.98948\n",
      "Epoch 767/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0434 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00767: val_acc did not improve from 0.98948\n",
      "Epoch 768/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0389 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00768: val_acc did not improve from 0.98948\n",
      "Epoch 769/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0421 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00769: val_acc did not improve from 0.98948\n",
      "Epoch 770/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00770: val_acc did not improve from 0.98948\n",
      "Epoch 771/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9973 - val_loss: 0.0399 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00771: val_acc did not improve from 0.98948\n",
      "Epoch 772/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0431 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00772: val_acc did not improve from 0.98948\n",
      "Epoch 773/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0395 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00773: val_acc did not improve from 0.98948\n",
      "Epoch 774/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9973 - val_loss: 0.0396 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00774: val_acc did not improve from 0.98948\n",
      "Epoch 775/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0420 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00775: val_acc did not improve from 0.98948\n",
      "Epoch 776/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0392 - val_acc: 0.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00776: val_acc did not improve from 0.98948\n",
      "Epoch 777/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0406 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00777: val_acc did not improve from 0.98948\n",
      "Epoch 778/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0388 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00778: val_acc did not improve from 0.98948\n",
      "Epoch 779/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9973 - val_loss: 0.0450 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00779: val_acc did not improve from 0.98948\n",
      "Epoch 780/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0398 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00780: val_acc did not improve from 0.98948\n",
      "Epoch 781/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0396 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00781: val_acc did not improve from 0.98948\n",
      "Epoch 782/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0412 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00782: val_acc did not improve from 0.98948\n",
      "Epoch 783/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0389 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00783: val_acc did not improve from 0.98948\n",
      "Epoch 784/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0415 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00784: val_acc did not improve from 0.98948\n",
      "Epoch 785/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0415 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00785: val_acc did not improve from 0.98948\n",
      "Epoch 786/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0393 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00786: val_acc did not improve from 0.98948\n",
      "Epoch 787/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0420 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00787: val_acc did not improve from 0.98948\n",
      "Epoch 788/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0403 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00788: val_acc did not improve from 0.98948\n",
      "Epoch 789/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0392 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00789: val_acc did not improve from 0.98948\n",
      "Epoch 790/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0418 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00790: val_acc did not improve from 0.98948\n",
      "Epoch 791/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0394 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00791: val_acc did not improve from 0.98948\n",
      "Epoch 792/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0395 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00792: val_acc did not improve from 0.98948\n",
      "Epoch 793/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0417 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00793: val_acc did not improve from 0.98948\n",
      "Epoch 794/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0530 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00794: val_acc did not improve from 0.98948\n",
      "Epoch 795/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0415 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00795: val_acc did not improve from 0.98948\n",
      "Epoch 796/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0394 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00796: val_acc did not improve from 0.98948\n",
      "Epoch 797/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00797: val_acc did not improve from 0.98948\n",
      "Epoch 798/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0424 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00798: val_acc did not improve from 0.98948\n",
      "Epoch 799/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0415 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00799: val_acc did not improve from 0.98948\n",
      "Epoch 800/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9972 - val_loss: 0.0400 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00800: val_acc did not improve from 0.98948\n",
      "Epoch 801/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0398 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00801: val_acc did not improve from 0.98948\n",
      "Epoch 802/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0396 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00802: val_acc did not improve from 0.98948\n",
      "Epoch 803/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0445 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00803: val_acc did not improve from 0.98948\n",
      "Epoch 804/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0391 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00804: val_acc did not improve from 0.98948\n",
      "Epoch 805/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0426 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00805: val_acc did not improve from 0.98948\n",
      "Epoch 806/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0407 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00806: val_acc did not improve from 0.98948\n",
      "Epoch 807/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0403 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00807: val_acc did not improve from 0.98948\n",
      "Epoch 808/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0410 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00808: val_acc did not improve from 0.98948\n",
      "Epoch 809/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0415 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00809: val_acc did not improve from 0.98948\n",
      "Epoch 810/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0419 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00810: val_acc did not improve from 0.98948\n",
      "Epoch 811/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0401 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00811: val_acc did not improve from 0.98948\n",
      "Epoch 812/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0405 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00812: val_acc did not improve from 0.98948\n",
      "Epoch 813/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0409 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00813: val_acc did not improve from 0.98948\n",
      "Epoch 814/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0441 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00814: val_acc did not improve from 0.98948\n",
      "Epoch 815/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0426 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00815: val_acc did not improve from 0.98948\n",
      "Epoch 816/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9971 - val_loss: 0.0408 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00816: val_acc did not improve from 0.98948\n",
      "Epoch 817/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0408 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00817: val_acc did not improve from 0.98948\n",
      "Epoch 818/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0412 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00818: val_acc did not improve from 0.98948\n",
      "Epoch 819/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0396 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00819: val_acc did not improve from 0.98948\n",
      "Epoch 820/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9970 - val_loss: 0.0392 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00820: val_acc did not improve from 0.98948\n",
      "Epoch 821/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9972 - val_loss: 0.0395 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00821: val_acc did not improve from 0.98948\n",
      "Epoch 822/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0425 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00822: val_acc did not improve from 0.98948\n",
      "Epoch 823/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0406 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00823: val_acc did not improve from 0.98948\n",
      "Epoch 824/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0399 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00824: val_acc did not improve from 0.98948\n",
      "Epoch 825/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0399 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00825: val_acc did not improve from 0.98948\n",
      "Epoch 826/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0399 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00826: val_acc did not improve from 0.98948\n",
      "Epoch 827/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9969 - val_loss: 0.0414 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00827: val_acc did not improve from 0.98948\n",
      "Epoch 828/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0432 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00828: val_acc did not improve from 0.98948\n",
      "Epoch 829/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0421 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00829: val_acc did not improve from 0.98948\n",
      "Epoch 830/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0060 - acc: 0.9973 - val_loss: 0.0400 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00830: val_acc did not improve from 0.98948\n",
      "Epoch 831/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0412 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00831: val_acc did not improve from 0.98948\n",
      "Epoch 832/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0415 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00832: val_acc did not improve from 0.98948\n",
      "Epoch 833/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0405 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00833: val_acc did not improve from 0.98948\n",
      "Epoch 834/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0422 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00834: val_acc did not improve from 0.98948\n",
      "Epoch 835/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0407 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00835: val_acc did not improve from 0.98948\n",
      "Epoch 836/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0403 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00836: val_acc did not improve from 0.98948\n",
      "Epoch 837/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0408 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00837: val_acc did not improve from 0.98948\n",
      "Epoch 838/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0230 - acc: 0.9934 - val_loss: 0.0383 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00838: val_acc did not improve from 0.98948\n",
      "Epoch 839/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0391 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00839: val_acc did not improve from 0.98948\n",
      "Epoch 840/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9973 - val_loss: 0.0398 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00840: val_acc did not improve from 0.98948\n",
      "Epoch 841/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0403 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00841: val_acc did not improve from 0.98948\n",
      "Epoch 842/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0417 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00842: val_acc did not improve from 0.98948\n",
      "Epoch 843/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0387 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00843: val_acc did not improve from 0.98948\n",
      "Epoch 844/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0410 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00844: val_acc did not improve from 0.98948\n",
      "Epoch 845/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0403 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00845: val_acc did not improve from 0.98948\n",
      "Epoch 846/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0391 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00846: val_acc did not improve from 0.98948\n",
      "Epoch 847/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0411 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00847: val_acc did not improve from 0.98948\n",
      "Epoch 848/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0398 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00848: val_acc did not improve from 0.98948\n",
      "Epoch 849/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0451 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00849: val_acc did not improve from 0.98948\n",
      "Epoch 850/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9973 - val_loss: 0.0408 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00850: val_acc did not improve from 0.98948\n",
      "Epoch 851/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0510 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00851: val_acc did not improve from 0.98948\n",
      "Epoch 852/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0459 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00852: val_acc did not improve from 0.98948\n",
      "Epoch 853/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0411 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00853: val_acc did not improve from 0.98948\n",
      "Epoch 854/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0417 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00854: val_acc did not improve from 0.98948\n",
      "Epoch 855/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00855: val_acc did not improve from 0.98948\n",
      "Epoch 856/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0397 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00856: val_acc did not improve from 0.98948\n",
      "Epoch 857/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9973 - val_loss: 0.0403 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00857: val_acc did not improve from 0.98948\n",
      "Epoch 858/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0395 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00858: val_acc did not improve from 0.98948\n",
      "Epoch 859/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9973 - val_loss: 0.0406 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00859: val_acc did not improve from 0.98948\n",
      "Epoch 860/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0453 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00860: val_acc did not improve from 0.98948\n",
      "Epoch 861/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0408 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00861: val_acc did not improve from 0.98948\n",
      "Epoch 862/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0446 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00862: val_acc did not improve from 0.98948\n",
      "Epoch 863/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0426 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00863: val_acc did not improve from 0.98948\n",
      "Epoch 864/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0420 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00864: val_acc did not improve from 0.98948\n",
      "Epoch 865/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0416 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00865: val_acc did not improve from 0.98948\n",
      "Epoch 866/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0402 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00866: val_acc did not improve from 0.98948\n",
      "Epoch 867/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0431 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00867: val_acc did not improve from 0.98948\n",
      "Epoch 868/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0405 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00868: val_acc did not improve from 0.98948\n",
      "Epoch 869/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00869: val_acc did not improve from 0.98948\n",
      "Epoch 870/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0410 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00870: val_acc did not improve from 0.98948\n",
      "Epoch 871/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9973 - val_loss: 0.0460 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00871: val_acc did not improve from 0.98948\n",
      "Epoch 872/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0413 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00872: val_acc did not improve from 0.98948\n",
      "Epoch 873/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0429 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00873: val_acc did not improve from 0.98948\n",
      "Epoch 874/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0411 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00874: val_acc did not improve from 0.98948\n",
      "Epoch 875/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0416 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00875: val_acc did not improve from 0.98948\n",
      "Epoch 876/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0469 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00876: val_acc did not improve from 0.98948\n",
      "Epoch 877/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0489 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00877: val_acc did not improve from 0.98948\n",
      "Epoch 878/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9973 - val_loss: 0.0402 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00878: val_acc did not improve from 0.98948\n",
      "Epoch 879/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0411 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00879: val_acc did not improve from 0.98948\n",
      "Epoch 880/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0418 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00880: val_acc did not improve from 0.98948\n",
      "Epoch 881/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0420 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00881: val_acc did not improve from 0.98948\n",
      "Epoch 882/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0444 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00882: val_acc did not improve from 0.98948\n",
      "Epoch 883/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0429 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00883: val_acc did not improve from 0.98948\n",
      "Epoch 884/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0464 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00884: val_acc did not improve from 0.98948\n",
      "Epoch 885/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9973 - val_loss: 0.0406 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00885: val_acc did not improve from 0.98948\n",
      "Epoch 886/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0411 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00886: val_acc did not improve from 0.98948\n",
      "Epoch 887/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0413 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00887: val_acc did not improve from 0.98948\n",
      "Epoch 888/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9970 - val_loss: 0.0410 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00888: val_acc did not improve from 0.98948\n",
      "Epoch 889/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0062 - acc: 0.9969 - val_loss: 0.0417 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00889: val_acc did not improve from 0.98948\n",
      "Epoch 890/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0397 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00890: val_acc did not improve from 0.98948\n",
      "Epoch 891/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0422 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00891: val_acc did not improve from 0.98948\n",
      "Epoch 892/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0405 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00892: val_acc did not improve from 0.98948\n",
      "Epoch 893/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0409 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00893: val_acc did not improve from 0.98948\n",
      "Epoch 894/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9971 - val_loss: 0.0440 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00894: val_acc did not improve from 0.98948\n",
      "Epoch 895/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0420 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00895: val_acc did not improve from 0.98948\n",
      "Epoch 896/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0422 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00896: val_acc did not improve from 0.98948\n",
      "Epoch 897/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0397 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00897: val_acc did not improve from 0.98948\n",
      "Epoch 898/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0407 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00898: val_acc did not improve from 0.98948\n",
      "Epoch 899/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9970 - val_loss: 0.0409 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00899: val_acc did not improve from 0.98948\n",
      "Epoch 900/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00900: val_acc did not improve from 0.98948\n",
      "Epoch 901/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0436 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00901: val_acc did not improve from 0.98948\n",
      "Epoch 902/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9973 - val_loss: 0.0415 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00902: val_acc did not improve from 0.98948\n",
      "Epoch 903/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0404 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00903: val_acc did not improve from 0.98948\n",
      "Epoch 904/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0422 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00904: val_acc did not improve from 0.98948\n",
      "Epoch 905/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0407 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00905: val_acc did not improve from 0.98948\n",
      "Epoch 906/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0440 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00906: val_acc did not improve from 0.98948\n",
      "Epoch 907/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0405 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00907: val_acc did not improve from 0.98948\n",
      "Epoch 908/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0457 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00908: val_acc did not improve from 0.98948\n",
      "Epoch 909/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9969 - val_loss: 0.0401 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00909: val_acc did not improve from 0.98948\n",
      "Epoch 910/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00910: val_acc did not improve from 0.98948\n",
      "Epoch 911/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0424 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00911: val_acc did not improve from 0.98948\n",
      "Epoch 912/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0408 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00912: val_acc did not improve from 0.98948\n",
      "Epoch 913/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0423 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00913: val_acc did not improve from 0.98948\n",
      "Epoch 914/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0409 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00914: val_acc did not improve from 0.98948\n",
      "Epoch 915/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0061 - acc: 0.9970 - val_loss: 0.0417 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00915: val_acc did not improve from 0.98948\n",
      "Epoch 916/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9969 - val_loss: 0.0406 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00916: val_acc did not improve from 0.98948\n",
      "Epoch 917/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0415 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00917: val_acc did not improve from 0.98948\n",
      "Epoch 918/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0406 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00918: val_acc did not improve from 0.98948\n",
      "Epoch 919/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0407 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00919: val_acc did not improve from 0.98948\n",
      "Epoch 920/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9973 - val_loss: 0.0432 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00920: val_acc did not improve from 0.98948\n",
      "Epoch 921/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0429 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00921: val_acc did not improve from 0.98948\n",
      "Epoch 922/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0414 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00922: val_acc did not improve from 0.98948\n",
      "Epoch 923/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0415 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00923: val_acc did not improve from 0.98948\n",
      "Epoch 924/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0451 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00924: val_acc did not improve from 0.98948\n",
      "Epoch 925/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9970 - val_loss: 0.0421 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00925: val_acc did not improve from 0.98948\n",
      "Epoch 926/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0409 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00926: val_acc did not improve from 0.98948\n",
      "Epoch 927/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9969 - val_loss: 0.0413 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00927: val_acc did not improve from 0.98948\n",
      "Epoch 928/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0412 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00928: val_acc did not improve from 0.98948\n",
      "Epoch 929/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9973 - val_loss: 0.0405 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00929: val_acc did not improve from 0.98948\n",
      "Epoch 930/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0415 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00930: val_acc did not improve from 0.98948\n",
      "Epoch 931/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9970 - val_loss: 0.0415 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00931: val_acc did not improve from 0.98948\n",
      "Epoch 932/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0429 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00932: val_acc did not improve from 0.98948\n",
      "Epoch 933/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0407 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00933: val_acc did not improve from 0.98948\n",
      "Epoch 934/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0424 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00934: val_acc did not improve from 0.98948\n",
      "Epoch 935/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9973 - val_loss: 0.0420 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00935: val_acc did not improve from 0.98948\n",
      "Epoch 936/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0403 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00936: val_acc did not improve from 0.98948\n",
      "Epoch 937/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0423 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00937: val_acc did not improve from 0.98948\n",
      "Epoch 938/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9972 - val_loss: 0.0452 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00938: val_acc did not improve from 0.98948\n",
      "Epoch 939/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00939: val_acc did not improve from 0.98948\n",
      "Epoch 940/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0440 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00940: val_acc did not improve from 0.98948\n",
      "Epoch 941/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9973 - val_loss: 0.0429 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00941: val_acc did not improve from 0.98948\n",
      "Epoch 942/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0407 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00942: val_acc did not improve from 0.98948\n",
      "Epoch 943/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0412 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00943: val_acc did not improve from 0.98948\n",
      "Epoch 944/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0397 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00944: val_acc did not improve from 0.98948\n",
      "Epoch 945/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0416 - val_acc: 0.9886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00945: val_acc did not improve from 0.98948\n",
      "Epoch 946/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9973 - val_loss: 0.0444 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00946: val_acc did not improve from 0.98948\n",
      "Epoch 947/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0426 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00947: val_acc did not improve from 0.98948\n",
      "Epoch 948/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0435 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00948: val_acc did not improve from 0.98948\n",
      "Epoch 949/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9971 - val_loss: 0.0425 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00949: val_acc did not improve from 0.98948\n",
      "Epoch 950/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0410 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00950: val_acc did not improve from 0.98948\n",
      "Epoch 951/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0418 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00951: val_acc did not improve from 0.98948\n",
      "Epoch 952/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0415 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00952: val_acc did not improve from 0.98948\n",
      "Epoch 953/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0403 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00953: val_acc did not improve from 0.98948\n",
      "Epoch 954/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0408 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00954: val_acc did not improve from 0.98948\n",
      "Epoch 955/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0412 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00955: val_acc did not improve from 0.98948\n",
      "Epoch 956/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0412 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00956: val_acc did not improve from 0.98948\n",
      "Epoch 957/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9971 - val_loss: 0.0409 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00957: val_acc did not improve from 0.98948\n",
      "Epoch 958/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9973 - val_loss: 0.0420 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00958: val_acc did not improve from 0.98948\n",
      "Epoch 959/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9970 - val_loss: 0.0443 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00959: val_acc did not improve from 0.98948\n",
      "Epoch 960/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0450 - val_acc: 0.9874\n",
      "\n",
      "Epoch 00960: val_acc did not improve from 0.98948\n",
      "Epoch 961/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0416 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00961: val_acc did not improve from 0.98948\n",
      "Epoch 962/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0434 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00962: val_acc did not improve from 0.98948\n",
      "Epoch 963/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0428 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00963: val_acc did not improve from 0.98948\n",
      "Epoch 964/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0406 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00964: val_acc did not improve from 0.98948\n",
      "Epoch 965/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9971 - val_loss: 0.0401 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00965: val_acc did not improve from 0.98948\n",
      "Epoch 966/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9970 - val_loss: 0.0454 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00966: val_acc did not improve from 0.98948\n",
      "Epoch 967/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0399 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00967: val_acc did not improve from 0.98948\n",
      "Epoch 968/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0398 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00968: val_acc did not improve from 0.98948\n",
      "Epoch 969/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0439 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00969: val_acc did not improve from 0.98948\n",
      "Epoch 970/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0408 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00970: val_acc did not improve from 0.98948\n",
      "Epoch 971/1000\n",
      "109429/109429 [==============================] - 1s 10us/step - loss: 0.0057 - acc: 0.9972 - val_loss: 0.0415 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00971: val_acc did not improve from 0.98948\n",
      "Epoch 972/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0420 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00972: val_acc did not improve from 0.98948\n",
      "Epoch 973/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9971 - val_loss: 0.0445 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00973: val_acc did not improve from 0.98948\n",
      "Epoch 974/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0412 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00974: val_acc did not improve from 0.98948\n",
      "Epoch 975/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0417 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00975: val_acc did not improve from 0.98948\n",
      "Epoch 976/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0408 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00976: val_acc did not improve from 0.98948\n",
      "Epoch 977/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0413 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00977: val_acc did not improve from 0.98948\n",
      "Epoch 978/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0416 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00978: val_acc did not improve from 0.98948\n",
      "Epoch 979/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0416 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00979: val_acc did not improve from 0.98948\n",
      "Epoch 980/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9970 - val_loss: 0.0423 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00980: val_acc did not improve from 0.98948\n",
      "Epoch 981/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0412 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00981: val_acc did not improve from 0.98948\n",
      "Epoch 982/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0422 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00982: val_acc did not improve from 0.98948\n",
      "Epoch 983/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0057 - acc: 0.9973 - val_loss: 0.0398 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00983: val_acc did not improve from 0.98948\n",
      "Epoch 984/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0443 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00984: val_acc did not improve from 0.98948\n",
      "Epoch 985/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9971 - val_loss: 0.0421 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00985: val_acc did not improve from 0.98948\n",
      "Epoch 986/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0411 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00986: val_acc did not improve from 0.98948\n",
      "Epoch 987/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9973 - val_loss: 0.0419 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00987: val_acc did not improve from 0.98948\n",
      "Epoch 988/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0444 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00988: val_acc did not improve from 0.98948\n",
      "Epoch 989/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0060 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00989: val_acc did not improve from 0.98948\n",
      "Epoch 990/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9971 - val_loss: 0.0405 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00990: val_acc did not improve from 0.98948\n",
      "Epoch 991/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0407 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00991: val_acc did not improve from 0.98948\n",
      "Epoch 992/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9972 - val_loss: 0.0411 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00992: val_acc did not improve from 0.98948\n",
      "Epoch 993/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9971 - val_loss: 0.0430 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00993: val_acc did not improve from 0.98948\n",
      "Epoch 994/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0416 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00994: val_acc did not improve from 0.98948\n",
      "Epoch 995/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0425 - val_acc: 0.9882\n",
      "\n",
      "Epoch 00995: val_acc did not improve from 0.98948\n",
      "Epoch 996/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9970 - val_loss: 0.0412 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00996: val_acc did not improve from 0.98948\n",
      "Epoch 997/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9970 - val_loss: 0.0411 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00997: val_acc did not improve from 0.98948\n",
      "Epoch 998/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0428 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00998: val_acc did not improve from 0.98948\n",
      "Epoch 999/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0058 - acc: 0.9972 - val_loss: 0.0416 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00999: val_acc did not improve from 0.98948\n",
      "Epoch 1000/1000\n",
      "109429/109429 [==============================] - 1s 9us/step - loss: 0.0059 - acc: 0.9971 - val_loss: 0.0453 - val_acc: 0.9878\n",
      "\n",
      "Epoch 01000: val_acc did not improve from 0.98948\n"
     ]
    }
   ],
   "source": [
    "model, nnStr = createModel(filters, filterShape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = loadData()\n",
    "\n",
    "fitHistory = trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (109429, 4, 8, 8)\n",
      "y_train shape: (109429, 1)\n",
      "X_test shape: (53899, 4, 8, 8)\n",
      "y_test shape: (53899, 1)\n",
      "109429 train samples\n",
      "53899 test samples\n",
      "53899/53899 [==============================] - 2s 42us/step\n",
      "Evaluated test loss: 0.018895605267997804\n",
      "Evaluated test accuracy: 0.9939145438690885\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = calcScore()\n",
    "\n",
    "saveTrainResults()\n",
    "\n",
    "# compareResults('005','013', metric1='acc', metric2='acc', saveFigName = 'testmynd', makeEqual = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. train on 3pc\n",
    "2. **transfer to 4pc**\n",
    "3. train 4pc from start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING TEMPLATE CODE\n",
    "import math\n",
    "\n",
    "# What data to use\n",
    "tableBase = '4PpKk'\n",
    "convertStates = False\n",
    "fractionOfDataToUse = 1 # [0,1]\n",
    "\n",
    "# Transfer Learning\n",
    "loadWeights = True \n",
    "weightsSource = '024'\n",
    "\n",
    "# Compare with other result during training\n",
    "compareResultsDuringTraining = False\n",
    "compareWith = '013' # orginal net structure, trained from random on 4pc dataset\n",
    "\n",
    "\n",
    "# NN parameters\n",
    "# filters = [8,16,16,32,32]    #016:0.913  10kpm 2048:30                  8192:23:38% 32768:17:52% \n",
    "# filters = [8,16,32,64,128]   #005:0.952  50kpm 2048:37s    4096:28:50% \n",
    "filters = [8,32,64,128,256]  #013:0.968 188kpm 2048:50s    4096:40s:61%             32768:46s:80% 65536:42s:99% \n",
    "# filters = [32,64,128,160,256]#014:0.974 388kpm 2048:3m:91% \n",
    "filterShape = [2,2,2,2,2]\n",
    "batch_size = 2048\n",
    "epochs = 600\n",
    "\n",
    "# Other paramters\n",
    "confirmDirOverwrite = False\n",
    "\n",
    "\n",
    "### NO NEED TO MODIFY BELOW ###\n",
    "# Generate dataset variables\n",
    "fileName = tableBase + '.hdf5'\n",
    "dataSetName = tableBase + '_onlyLegal'\n",
    "if not convertStates: \n",
    "    dataSetName = tableBase + '_onlyLegal_fullState'\n",
    "dataSetWdlName = tableBase + '_Wdl_onlyLegal'\n",
    "\n",
    "# Number of Pieces\n",
    "nPi =  int(dataSetName[0])\n",
    "nPa = nPi - 2\n",
    "nWPa = math.ceil(nPa/2)\n",
    "\n",
    "# Other NN stuff\n",
    "num_classes = 5\n",
    "input_shape = (4,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of last epoch:  0.8440740174340361\n",
      "Validation Accuracy of last epoch:  0.891251512893857\n",
      "Train Loss of last epoch:  0.36972765831312904\n",
      "Validation Loss of last epoch:  0.25865178328182514\n",
      "Epoch 2/300\n",
      "4581376/4982178 [==========================>...] - ETA: 3s - loss: 0.2281 - acc: 0.9032"
     ]
    }
   ],
   "source": [
    "model, nnStr = createModel(filters, filterShape, loadWeights, weightsSource)\n",
    "\n",
    "X_train, X_test, y_train, y_test = loadData()\n",
    "\n",
    "fitHistory = trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2453910/2453910 [==============================] - 121s 50us/step\n",
      "Evaluated test loss: 0.11263863526407211\n",
      "Evaluated test accuracy: 0.964085072394911\n",
      "Save dir: Results/028\n",
      "Creating save dir\n",
      "Saving history...\n",
      "Saving weights...\n",
      "Saving figures...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving summary...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "score = calcScore()\n",
    "saveTrainResults()\n",
    "# compareResults('005','013', metric1='acc', metric2='acc', saveFigName = 'testmynd', makeEqual = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. train on 3pc\n",
    "2. transfer to 4pc\n",
    "3. **train 4pc from start**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of last epoch:  0.9769988145733779\n",
      "Validation Accuracy of last epoch:  0.9619741555313279\n",
      "Train Loss of last epoch:  0.05795736570648465\n",
      "Validation Loss of last epoch:  0.10984990670707757\n"
     ]
    }
   ],
   "source": [
    "# Transfer Learning\n",
    "loadWeights = False \n",
    "weightsSource = '024'\n",
    "\n",
    "compareResultsDuringTraining = False\n",
    "compareWith = '026' # orginal net structure, trained from random on 4pc dataset\n",
    "\n",
    "model, nnStr = createModel(filters, filterShape)\n",
    "X_train, X_test, y_train, y_test = loadData()\n",
    "fitHistory = trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2453910/2453910 [==============================] - 120s 49us/step\n",
      "Evaluated test loss: 0.10984990601903802\n",
      "Evaluated test accuracy: 0.9619741555312307\n",
      "Save dir: Results/026\n",
      "Creating save dir\n",
      "Saving history...\n",
      "Saving weights...\n",
      "Saving figures...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving summary...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "score = calcScore()\n",
    "\n",
    "saveTrainResults()\n",
    "\n",
    "# compareResults('005','013', metric1='acc', metric2='acc', saveFigName = 'testmynd', makeEqual = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:endnetGpu]",
   "language": "python",
   "name": "conda-env-endnetGpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
