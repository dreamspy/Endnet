{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which GPU to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiGPU = False\n",
    "whichGPU = 1\n",
    " \n",
    "# Select which GPU to use\n",
    "if(multiGPU):\n",
    "    from keras.utils.training_utils import multi_gpu_model\n",
    "else:\n",
    "    import os\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    # The GPU id to use, usually either \"0\" or \"1\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(whichGPU)\n",
    "    \n",
    "# # Do other imports now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run -i 'arena.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 1\n",
    "# %aimport arena\n",
    "# %reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING TEMPLATE CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "##### TRAINING TEMPLATE CODE\n",
    "\n",
    "##############################\n",
    "#\n",
    "#    PARAMETERS \n",
    "#\n",
    "##############################\n",
    "import math\n",
    "\n",
    "# Experiment description\n",
    "expDescr = \"Experiment description text\"\n",
    "\n",
    "# What data to use\n",
    "tableBase = '4PpKk'\n",
    "convertStates = False\n",
    "fractionOfDataToUse = 1 # [0,1]\n",
    "\n",
    "# Interactive (just in general if one is asked for confirmations, set to False if on autopilot over night f.x.)\n",
    "askForConfirmation = True\n",
    "\n",
    "# Transfer Learning\n",
    "loadWeights = False \n",
    "weightsSource = '024'\n",
    "loadCheckpointWeights = False\n",
    "\n",
    "# Plot during training\n",
    "plotDuringTraining = True\n",
    "compareResultsDuringTraining = False\n",
    "compareWith = '013' # orginal net structure, trained from random on 4pc dataset\n",
    "\n",
    "\n",
    "# NN parameters\n",
    "# filters = [8,16,16,32,32]    #016:0.913  10kpm 2048:30                  8192:23:38% 32768:17:52% \n",
    "# filters = [8,16,32,64,128]   #005:0.952  50kpm 2048:37s    4096:28:50% \n",
    "# filters = [8,32,64,128,256]  #013:0.968 188kpm 2048:50s    4096:40s:61%             32768:46s:80% 65536:42s:99% \n",
    "# filters = [32,64,128,160,256]#014:0.974 388kpm 2048:3m:91% \n",
    "# filters = [16,32,64,128,128,128]#035:0.975 191kpm 2048:45s:50%/50% 2048:68s:78% \n",
    "# filters = [16,16,32,32,64,64,128] #054 70kpm\n",
    "# filters = [16,16,32,32,64,64,128] #054 70kpm\n",
    "filters = [16,32,32,64,128,128,128]\n",
    "filterShape = [2,2,2,2,2,2,2]\n",
    "batch_size = 256\n",
    "epochs = 150\n",
    "multiGPU = False\n",
    "whichGPU = 0\n",
    "# optimizer = 'Adam'\n",
    "optimizer = 'Adadelta'\n",
    "useBatchNorm = False\n",
    "\n",
    "# Other paramters\n",
    "confirmDirOverwrite = False\n",
    "tPrintInterval = 0.5 # for print progress\n",
    "yieldSize = 10000 # for load generator\n",
    "\n",
    "### NO NEED TO MODIFY BELOW ###\n",
    "# Generate dataset variables\n",
    "fileName = tableBase + '.hdf5'\n",
    "dataSetName = tableBase + '_onlyLegal'\n",
    "if not convertStates: \n",
    "    dataSetName = tableBase + '_onlyLegal_fullStates'\n",
    "dataSetWdlName = tableBase + '_Wdl_onlyLegal_3Values'\n",
    "\n",
    "# Number of Pieces\n",
    "nPi =  int(dataSetName[0])\n",
    "nPa = nPi - 2\n",
    "nWPa = math.ceil(nPa/2)\n",
    "\n",
    "# Select which GPU to use\n",
    "# if(multiGPU):\n",
    "#     from keras.utils.training_utils import multi_gpu_model\n",
    "# else:\n",
    "#     import os\n",
    "#     os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#     # The GPU id to use, usually either \"0\" or \"1\"\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(whichGPU)\n",
    "    \n",
    "# Other NN stuff\n",
    "num_classes = 3\n",
    "input_shape = (4,8,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n"
     ]
    }
   ],
   "source": [
    "# Train, evaluate and save \n",
    "# %reload_ext autoreload\n",
    "model, nnStr = createModel()\n",
    "# resID = genNextResultsDir(model)\n",
    "# X_train, X_test, y_train, y_test = loadData()\n",
    "# score = calcScoreBigData(model)\n",
    "# score = calcScore(model)\n",
    "# saveTrainResults(resID, model, logDir, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### many batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and save with different paramters\n",
    "X_train, X_test, y_train, y_test = loadData()\n",
    "\n",
    "bs = [256,256,256,512,512,512,1024,1024,1024]\n",
    "\n",
    "for batch_size in bs:\n",
    "    expDescr = \"Testing batch size effect for 70kpm network (7 CNN layers) {}bs\".format(batch_size) \n",
    "    print(\"---------------------- batch size \", batch_size, '-------------------------------')\n",
    "    model, nnStr = createModel()\n",
    "    resID = genNextResultsDir(model)\n",
    "    fitHistory, logDir = trainModel(resID, model)\n",
    "    score = calcScore(model)\n",
    "    saveTrainResults(resID, model, logDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bengio Template Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4982178, 4, 8, 8)\n",
      "y_train shape: (4982178, 1)\n",
      "X_test shape: (2453910, 4, 8, 8)\n",
      "y_test shape: (2453910, 1)\n",
      "4982178 train samples\n",
      "2453910 test samples\n",
      "Done loading dataset\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n",
      "Loading weights from Results/103/weights.hdf5, keeping first 0 layers.\n",
      "- Resetting layer nr 1: <keras.layers.convolutional.Conv2D object at 0x7f38c87524a8>\n",
      "- Resetting layer nr 2: <keras.layers.convolutional.Conv2D object at 0x7f38c8752780>\n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f38ca8dbac8>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3503f21048>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f38c7c5a358>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3528071780>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f38c668bcf8>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38c66912e8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f38c6691b00>\n",
      "Save dir: Results/177/\n",
      "Creating save dir\n",
      "Done generating results dir Results/177/\n",
      "Saving weights to Results/177/weightsCheckpoints/\n",
      "Train on 4982178 samples, validate on 2453910 samples\n",
      "Epoch 1/20\n",
      "4980992/4982178 [============================>.] - ETA: 0s - loss: 0.2548 - acc: 0.8906"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/projects/Endnet/mainCode/arena.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mfitHistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# score and save accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Endnet/mainCode/arena.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(resID, model)\u001b[0m\n\u001b[1;32m    488\u001b[0m                                       keras.callbacks.TensorBoard(log_dir=logDir)],\n\u001b[1;32m    489\u001b[0m \u001b[0;31m#                          .format(resID,nPi, initWeightsId, kpm, int(time() - 1500000000)))],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                            validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfitHistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogDir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2633\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2636\u001b[0m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     \"\"\"\n\u001b[1;32m   1413\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1368\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1369\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3n4 noFreeze\n",
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103'\n",
    "freeze = False\n",
    "epochs = 20\n",
    "resSaveFile = '3n4plus'\n",
    "\n",
    "fractionOfDataToUse = 1\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "saveDir = 'bengioResults'\n",
    "\n",
    "X_train, X_test, y_train, y_test = loadData()\n",
    "model, nnStr = createModel()\n",
    "results = []\n",
    "currentAverage = 0\n",
    "averageOver = \n",
    "layersCount = len(model.layers)\n",
    "\n",
    "for copyFirstNLayers in range(layersCount + 1):\n",
    "    if copyFirstNLayers != layersCount - 1:\n",
    "        model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "        resID = genNextResultsDir(model)\n",
    "        #add freeze and some tl parameters to save dir\n",
    "\n",
    "        # train\n",
    "        fitHistory, logDir = trainModel(resID, model)\n",
    "\n",
    "        # score and save accuracy\n",
    "        score = calcScore(model)\n",
    "        saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "        results.append(score[1])\n",
    "\n",
    "        # save results incrementally to txt file\n",
    "        save_obj(bengioResults, resSaveFile, results)\n",
    "        with open(bengioResults + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "            file.write(str(results))\n",
    "            \n",
    "        # to load:\n",
    "        # results = load_obj('temp','3n4.txt')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAGfCAYAAAATcNWCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xd8Tff/wPHXyUYiQSREQuxIiJEIIVTsvdtqlaq22qKq7a9Fh9UqWl1Up5ZWW+qr9t57EzOJHcSKIIjIvOf3x0FVkUTuveeO9/PxyEPGuefzPonkvu/5vD+ft6KqKkIIIYQQQh8OegcghBBCCGHPJBkTQgghhNCRJGNCCCGEEDqSZEwIIYQQQkeSjAkhhBBC6EiSMSGEEEIIHUkyJoQQQgihI0nGhBBCCCF0JMmYEEIIIYSOnPQOID+8vb3VwMBAk45x8+ZNihQpYtIxLJk9X79cu31eO9j39dvztYN9X79cu+mvfffu3cmqqpbM7TirSsYCAwPZtWuXScdYt24dTZo0MekYlsyer1+uvYneYejGnq/fnq8d7Pv65dqbmHwcRVFO5eU4maYUQgghhNCRJGNCCCGEEDqSZEwIIYQQQkdWVTMmhBBCCPPIysoiMTGR9PR0vUMxOk9PT+Li4ox2Pjc3N/z9/XF2dn6sx0syJoQQQoj/SExMxMPDg8DAQBRF0Tsco7px4wYeHh5GOZeqqly+fJnExETKly//WOeQaUohhBBC/Ed6ejolSpSwuUTM2BRFoUSJEgW6gyjJmBBCCCEeSBKxvCno90mSMSGEEEIIHUkyJoQQQgiLlJ6eTkREBDVr1iQkJIQRI0bk6XE7d+7EycmJ2bNnmzhC45ACfiGEEEJYJFdXV9asWYO7uztZWVlERUXRpk0b6tev/9DH5OTkMGTIEFq2bGnGSAtG7owJIYQQwiIpioK7uzugbbWRlZWFoigEBgYyYsQI6tSpQ40aNYiPj7/7mEmTJtGtWzd8fHz0CjvfJBkTQgghhMXKycmhVq1a+Pj40KJFC+rVqweAt7c3e/bs4bXXXmPChAkAnD17lrlz5/Laa6/pGXK+yTSlEEIIIXIVOHSx0c+ZMK5drsc4Ojqyd+9eUlJS6NKlCwcPHgSga9euAISFhTFnzhwABg8ezPjx43FwsK57TZKMCSGEECJXeUmcTMnLy4vo6GiWLVsGaPVkoCVr2dnZAOzatYsePXoAkJyczJIlS3BycqJz5876BJ1H1pU6CiGEEMJuXLp0iZSUFABu3brFypUrCQoKeujxJ0+eJCEhgYSEBLp37863335r8YkYSDImhEg+RtiutyDJeH3ahBDCGM6fP090dDShoaHUrVuXFi1a0L59e73DMjqZphTC3i0fRoZrCTx+7QjP/gVl6ugdkRBCABAaGkpMTMx/Pp+QkHD3/fDwcNatW/efY6ZNm2a6wIxM7owJYc8OL4MrJzkU8i50+Ar+eBISNusdlRBC2BVJxoSwV9kZsGwotBmH6uAMQe2g2xSY1QuOrtI7OiGEsBuSjAlhr7ZOBp9gqNT8n89VjIYeM2Deq3Bonn6xCSGEHZGaMSHs0fVzsGUSvLzmv18rWw+emwN/dIfMm1C7p/njE0IIOyJ3xoSwRyuHQ3hfKF7+wV8vHQrPL4K1n8D2H8wbmxBC2BlJxoSwN6e2am+N3nr0cSWrwAtLYNt3sOEzUFXzxCeEEHZGkjEh7IkhB5a+Ay1Hg0uR3I8vVg76LoMDf2t30yQhE0KYUXp6OhEREdSsWZOQkBBGjBiRp8ft3LkTJycnZs+eneuxgYGBJCcnFzTUApFkTAh7sudXcC0KIV3z/hiPUtodsoSNsPgtMBhMF58QQtzD1dWVNWvWsG/fPvbu3cuyZcvYtm3bIx+Tk5PDkCFDaNmypZmiLDhJxoSwF2lXtBqwNuNBUfL32MLFofcCuHQY5r4COVmmiVEIIe6hKAru7u4AZGVlkZWVhaIoBAYGMmLECOrUqUONGjWIj4+/+5hJkybRrVs3fHx87n5u3bp1NG7cmHbt2lG1alUGDx6M4b4XlgkJCVSvXv3uxxMmTGDkyJEATJw4keDgYEJDQ+/2vjQmScaEsBdrP4HgTlCqxuM93q0o9JwNt67CrOchK9248QkhxAPk5ORQq1YtfHx8aNGiBfXq1QPA29ubPXv28NprrzFhwgQAzp49y9y5c3nttdf+c54dO3YwadIkYmNjOXnyJHPmzMlzDOPGjSMmJob9+/fz/fffG+fC7iFbWwhhDy4chNh5MGBHwc7jUhh6/AlzXoY/n9Led3U3ToxCCMs20tME57yW6yGOjo7s3buXlJQUunTpwsGDBwHo2lUrtwgLC7ubWA0ePJjx48fj4PDfe00RERFUqFABgO7du7Np0ya6d++epzBDQ0Pp2bMnnTt3NknjcUnGhLB1qgpL34Umw7TpxoJycoHuv8CCQTC9C/T8HxTyKvh5hRCWLQ+Jkyl5eXkRHR3NsmXLAK2eDLRkLTs7G4Bdu3bdnUZMTk5myZIlODk54eXlhXJfecb9Hzs5Of1r6jI9/Z+7/4sXL2bDhg0sXLiQMWPGcODAAZycjJdCyTSlELbu0BzIuA5hfYx3TgdH6DhJayo+rT2kXjLeuYUQ4rZLly6RkpICwK1bt1i5ciVBQUEPPf7kyZMkJCSQkJBA9+7d+fbbb+/eydqxYwcnT57EYDDw999/ExUV9a/H+vr6kpSUxOXLl8nIyGDRokUAGAwGzpw5Q3R0NOPHj+fatWukpqYa9TolGRPClmXehBXDoc1nWgJlTA4O0HocVG0DU9vAtUTjnl8IYffOnz9PdHQ0oaGh1K1blxYtWtC+ffvHOlfdunUZOHAg1apVIzAwkC5duvzr687OzgwfPpyIiAhatGhxN+nLycnhueeeo0aNGtSuXZtBgwbh5WXc2QCZphT/OLYaRbYtsC2bvoRykdqbKSgKNH0fXD20hKzXPChR0TRjCSHsTmhoKDExMf/5fEJCwt33w8PDWbdu3X+OmTZt2r8+Llq06N27XTdu3LhbV3bvuQYNGsSgQYP+c65NmzblP/h8kDtjQpOaBL93o9ypWXpHIozlyknY+TO0GG36sRoOgqi3tCnLi7GmH08IIWyIJGNCE7cQKjTB79wKOFPAFXfCMix/HxoMhKJ+5hkv/AVo+RH81gnO7jbPmEIIkQdNmjS5e1fMEkkyJjSx86Huixyp8qq2qWfmTb0jEgVxbBUkxULkQPOOW6M7dPga/ngKEkx7W18IYXqqtEDLk4J+nyQZE3AzGc7thUrNSS4ZCQH1YMUHekclHld2JiwdqhXXO7maf/ygttD9Z5jVG46sMP/4QgijcHNz4/Lly5KQ5UJVVS5fvoybm9tjn0MK+AXEL4ZKTcG5kPZxm/HwXZT2RFrFenp7idt2/ADFAqFKK/1iqNAEnpkJM5+Ftp9BSJfcHiGEsDD+/v4kJiZy6ZLtbV2Tnp5eoOTpfm5ubvj7+z/24yUZE9oUZZ1e/3zs5gmdv9V2WX91MxQpoV9sIn9uXISNX8CLK/Pff9LYAiKg11z4vTtkpP77/5gQwuI5OztTvnx5vcMwiXXr1lG7dm29w7hLpintXdoVSNwJlVr8+/PlG0H1brBosLaDu7AOq0dpSY93Jb0j0ZSqAX0WwfrxsO07vaMRQgiLJMmYvTu8FMo3fnB/waYfQvJR2P+X+eMS+Ze4C46vgcbv6B3Jv3lXhheWwI4fYf2nktwLIcR9JBmzd7HzIfghTU+d3aDrj9oWCSlnzBuXyB+DAZa8A81HahuwWhqvsvDCMjg0F1Z+KAmZEELcQ5Ixe5Z+DU5teXShd+lQiOwP817TnvCFZdr7Bzg4QY2n9I7k4Tx8oc9iSNisTX8bcvSOSAghLIIkY/bs8DIIjAK3oo8+ruFgyMmE7VLzY5FupcCaj6Dtp1q/SEtWuDg8vwCSj8GcfpCTpXdEQgihOwv/yy1MKnY+BHfK/TgHR+jyPWz8HJLiTB+XyJ/146FKa/CznJVBj+TqAc/Nhowb8FcvyErXOyIhhNCVJGP2KuMGJGyEqq3zdnzxCtBsuHY3IzvTtLGJvEuKh/2ztJ+NNXEuBE//rtUl/vmktvWFEELYKUnG7NXRFdpO+4WK5f0xdZ7X+hyuH2e6uETeqSosfReeeBeKeOsdTf45uUC3n8GrHEzvDLeu6h2REELoQpIxe5XXKcp7KQp0nAR7psPp7aaJS+Rd/CJITYLwF/WO5PE5OGr/p/zrwrT22vUIIYSdkWTMHmXehONrIahd/h/r7gPtv9CaicvUkn6ybsHy97TWVY5W3khDUaDVJxDUHqa2kW1UhBB2R5Ixe3RsFZQJ01a2PY5qHaBcA1jxvnHjEnm3eaJWsF/hCb0jMQ5FgehhEPYCTG0Ll4/rHZEQQpiNJGP26HGmKO/Xepy22/uR5caJSeRdymnY/j20/FjvSIyvwUBo/DZMawcXD+kdjRBCmIUkY/Ym6xYcXaVNCRWEW1Ho/B0sfANuXjZObCJvVnwI9V7VdrW3RWF9tETzt86QuFvvaIQQwuTylIwpitJaUZTDiqIcUxRl6AO+Xk5RlNWKouxXFGWdoij+tz8frSjK3nve0hVF6Xz7a4qiKGMURTmiKEqcoiiDjHtp4oGOr9F21XcvWfBzBUZBje6w6A1pb2MuJ9bDuT3Q0MZ/XWp01wr7/3wKTm7UOxohhDCpXJMxRVEcgclAGyAYeEZRlOD7DpsA/KaqaigwGhgLoKrqWlVVa6mqWgtoCqQBK24/pg8QAASpqloNmFnwyxG5MsYU5b2iP9Dqe/bJj8/kcrJh6RBoOUbbp8vWVW0NT06F/z0v0+GmYsjBMTtN7yiEsHt5uTMWARxTVfWEqqqZaEnT/c/mwcCa2++vfcDXAboDS1VVvfOb/xowWlVVA4CqqrKm3dSyM+DIMq0A31juNBNf8YGsgjO1XT9r/R2N+fOzdOUbw7OzYP4AOPi33tHYBlWFMztgybvweRDhu96ULghC6CwvyVgZ4N5n2cTbn7vXPqDr7fe7AB6KopS475gewIx7Pq4IPK0oyi5FUZYqilI572GLx3JiHfiEgEcp4563VA2IHCDNxE3pZrLW9qj1eG3loT3xD4de82DZe7DnN72jsV4XD8GqkfB1qJbcFi4BLyzlZpFysPUbvaMTwq4pai61PoqidAdaq6r60u2PewH1VFUdeM8xfsA3QHlgA9ANqK6qasrtr5cG9gN+qqpm3f5cKjBCVdXPFUXpCrypqmqjB4zfD+gH4OvrGzZzpmmnw1JTU3F3dzfpGHqpGv81qe4VOOv/8Dsrj339ag61Y97nUslIEgOMOA1qRpb8s69yeDI5jq4cr/SSSc5vydd+R6G0s9TcN4JE/44kBnQ06rmt4fofh9utC/gkbcD34kYcc9JI8mlMkk8jUt3L303qDZdP0ChuOLvCvyLDzQo7ORSQrf7s80Ku3fTXHh0dvVtV1fBcD1RV9ZFvQCSw/J6PhwHDHnG8O5B43+feAH6873PxQPnb7yvAtdxiCQsLU01t7dq1Jh9DF1kZqjqunKqmJD7ysAJd/+UTqjq+vKpejH38c+jIYn/2Z/eo6meVVfVWismGsNhrv9/V06r6dW1VXTtOVQ0Go53Waq4/L66fV9Utk1X1x2hVHV9BVRe9paoJW1Q1J+eBh69du1ZVV41S1dkvmjdOC2FTP/t8kms3PWCXmktuo6pqnqYpdwKVFUUpryiKC9p044J7D1AUxVtRlDvnGgb8ct85nuHfU5QA84Do2+8/ARzJQyzicSVsgBKVwfP+GWYjKl4emo2AOS9LM3FjUVWttqfph+DmqXc0+vMKgL7LtIUoKz6QVbx33LoKu3+FXzvA5Ai4cACi34O3D0O7z6FcJDg84s991FuQsBlObzNfzEKIu3JNxlRVzQYGAsuBOGCWqqqHFEUZrSjKnbmCJsBhRVGOAL7AmDuPVxQlEG3V5Pr7Tj0O6KYoygG01ZemmX8RGmOvonyYOr2hqD+sG2v6sezB/r/AkAW1euodieVw94E+i7TEYeEgMOToHZE+Mm/CgdnwZw/4KlTrrFH3ZXj7CHT5Dio1z3urLFd3aDFKazxvr99PIXSUp99UVVWXAEvu+9zwe96fDcx+yGMT+G/BP6pWT/YYzRFFvuVkQ/xi6PeO6cdSFOg4Eb6PgiqtoWw9049pqzJuaAXXT//+6Lsa9qhwceg9D2Y8A3+/pK3odXTWOyrTy87Ukq6Ds7XNmwPqQvXu2vW7FS3YuWs8CTunQMzvEPa8ceIVQuSJ/IW3B6c2gVc58+3Y7u4D7aSZeIFt+AwqNtVWE4r/cvWAnrMhKw3+ek7rLmGLDDnaZr8LXofPq8CWiVpv2EF74Lm/odYzBU/EQHsh1WY8rPkYbqUU/HxCiDyTZMwexM6HYOOuPstVtfZQriEsf8+849qK5GPaHYpmI/SOxLI5u2l3Dl2KwB9PancTbYGqQuIuWDoUvgjW6uNKVIJXNmo1c3VfgiImWPnoV1vbbHf9eOOfWwjxUJKM2TpDDsQthGpmTsYAWo+FE2vh8DLzj23NVBWWDYWoN7VNXsWjOTpD15+0BSS/dYa0K3pH9PiS4mD1RzCxlnZn2c1Tq497dSM0fENbwGBqTYdrtYqXDpt+LCEEIMmY7Tu9VdvktURF84/tVhQ6f3+7mXiy+ce3VkeWw9UEiHhF70ish4MjdJgIZevDtPZw46LeEeXd1QTY+Dl82wCmd4XsdHjyVxi4C6KHgbeZ98N2LwmN3tZeEMhqVSHMQpIxW2euVZQPE9gQQp/SEjL5w5677AztSbDNeHBy0Tsa66Io0PJj7f/71DaW3Z4rNQm2/wBTmsNPTeFaIrT9DN48BK3GgF8tfTstRPTTYjq8VL8YhLAjeVz3LKySwQCxC7RpDj01/QB+jIZ9M6DWs/rGYum2TgafYKjUTO9IrJOiQJMhWnH/1DZaGyXvSnpHpbmVopUMHJwN52KgSht4YghUaGJ5K0EdnbUyg8X/py0icXbTOyIhbJokY7YscYe2BYC5pznu5+QKXX+A3zppRf3Fyukbj6W6fg62TIKX1+gdifWL7K/tnTWtnbbisFR1feLITIMjS+HA35CwUWt8HtYHnpkJzoX0iSmvKjUHn2qwbbI2bSmEMBlJxmxZ7AJ9pyjvVaoGNBgE8/rD8wtl36wHWTkcwvtqheii4Or01lZZTu+sJT/m2iIkJwuOr9E2ZD2yHPzDtL3AunxnfV0UWo3RplFrPgNF/fSORgibJc+I90i6ns7B5Byycwx6h1Jwqqp/vdj9GrwOqkF7pS3+7dRW7a3RW3pHYluqd4NOk+HPp+HkBtONYzDAyY1abeSEKlpBfkAEvL4bes2F2j2tLxEDKF5Bu5O3aqTekQhh0yQZu8f5a+n8fTST+mNXM3z+QXYmXMFgsNKi87N7wKUwlAzSO5J/ODhqdwc2fQkXY/WOxnIYcmDpO9BytHYnRxhXlVbw5DT43wvGLUhXVe33bPn78GUILBsGxQLhlfXw4gqIeFlbmWjtGr2tJbJndugdiRA2S6Yp71EzwIsRkYUoX6Mui/af58N5B7l2K4v2oaXpUNOPGmU8UfRc4ZQfsfO0u2KWFm+xQGg+Cub0g5dXa/Vk9m73NHD1hJCuekdiu8o3gmdnwYweWmF6je6Pf65Lh7UpyIO3O8BV7661ZipZ1TixWhpXD2g+Uutb+dIaKTEQwgQkGXuAciWKMCC6EgOiK3Hk4g0W7TvHoBkxqECHUD861PSjaikPvcN8uDtTlD3+0DuSB6v9HBxeojUTbz5S72j0lXZF+z70mmd5ibOt8Q/Tkqbfu0Fmqjb9Bhy/lEpGdi53wFNOw8G/tUL8tGQtce42Bfzq2MfPrcZTsPNn2PsH1OmldzRC2BxJxnJRxdeDt1pW5c0WVTh49joL95/jhak7cHdzupuYBXpb2NTS+X3alKCvTivIcqMo2gad3zeEyq2gXKTeEeln7ScQ3Fm/1X72xjcE+izWdurPSGWmU0eGzz9EVBkHWjW/79jUS9od5gOzIfmI1lKs9VitL6SDoy7h68bBQdv7bkYP7ftgjfVvQlgwScbySFEUavh7UsPfk6Gtg9hz+ioL952j+/dbKe3pRseafrQLLY2flwUsV79TuG/Jr9jdS0L7L2Heq/DqJm0qxN5cOKA92Q+QWhyzKlGRzN6LufZjWzLUA8x4eSwv/LKV2HPXCS6uQtwibQoycbdWb9boLagQLZvwlqkDlVvA+k+1VZZCCKORZOwxODgohAcWJzywOB+2D2b7ySss3HeOthM3UtnHnQ41/WhTvTQlPXSoh1JV7Qm++y/mHzu/gtpp05XL34OOk/SOxrxUFZYOgSbDtL3ghNkk3Uin/6xEyvp+wWfpo3CM/4z3ShXixm+TUdUDKIGNtKn0p//QFsGIfzQbAZPrQZ3noWQVvaMRwmZIMlZATo4ONKzkTcNK3ozuVJ2NRy+xcN85Plt+mJr+XnSoWZrWIaXxLGymHbYvHgJDNpSuZZ7xCqrVWPg+SlvlVrWN3tGYz6E5kHH9bt2SMI+Y01fp/8cenq4bwKCmkThk1IXZfWmZeZlfHZ7gatMvaB1uQSuQLY27j3ancPkw6Dnbsu++C2FFJBkzIhcnB5pV86VZNV9uZeaw9nASC/ed4+NFcUSUL06Hmn40D/bF3dWE33ZrmKK8l1tR6PK9tu2Af10o4q13RKaXeRNWDNcKwO2t9khHs3aeYdyyeMZ1rUHLkFLaJwsVg15z2b9uHQ3LhTJ4ZgyNQytR2EX+ND5UxCuw+1dtQ9uqrfWORgibIGuUTaSQiyNta5Tmu+fC2DKsKe1rlmbBvnNEfrKa/n/sZtnB86Rn5Rh/4Nj5WkG4NSnXAGo+bT/NxDd+oS1asOeFC2aUmW3gw3kH+X79cWa9Uv+fROw+EeWLExZYnO/XHTdzhFbGyQVaj9Ma2mdn6B2NEDZBkjEz8HBzpkttf37pU5cN70bTuHJJpm87RcSYVbz1117WxieRmW2EXf+T4rW7LmXCCn4uc4t+H64mwN4/9Y7EtK6cgF2/QIvRekdiFy7dyKDnlG2cS7nFvIENqeTz6IUiw9oEMX3bKc5cSTNThFaqcnNtX7Vt3+odiRA2QZIxMytWxIUeEWX546X6rHr7CUL9Pflm7THqfbKKYXP2s+VYMjmPu+t/7Hxt2bm1TFHey8kVuvwAKz+Eq6f0jsZ0ln+gtYWSPn8mt/dMCp2+2URkhRL81Ducom651236eRWib8PyjFkcZ4YIrVyrT2DzRLhxQe9IhLB6kozpyMfDjT4Ny/P3aw1Y+HoUgSWK8MnSOOqPXc3IBYfYfSqf7ZgsrRdlfpWqDg3fgHmvaS2CbM2xVZAUC5ED9I7E5s3adYa+03YyvEMIb7WsioND3l+gvNy4AofOX2PT0WQTRmgDSlTUNoCVvpVCFJgkYxbCv1hhXnmiIoteb8Rf/epTvIgLQ/4+QKNP1zJ2aRwHz15DfVQ9VfJRSLsM/hHmC9oUIgdqdWNbbayZeHYmLB2q1dpICyiTycoxMGL+Qb5bd5y/+tWndfUH14c9ipuzIx+0C2bUwkNk5RihfMCWNX4Hjq+FxF16RyKEVZNkzAJVKOnOoGaVWflmY37uE46Tg0L/P/bQ7PP1fLHyCMeSbvz3QXemKK29b9ydZuKbv9K26bAVO36A4uVl9ZkJJadm0HPKdk5fSWPegIZU9n38jYRbBvtSytON37fZ8JS5MdzpW7nkHTBI4irE47LyZ27bpigKQaWK8k6rINa/04Qvnq7FzYxsek7ZTuuvNjB57TFOX75daGztU5T3KhaoFbjP6Wcbq7VuXNRWULYaq3ckNmt/YgodJ20iIrA4U56vi2ehgu3rpygKw9sHM2nNMS6n2sD/QVMKfRoUB9hn44tvhDAhScashKIo1Arw4sP2wWwd2oxRHUM4f+0WXb7dzCsTZ5N25SwXPGvrHabx1OoJXuW03o3WbtVIrbbGu5Lekdikv3cn0mfqToZ3COb/WlXFMR/1YY9S2deDzrXKMGHFYaOcz2Y5OECbT2H1R5B+Xe9ohLBKkoxZIQcHhXoVSvBx5xpsf68ZQ8oeZl+RhrSauJmnftjK79tOWf+reUWBDl/Dvhlwaqve0Ty+MzvhxFqttkYYVVaOgZELDjFxzVFmvFyf1tVLG32MN5pXZmVsEgfPXjP6uW2KfxhUagYbPtU7EiGskiRjVs7J0YEKSauIbN+XHe834+VGFdhx8gpNJqyj9y87+N+uM1y7laV3mI/HvSS0/wrmvgIZD6iTs3QGAyx9B5qPss9G6CZ0OTWD56Zs52TyTRYMiKJqKdN8fz0LOfN/LaswYsGhRy+gEVrfypg/IPmY3pEIYXUkGbN2Kae1zVIDo3B1cqRFsC8Tn6nN9vea8WSYPytjLxI1bg0v/7aLBfvOkZaZrXfE+RPUFso3hmXD9I4k//b+AQ7OEPqU3pHYlINnr9Hxm82ElSvGL33qmrzv65PhAWRmG5i/95xJx7F6Hr4Q9abWt1IIkS+SjFm72AUQ1A4c//2EVNjFiQ41/fixdzibhzWlVUgp/t6dSL0xqxn45x6WH7pgmnZMptB6LJzcAPFL9I4k726lwJqPoO2n1rkJr4WaG5NI71928H67arzbOsho9WGP4uigMLJjMOOWxnMzw8pezJhbvVe1LhNHlusdiRBWRZIxa5eHXpRF3ZzpHubPr30jWP9uNJEVSzB180nqfbKat2ftY/2RS5a9n5Krh7Y7/6LBkHpJ72jyZv14qNIa/GxoUYWOsnMMjF4Yy1ertPqwtjWMXx/2KGHlihNZsQST18oU3CM5uWirhpcN0/bWE0LkiSRj1uz6Obh8VJvGy6PiRVzoWa8cM/tFsuLNxoT4FeWrVUeo/8lqPph3gBuZFloXUy4Saj5jHc3Ek+Jh/yxoNlzvSGzClZuZ9P5lB0eTbjB/QEOT1YflZmibIGbsOE1C8k1dxrcaVVpqu/Nv/07vSISwGpKMWbO4hVCljfZq9DH4FnWjb1R55vZvyLwBDXFycGDU1lvEnrPQ5enR70HKKa0Wy1KpKix9F554F4p46x2N1dPqwzYR6u/FtBdCU0KsAAAgAElEQVQi8Cr8eP/XjcG3qBv9GlfkY+lbmbtWY2HTV9oee0KIXEkyZs2MuNFrQPHCjOwYQvcqLjz383YW7rPAYmUnV+j6I6wcri1asERxCyE1CcJf1DsSqzd/71l6/7KDoW2CGNrGPPVhuekbFcixpBusO5ykdyiWzbsS1H4OVo/SOxIhrIIkY9bqxkW4eBAqRhv1tPVLOzH9xQjGL4tn7NI4cvLTqNwcfEOg4WCYa4HNxLNuwfL3taJ9Rye9o7Fa2TkGxiyOZcKKw/zxUj3ah/rpHdJdrk6OfNg+mNGLYsnMtuA6S0vQ+B04tlr6VgqRB5KMWav4hVC5lUmaTof4ebJgYBQHEq/RZ+oOUtIsrBA3coC2QnHrN3pH8m+bJ0KZOvmq4RP/dvVmJs9P3UH8hRssGBBFtdJF9Q7pP5oG+VC2eGF+3ZKgdyiWza2oVje59F3pWylELiQZs1Ym7kVZvIgLv/WNoIqvB50mbyb+ggXVkTk4QufvYPPXcOGg3tFoUk7D9u+h5Ud6R2K1Ys9dp+PkTVT382Rqn7oUK6JffdijKIrCh+2D+XbdMZJupOsdjmWr+Yz27/6Z+sYhhIWTZMwa3UyGc/u09iMm5OTowIftgxncvDLP/rSdJQfOm3S8fClWDlp8ZDnNxFd8oO2x5FVW70is0oJ953ju5+280yqIYW2r4eRo2X+aKpZ058nwAD5bJn0rH+lO38pVo6yzi4YQZmLZf/HEg8Uv0hIx50JmGa5LbX9+6xvBmMVxfLY83nLqyGo9C8XLw9ox+sZxYj2ci4GGg/SNwwrlGFTGLonj02XxTH8xgo41Lac+LDevN63E+iOX2HsmRe9QLJt/uFbbuuEzvSMRwmJJMmaNTDxF+SDVy3gyf2BDdiVc5cVfd1pGv8u7zcT/goTN+sSQkw1Lh0CrT8yWHNuKlLRM+kzdwcFz11g4MIoQP0+9Q8oXDzdn3mlVlZELDmGwlBcolqr5SNgzHS4f1zsSISySJGPWJu2KtjqpcguzD+3t7srvL9UjsEQROk/ezNGLFjDtUMRbS8jmvQrpOtS17Zyi9eQLam/+sa1Y3PnrdPxmM0GlPPj1hQiLrQ/LTbc6/qjAnJizeodi2TxKQcM3rLPHrBBmIMmYtTm8BCo0AZciugzv7OjAyI4h9G9Skad/3MbyQxd0ieNfqrbWvifmblB8Mxk2fAqtx0v/yXxYtP8cPads5+2WVXi/XbDF14c9ioODwqiOIXy6LJ4b6RZwt9iS1X9N6xhydKXekQhhcaz3r6C90mGK8kGeDA9gap+6jFpwiC9WHtF/mqbVJ5CwCeIXm2/M1aMhtAf4BJlvTCuWY1AZtzSesUvi+a1vBJ1qldE7JKOoFeBF4yol+WaN9K18JCfX230rh0rfSiHuI8mYNbmVAqe3QZVWekcCQM0AL+YPjGLr8WT6Td/FdT3vDNxtJv6meZqJn4uBI8ugyRDTj2UDUtIyeWHaTvadSWHh61FUL2Nd9WG5ebd1VWbtOsPxS6l6h2LZqrSCYoGw4we9IxHCokgyZk2OLIPARlriYSFKerjyx0v1Ke1ZiM6TN3MsSccno7L1tRWWCweZtpm4wQBL3oWmH4KbbSUVphB/4TqdJm+mso8701+MoLiV1oc9io+HG/2bVOKjRbF6h2LZFAVaj4ONX0jfSiHuIcmYNbGQKcr7uTg58FHn6vRrVIGnftjKqlgd/8g2eQ9SzkDMdNONcWAWGLKhVk/TjWEjlhw4z7M/bWdw88p82N6668Ny83yDQE5fSWNNvCQZj+RdWXvRtHq03pEIYTFs9y+jrUm/rtVEVW2tdyQP1SOiLFOeD+eDeQeZuPqoPnVkTi5aM/FVI+HKSeOfP+OGdu62n2kbWooHyjGofLosnjGL4/itbwRdavvrHZLJuTg5MLx9MKMXxpKRbWF9Uy3NE+/CsZVwdrfekQhhEeTZxFocXQFlIy1+WqxO2WIsGNiQdYeTePX33aRmZJs/CN9giHoT5pmgmfj6T6FiU20jS/FA19KyePHXnew5fZUFAxvaXH3YozSp6kMlH3d+2ZSgdyiWzc1Tm+ZfOkT6VgqBJGPWI3aeRU5RPohPUTdm9KtPCXdXukzezMnkm+YPov4AUBxhy0TjnTP5KMT8Ds1GGO+cNubIxRt0mryJ8t5FmP5iPUq4G7+RvaX7oF0wP244zsXr0rfykWr11Kb7D8zSOxIhdCfJmDXISNVa7lRto3ckeebq5MjYrjXo0zCQ7t9tYW18knkDcHCALt/Blklw4UDBz6eq2pL8Rm9pm7yK/1h28Dw9ftzG600rM6JDCM42XB/2KIHeRegRUZbxS+P1DsWy3e1bOVL6Vgq7Z59/La3NsZXatFjh4npHkm8965Xjh15hDJ2zn8lrj6GacpXj/bzKQsuPYc4rBW8mfmQ5pJyGiFeME5sNMRhUJiw/zEeL4pj2Ql26hdl+fVhuBkZXYsvxy+w+dUXvUCxbQASUfwI2fq53JELoSpIxa2ChqyjzKjywOPMHRLEi9iID/tzDTXPWkdV8Rmsmvubjxz9HVrp2V6z1OG2BgLjr2i2tPmxHwhXmD2xIqL+X3iFZhCKuTgxtE8TIBbH6b4hs6ZqPhN2/St9KYdckGbN0Wbfg2Gqr731YytONv/rVx93Via7fbuHUZTPVkd1pJr5/lrYa9XFsmww+wVCpmXFjs3JHL96g8+TNlC1emD9eqoe3HdaHPUqnWn64ODnwv91n9A7FshUtDQ1eh+Xv6x2JELqRZMzSHVsNfrW0hthWzs3ZkfHdQulZvyzdvtvC+iNm2CkftO9dx4na6sr8NhO/dha2fAOtxpgmNiu1/NAFnv5xG/2bVGRUp+p2Wx/2KIqiMLJDCJ8tP8K1W9K38pEiB8CleDi2Su9IhNCF/AW1dFY+RXk/RVHoHRnI5Gfr8H//28cP64+bp46sSiuoEA3L8tlMfNUIqPuiNtUpMBhUvlhxmFELDjG1T12eDA/QOySLVsPfkxbBPny96qjeoVg2J1etv+yyYZAjiauwP5KMWbLsDDi6HII66B2J0dWrUIL5AxqyaP95Bs3cS1qmGerIWn0CpzZD3KK8HX9qC5zaqu1ZJriensXLv+1i24krzB8YRc0AqQ/Li/9rWZV5e89y9KKsGHykqm3AMwB2/Kh3JEKYnSRjluz4WvCtbrNbKfh5FeJ/r0bi7KjQ7butnLmSZtoBXd21ZuKL34LUXLbaMORo/SdbjgaXIqaNywocS0ql8+TNlClWiN9fqkdJD6kPy6sS7q4MjK7EqIWx5l1NbG3u9K3cMCH3308hbEyekjFFUVorinJYUZRjiqIMfcDXyymKslpRlP2KoqxTFMX/9uejFUXZe89buqIone977ERFUXTsLm3BbGyK8kHcnB35/MmaPBnmT5dvt7D5WLJpByxbT9tsckEuzcR3T9N2CQ/patp4rMDK2Is8/cNWXm1ckdGdquPiJK/h8qtXZDkuXk9nhZ59W61BySraCmjpWynsTK5/VRVFcQQmA22AYOAZRVGC7ztsAvCbqqqhwGhgLICqqmtVVa2lqmotoCmQBqy459zhQDFjXIjNyc6EI0uhmu1NUd5PURT6RpVn4jO1GPzXXqZsPGHaOwhNhsH1RNjz24O/nnYF1o2FNuO1V+t2ymBQ+XLlEYbPP8iU58N5qq7Uhz0uZ0cHRnQI4ePFsaRnSd/KR3riXW1fv3MxekcihNnk5SVuBHBMVdUTqqpmAjOB+2/XBANrbr+/9gFfB+gOLFVVNQ3uJnmfAe8+TuA27+QG8K4CRf30jsRsGlT0Zm7/BsyNOcubf+013ZOWkwt0/QlWj3pwM/G1YyC4M5SqbprxrcCN9Cz6Td/N5mPJzB/YkNpl5TVTQUVV9ia4dFGmbDyhdyiWrZAXNP1A61sp07rCTii53YFQFKU70FpV1Zduf9wLqKeq6sB7jvkT2K6q6teKonQF/ga8VVW9fM8xa4AvVFVddPvjNwAHVVW/VBQlVVVV94eM3w/oB+Dr6xs2c+bMAlxu7lJTU3F3f2AoZlU1fhI3i5QlMcC805SWcP0ZOSpTD2Zw/qbKoNqulChkmmkx/zPzKXlpKzG1x4DiSGpqKr5coua+EeyImEy2s4dJxrVE9/7cz6camBiTTlBxR3pWc8HJwfbvDprr//2lNAMjt95idINCJvt/nV+W8Dv/H2oOYbvf4UxAR5J8m5hkCIOqsv5MNtWLZlDSy8Ku30ws8mdvJua69ujo6N2qqobneqCqqo98Q7ujNeWej3sB39x3jB8wB4gBvgYSAa97vl4auAQ433P8JsDp9sepucWhqiphYWGqqa1du9bkY+QqO1NVxwWq6tXTZh/aIq5fVVWDwaD+uP64Gv7xSnXLsWTTDJKTo6pT26nqhs9VVVXVtWvWqOovbVR158+mGc+C3fm5r4q9oNYZvUKdsf2UvgGZmTn/309YHq8O/HOP2cbLjaX8zv/HqW2qOiFIVdNvGP3UWdk56pszY9TQkcvV7l8uVQ0Gg9HHsAYW+7M3A3NdO7BLzUN+k5eXZmeBe4tF/G9/7t6E7pyqql1VVa0NvH/7cyn3HPIUMFdV1TsbyNQGKgHHFEVJAAorinIsD7HYh4RN2r5WXvZbo6MoCi83rsCXT9Xi9RkxTNt80vh1ZA4O0Pk72DoZzu/HJ2kjZFyHOs8bdxwrYFBVJq4+yvtzD/LT8+H0iCird0g267UmFdmdcIUdJ6Vv5SOVrQeBUUbvW5mZbeD1GTFcSs1g3f814XyqgZk7pUuC0FdekrGdQGVFUcoriuIC9AAW3HuAoijeiqLcOdcw4Jf7zvEMMOPOB6qqLlZVtZSqqoGqqgYCaaqqVnrci7A5drCKMq+iKmt1ZDN3nuH//rff+HVkXgG3m4n3o8KJadDmM3BwNO4YFizHoLL71BUmxWSw7nASCwY2pI7Uh5lUYRcnhrWtxogFh8iRvpWP1mIU7J4KV4xTZ5eelcMr03eRbVCZ8nw4xYq40L+WG58tP8wR2QdO6CjXZExV1WxgILAciANmqap6SFGU0YqidLx9WBPgsKIoRwBf4G7vGEVRAtHurK03auS2ypAD8YugWsfcj7UTAcULM6d/A9Kzc3j6h62cv3bLuAPU7AElq5LiVQPKRRr33BboenoWi/ef562/9lJ3zCren3uQwKIOzOhXH5+ibnqHZxfah5bGw82JGTtO6x2KZSvqB5EDYfkHBT7VzYxs+k7bibubM9/2rIOrk/aiy8/dgaGtgxj45x5Z6Sp0k6cKUlVVl6iqWkVV1Yqqqo65/bnhqqouuP3+bFVVK98+5iVVVTPueWyCqqplVFU1POL89llB+CCntmh/gKT9zr8UdnHim2dq07p6aTp9s9m4UzyKAt2nEh80yHjntDAnk28yZeMJnv1pGw3GruF/u89Qu6wXC1+PYtngxnSq5HL3yUmY3p2+lV+tOkJKWqbe4Vi2yIGQdAiOr8n92Ie4np5F7192UMarEF89Xes/vVSfDPcnqFRRRi+KLWi0QjwWJ70DEPeRKcqHUhSF15pUJNivKP3/2M0bzavwXL2yKMbYC8zBARTbSUaycgzsSrjKmviLrI5PIjU9m2bVfHihYXkaVipBYRf51ddbsF9RWlcvxZcrjzCqk/1uo5IrZzetldnSofDaZnB0ztfDr97MpPcvO6hT1osRHUJweMDqYEVRGNOlOu0nbWLx/vO0Cy1trOiFyBP5i2xJDAaIWwh9FusdiUV7okpJZr/agH7Td3Ew8RqjO4fIXR20J531Ry6xKu4iG48mU65EYZoG+fD107UJ8Sv6wCchoa+3W1Sl+RfreaZeWYJKFdU7HMtVtS3s+El7i+yf54cl3Uin15QdRAf5MKR11Ue+cPNwc2bSM7V5YepOQv09CShe2BiRC5EnlrHRjdCc2Q5FvMFb1jLkJtC7CHP7N+R6ehY9ftzGxevpeodkdqqqcuTiDb5bd5wnv99C40/XsvjAeRpV9mblm41ZMDCKwc2rUMPfUxIxC1WsiAtvNK/MqAXSt/KR7vSt3DgBbuatZdq5lFs8/cM22oWWzjURuyPU34vXmlTk9RkxZOU8tLJGCKOTZMySyBRlvhRxdeLbnnVoXs2Xjt9sYvcp298qICM7hw1HLjFywSEaf7aWF6bu5Py1WwyIrsTOD5rzU+9wnq5bVgrxrcizEWW5mpbJ0oMX9A7FsvkEQY2n8tS38tTlmzz1w1Z61ivLoGaV81XK0LdheYoVdubzFUcKEq0Q+SLTlJbCYIC4BdBrrt6RWBVFURgQXYlqpT3o99tu3m5ZlWfr2dYeWZduZLD2cBKr4y6y5dhlqpTyoGmQDz/1Dqeqr4dxauaEbpxu9638v//tI7qqD4VcZMr9oZoMhW/qwrm94FfrgYccS0ql18/bGRBdiefql8v3EA4OChOerEm7iZtoULEEjauULGjUQuRKkjFLcXY3uHpAyap6R2KVmgb58r9XI+k3fTcHz11jZIcQXJys88avqqocOnedNfFJrI5P4uSlVBpVKUmrkFJ80qUGJdxd9Q5RGFlkxRLUCvDihw3HGdy8it7hWK5CXtD0fa1vZd9l2vTlPWLPXafP1B0MaR1EtzD/xx6mhLsrXzxdk8Ez97JoUBQ+HnKnWZiWdT5b2aLYeTJFWUAVSrozt38Dkm9k8OxP20i6YT11ZLcyc1gdd5H35h4gcuwaBv65h2u3shjSqiq7P2zB5Gfr0LWOvyRiNmxY2yCmbUkg8Wqa3qFYttq9ICsNDv79r0/HnL5K71+2M6JDSIESsTsaVPSmR90A3vprHwbZnFeYmCRjlkBVIXaBbPRqBB5uznz/XBiNKpek0zebiTl9Ve+QHur8tVv8vu0UfaftpO6YVfy08QTlSxThz5frse6daD5sH0yDSt7/2RNJ2Cb/YoV5oUF5PlkSp3cols3BEdp8CiuHQ+ZNALafuMxLv+5ifLdQo25LMahZZTKyc/h+w3GjnVOIB5FpSktwLkbbO8c3RO9IbIKDg8IbzSsT7FeUl37dxZDWQTxVV/8+nwaDyr7EFG36MS6J89du0aSqD11ql+HLp2vhWSh/+ycJ2/PKExVo9vl6thxPpkFFb73DsVzlIqFsJGz8gg0BrzL4r71MeqY2DSsZ93vm5OjA1z1q0/GbTdQrX4KwctIqTJiGJGOW4M4qSinENqoWwb6U946k32+7OHjuGh+2Dzb7XabUjGw2Hb3E6rgk1h5OongRF5oG+TKqUwi1A7xwkrte4h5uzo580K4aoxbEsnhQlPz/eJQWo8mc3IAJm8vzQ++21A0sbpJh/LwKMaZLDQbNiGHJoEZ4FpYXTcL45Dddb6qqraKUejGTqOTjzryBDTl79RY9p2wnOTUj9wcV0OnLaUzdfJJeP2+n/ier+XPHGaqX8WRu/4asePMJhrYJom5gcXmiFQ/UunopSri78Md26Vv5KAsSFKZkt2F6wAKTJWJ3tAopRfNqPgyds1/2gxMmIc8Gert4UGsOXrqm3pHYrKJuzvzUO5z65YvT6ZvN7E9MMer5s3MM7Dh5hbFL42jxxXq6freFuPPX6VmvHNvea8ZvfSN4vkGg7Ogt8kRRFEZ0COHr1Ue5clP6Vj7IrF1n+HhRLM36jsbzWjwcX2vyMYe1rUbC5TT+lObuwgRkmlJvMkVpFg4OCm+1rEqwnyd9pu7k/bbVCrTi6lpaFuuPXmJN3EXWH7mEn1chmgX5MOHJmtQoIzvei4KpWsqDjjX9+HzFYcZ0qaF3OBblt60JfL/uODP61adiSXdoNQaWDYVXN+W7b2V+uDk78s2ztXny+62ElSsm7auEUUkypidVhUPzoMsPekdiN1pXL0WFkkXu1pG917ZanurIVFXl+KWbWuPtuCQOnbtOvfLFaVbNlyFtgijtWcgM0Qt78mbzKjT7Yh3PRJSlehlPvcOxCN+vP86f20/z1yuR/9xpDmqv9azc+TPUf9Wk41cs6c57basx8M8YFgxsSGEXeQoVxiHTlHq6FA9Zt6BMHb0jsStVfD2YPyCKk8k36f3zDi4/pI4sM9vA5mPJjF4YS/SEdfT6eTunLqfxyhMV2Pl+c37uU5dn65WVREyYhGdhZ95sUYVRCw/ZfZ2Sqqp8sfIIs3adYda9iRhoswptxsOGT/Pct7IgutUpQ40ynoxeGGvysYT9kGRMTzJFqRvPws78/Hxdapf1ouM3mzl49hoAl1Mz+Ht3Iv3/2E3Yxyv5bPlhihdx5tueYWwZ2pQxXWrQNMhXWtYIs+hRtyw3M3JYuP+83qHoRlVVPlkSx4pDF/irXySlPB+wG75PNajxJKz52OTxKIrCR52rs/3kFRbsO2fy8YR9kHuseoqdD+2/0jsKu+XooPBu6yBC/Dzp/csOvJyyubRuHVGVvGka5MOojtUp6SE73gv9ODoojOoUwqAZMTSv5mN302IGg8rwBQc5kHiNmf3q41XY5eEH3+lbGd4XSoeaNC53VycmPVOb3r/soJa/F2VLyOIcUTByZ0wvl47AravgX1fvSOxeu9DSzH41km6VXdj1QXO+ey6MJ8MDJBETFqFuYHEiyhfn27X2tQt8do6Bd2bv58iFVH5/qd6jEzGAQsUg+j2tb6UZpnWrl/FkYHQlXp+xh8xsg8nHE7ZNkjG9xM3X2h85yI/AElQo6U6ItyOuTjL9KCzP0DZB/LH9FKcv20ffysxsA2/M3EvSjXSm9a2Lh1seV0nWeR4yb/ynb6WpvNAwEG93VyasOGyW8YTtkkxAL3fqxYQQIhelPQvxUqMKfLzY9ovG07NyeO333WRk5/BT7/D8Tc3e7Vs54m7fSlNSFIXPnqzJwn3nWHs4yeTjCdslyZgeLh+HGxehbH29IxFCWIkXo8oTf+EGG45c0jsUk0nLzOalX3dRyMWR754Lw835Me5Ul2sAZevBJvPU4xYv4sKXT9fi3dn7uXg93SxjCtsjyZge4hZAtQ7aqzghhMiDO30rRy+KJSvH9mqUrqdn0fvnHZTydOPrHrUL1ke2xWjY+RNcPWW8AB+hfoUS9KxXljf/2kuOwb63IRGPR5IxPcgUpRDiMbQI9qW0pxu/bTVPkmEuKWmZPDdlO9VKF+XTbqE4FrSDhac/1O8PKz4wToB58HrTyuQYVL5bd8xsYwrbIcmYuV09BSlnoFxDvSMRQlgZrW9lMJPXHjNL03tzuHQjgx4/biOyQglGdwoxXiuxBq/D+b1wYr1xzpcLRweFr3rUYtqWBHYmXDHLmMJ2SDJmbnELIKgdONrXfkFCCOOo5ONBl9pl+GyZ9a/gO3/tFk//sJU21UsztE0QijE3wHYuBC0/1vpW5mQb77yPUNqzEOO6hjJ45l5S0qTJu8g7ScbMTaYohRAF9Ebzyqw5nMT+xBS9Q3lspy+n8dQPW+kREcAbzSsbNxG7o1pHKFwCdv1i/HM/RPNgX1qG+DLk7/1238ZK5J0kY+Z0LVFbSVm+sd6RCCGsWFE3Z95pWZWRCw5hsMKC8WNJqTz941b6NapAv8YVTTfQnb6V68dDmvmmDoe2CSLx6i1+32ZbtX3CdCQZM6e4hVC1LTjmcQNDIYR4iO5h/mQbVObtPat3KPkSd/46z/60jbdbVqVXZKDpB/QNgepdzdK38g5XJ0e+ebYOX646Suy562YbV1gvScbMSaYohRBG4uCgMKJDCOOXxZOaYZ6aqILadyaFXj9vZ3iHYLqH+Ztv4CbDtHrdCwfMNmR57yJ82L4aA2fsIS3TOn4+Qj+SjJnL9fOQFAcVntA7EiGEjQgrV4yGlbz5Zo3lb6ewM+EKfaftZFzXUNqH+pl38MLFtUbiZupbeUeX2v7UDijGiPmHzDamsE6SjJlL/CKo0hqcpPm0EMJ4hrYO4q+dpzmZbPr2P49r09FkXpm+m6961KJ5sK8+QYS9AOnX4NBcsw47ulMIu09dZV6MdU0nC/OSZMxcYudDcEe9oxBC2Bifom688kRFPl5kmX0rV8Ve5I2ZMXz/XBiNKpfULxAHR62Yf+VwyDRfw/Uirk5MerY2oxfFkmDBCbPQlyRj5pB6Cc7vh4pN9Y5ECGGDXmgYyInkm6yNt6xm1Yv2n2PonAP80qcuEeWL6x0OBEaBfzhs/tqsw4b4efJGs8oMnLGHjOwcs44trIMkY+YQvwgqN9c2IRRCCCNzdXLkw/Za38rMbMvoWzl7dyKjF8Yy/cUIagZ46R3OP1p8BDt+gJTTZh22d2Q5SnsW4lMb2KxXGJ8kY+YgqyiFECbWNMiXwBKFmbr5pN6hMH1rAl+sOMyfL9enWumieofzb14BUO9Vs/atBK2V1WfdQ1l28AKr4y6adWxh+SQZM7W0K3B2N1RqoXckQggb92H7YL5ff5yk6+m6xfDjhuP8uPEEf70SSSUfd93ieKQGg+BsDJzcYNZhvQq78FWPWgz5+wAXrun3MxKWR5IxU4tfDBWjwaWw3pEIIWxchZLuPBUewHgdpsJUVeWrVUeYufMMs16JJKC4Bf/NcykMLT+CpUMplHberNtd1A0szvOR5XhjZgw5Vtg9QZiGJGOmJlOUQggzGti0EhuPXiLm9FWzjamqKuOWxrPs4AX+6hdJaU8rqI8N7gTlG1Nr73vwRTDMflHrYXnpsMmTs/7RlVAUrGJ/OGEekoyZ0q2rcGY7VG6pdyRCCDvh4ebMkNZBZutbaTCojFhwiK0nLjPj5fqU9LCSvRQVBdqMY2vkL9BnEVRoAmd2wO/dYUJlmNUbtv8AFw6CwbiLIhwdFL7uUZvp206x/cRlo55bWCcnvQOwaYeXaU3BXT30jkQIYUe61C7D79tPMXtPIk+FB5hsnByDypC/93Pq8k1+f6keRd2ssO+uokCJitpbnV7a51JOw6ktkLBJS8jSLkO5BlCuIQQ2BN8a4Fiwp0/fom582r0Gb/61l8WDGlGsiIsRLkZYK0nGTCl2vrfwoYEAACAASURBVNagVgghzMjBQWFkhxBe+m0XrauXMkmSlJVj4M2/9pKSlsWvfSMo7GJDTydeZbW3mj20j6+fh1ObtbeY6XD9HATU0xK0wCjwqw2O+f8eNw3ypW2Ny7wzez8/9Q5DURQjX4iwFjJNaSrp17VXVVVa6R2JEMIO1QzwIrpqSSatPmr0c6dn5fDa73u4lZnDlOfDbSsRe5CipaFGd2j/JQzYDoNitLtoqRdh0VswPhB+7QjrP4WEzZCV95WS77YO4uL1dH7dkmCy8IXls/HfIB0dWa7dznbz1DsSIYSdeqdVEK2+2sDTdcsabZuJW5k59Ju+i6JuznzVoxbOjnb4mr6It7YA4M7irFtX4fQ27QX4ig+0RQB+tbRpzXINICACXIo88FQuTg5MeqY2Xb/bQnhgcaqXkecMeyTJmKnEzpNVlEIIXZX0cKV/k4qMXhTLry/ULfA02I30LF6ctouA4oUZ360GTvaYiD1IoWJQtY32BpBxA05v16Y1142FCwfAt/o/05oB9cDtn81wA72LMKJDMK/PiGHh61G4u8pTs72Rn7gpZKRqmwl2+kbvSIQQdq53ZCAzdpxmdVwSzYN9H/s8KWmZPD91JzXKFGV0x+o4OEh900O5emgt8Co31z7OTIPEnVpytukrOBcD3pW1xKxcQyhbn061yrD5WDLD5x/ki6dq6Ru/MDtJxkzh6ArttnShYnpHIoSwcy5ODozoEMKH8w8SVdkbN2fHfJ8jOTWD56Zsp1Flb95rW00KzfPLpTBUeEJ7A8jO0DqzJGzW+mTOeRmKBTImIJJPDhZj0RaF9g1q6huzMCtJxkxBNnoVQliQxlVKUtnHg583nWRAdKV8PfbCtXSenbKNDqF+DG5eWRIxY3Byvb1VRgPgHcjJgnN7cT61ibd9NqCu+IbMnWVwqRB1++5ZAyjqp3fUwoRkwt/YMtPg+Bqo2k7vSIQQ4q4P21fjp40n8tUT8cyVNJ76YStPhQfwZosqkoiZiqMzBNSFqDdx7zuX+a0283b2ALKLV4SDc+C7BvB1LZg/APb+CVdP6R2xMDK5M2Zsx1ZBmTpQpITekQghxF3lShShZ72yjFsax1c9aud6/IlLqTw3ZTuvNqlI78hA0wco7upZvzybjl3l48tujHzmda0DwKU4bVrzyHJYORyc3O7ZiDYKilfQNrAVVkmSMWOTKUohhIXq36QSzT5fz66EK4QHFn/ocfEXrvP8Lzt4u2VVk+7gLx5MURTGdwul7cSNNKzkTYtgX/AN0d7q9dN6ZyYf1RYEJGyEdeNANdxerdlQS9BKBklyZkUkGTOmrHQ4uhJaj9U7EiGE+I8irk4MaxvEiAWHWDAwCscHrIjcn5hC32m7GNEhmA41pU7p/9u78yiryivv499dA2MxiMzzIFNRICjBxCGCiQaHIFMMmPbt2G00vaImDklr0q/dTbcx6cSYqEnbdrQ75o0gQUA0aDQCGidU5qGYRRnUAmSwRKCo2u8f94BlWVC3qu69zx1+n7VqrVvnPOfcvcMK/jjPOc8JpU2LQu6dOpzrfr+EIV3PpWvbai9fN4MOA2I/I6+OhbO9W6Nw9jK8/Cs48tEnV856nRMLcnn1f3hDUkNhLJE2L4Auw6CoY+hKRERqNe70rvz+1beZ+eY2po7q+al9b279gOt+v4SfTBoWuxojQZ3Zqx1Xn9OH781YzqPfOuvE67qZQbs+sZ8RfxPbtm9b7P2ab78Eb/wWPtoFPb/wyfs1O+tpzXSiG/gTSVOUIpLmzIx/GTeEu59dz/6DFce3v7xpN9f9fgn3fH24glga+Yfz+1FYYNy7YFP9DmzbA07/Ooy7D25YAt95HYZ9Hfa9DXO/Az/tTZedzySnaKk3hbFEOXoYNjwDgy4LXYmIyEmVdGvDhcWduecvGwBYsO59bpy+jN984wy+OKBD4Oqkurw8454rhjP99Xd4dfOehp+oVWcomQiX3g3feQ3+5nF6vjMnNsUpwSmMJcqWF2I3TLbuEroSEZE63XrRAOat2MlTm4/wg1kreeibn+OsvnoKPB11bN2Mn00exs0zl/PBR0cSc9Ieo3Cz2NsAJLi4wpiZjTWz9Wa2ycxuq2V/LzN73sxWmtkiM+sebR9jZsur/Rwys/HRvj9E51xtZg+bWWFiW0uxUk1RikjmOLWoKd/9Un/+/HYFj/zdWQzv0TZ0SXISowd2ZNzpXbn1jyvwRFzNMqOs43mw+vHGn0sarc4wZmb5wK+Bi4FiYKqZFdcY9nPgEXcfBkwD7gJw94XuPtzdhwMXAAeBZ6Nj/gAMAoYCzYFrGt9OIJUVsG4+DP5q6EpEROL2f77Qi5+f34Lirq3rHizB3XLRQPZ8dISHX96akPOVdTwP1syJrWMmQcVzZWwUsMndt7j7EWAGUPMSUDGwIPq8sJb9AJOBp939IIC7z/cI8DrQvSENpIWtf40tuNdW6/GISOYwM5rmay2qTNGkII/7pozgNws3sWr7/kaf72DLntCsLWx7LQHVSWNYXZc7zWwyMNbdr4l+vwo4y92vrzbmUWCxu//KzCYCjwPt3X1PtTELgF+4+1M1zl8ILAa+6+5/reX7rwWuBejUqdOZM2bMaFincSovL6eoqKhexwxY/xs+bt6FbT0nJKmq1GlI/9lCvedm75Db/edy75CZ/S9+9yizNx7hX85uTvOChofp8vJyivc8TdPDe9g44NsJrDD9perPfcyYMUvcfWRd4xK1ztitwP1m9k3gRWAHUHlsp5l1ITYd+edajv0N8GJtQQzA3R8EHgQYOXKkjx49OkEl127RokXU6zsqj8Lrfw9XPE+/U3onq6yUqXf/WUS9jw5dRjC53H8u9w6Z2f9oYN/slTyzu5Jffn14g98ZumjRIvqefQs8dBHdzjsX8nNn6dF0+3OPZ5pyB1B9/q17tO04d9/p7hPdfQTwo2jbvmpDrgDmuHtF9ePM7J+BDsDNDag9PbzzCrTpDlkQxEREJDPccdkQ1u48wKwl2xt3onZ9oW1PeOuFxBQmDRJPGHsD6G9mfcysCTAFmFd9gJm1N7Nj57odeLjGOaYC02sccw3wFWCqu2fu3YNa6FVERFKseZN87r/yDO56eh2bysobd7KSSbB6dmIKkwapM4y5+1HgemJTjKXATHdfY2bTzGxcNGw0sN7MNgCdgDuPHW9mvYldWasZux+Ixr4aLXtxR+NaCaCqEkqfVBgTEZGUG9i5FbdeNJDrH13KoYrKug84kSETYN1TscXLJYi4JojdfT4wv8a2O6p9ngXMOsGxW4FutWzP/MnpbYuhZUc4tV/oSkREJAdNHdWDlzft5sfzS5l2eUnDTtK6K3QqgU1/gUGXJrZAiYtW4G8MTVGKiEhAZsaPJw5lwboynln9XsNPVDJRC8AGpDDWUFVVsHaewpiIiATVpnkh904dwY/mrGL73oMNO0nx5bDxL3Dko8QWJ3FRGGuoHW9CszbQYUDoSkREJMed0fMUvvXFvnxvxnKOVjbgmbiW7aHH52D904kvTuqkMNZQmqIUEZE0cu15fWneJJ9fPb+xYSfQU5XBKIw1hLvCmIiIpJW8POMXVwznsTe28cqm3fU/waBLY6/3+3hf3WMloRTGGmLnUihoBh0Hh65ERETkuA6tmnL3Fadz08zl7C6v51IVzdpAny/GlrmQlFIYa4hjV8Ua+AoKERGRZDmvfwcmntGdW/+4gqqqk79/+jNKJumpygAUxupLU5QiIpLmbr5wAPs/ruChl96q34EDvgLbl0D5ruQUJrVSGKuv91YCBp2Hhq5ERESkVoX5edw7ZQQPvLCZFdvqcQ9Yk5bQ/0JYOzd5xclnKIzVl6YoRUQkA/Ro14J/G1/CDdOXceBQRfwHDp2spypTTGGsPtxhzVxNUYqISEa4ZGgXzuvfnh/OXoV7nPeP9bsAdpXC/h3JLU6OUxirj7K1UFkBXUeErkRERCQu//eyYja+X87MN7fFd0BB09gyF2vmJLcwOU5hrD7WPgHF4zRFKSIiGaNZYT73XzmCnz6zno3vfxjfQSWTYfWs5BYmxymM1cfaJ6B4fOgqRERE6qV/p1b849iBXP/oMg5VVNZ9QO/zYP922LM5+cWJwljcdq2HQweg25mhKxEREam3K0b2YEDnVvzbU2vrHpxfELv4sEY38qeCwli81s6LTVHm6X8yERHJPGbGnRNK+OvG3Ty96t26Dxg6GVZpAdhUULKIlxZ6FRGRDNe6WSH3TR3BP81dza6DVScf3H0UHP4Q3o/jSpo0isJYPPZsho/KoMdZoSsRERFplNN7tOW68/vywIrDVFSeJJDl5UHJBL0eKQUUxuKx9gkY/FXIyw9diYiISKNdc25fWhQa9zy34eQDjz1VGe8aZdIgCmPx0BSliIhkkbw841tDm/L40u28vGn3iQd2OR0sH3YuTV1xOUhhrC57t8Ye7+15duhKREREEqZ1U+Purw3n5pnL2V1+uPZBZlAySa9HSjKFsbqsnQeDL4s95isiIpJFzu3fnklndOeWmSuoqjrBVOSxMFZVxw3/0mAKY3XRFKWIiGSxmy4cwIFDFTz00lu1D+g4CFq0g3deTW1hOURh7GT2bYMPtsRWIhYREclChfl53DtlBA+8sJkV2/bVPqhkop6qTCKFsZMpfRIGXQL5haErERERSZoe7Vow7fISbpyxjA8PVXx2wJCJsZmiylr2SaMpjJ2M3kUpIiI54tJhXTi7X3v+ae5qvOZSFu36wCm94a0XgtSW7RTGTuTATti1DvqcH7oSERGRlLjjsmJK3z3ArCXbP7tTT1UmjcLYiZQ+BQMvhoImoSsRERFJieZN8rlv6hnc9fQ6NpWVf3rnkAmw7k9w9ATLYEiDKYydiJ6iFBGRHDSwcytuuWgAN0xfxqGKyk92tO4CnYfCxufCFZelFMZqU14G76+CvmNCVyIiIpJyV47qSe9TW/CTp9d9eoeeqkwKhbHalD4J/S+CwmahKxEREUk5M+MnE4fx3Nr3eXbNe5/sGHw5bHoejnwUrrgspDBWG01RiohIjmvTopB7pw7nh3NW8e7+j2MbW54KPUbB+qfDFpdlFMZqKDyyH3Yuh9O+HLoUERGRoM7s1Y6rz+nDd6cv52hl9DqkkkmaqkwwhbEa2u9eDKddAIXNQ5ciIiIS3LfP70dBvnHfgk2xDYMuha0vwcd7wxaWRRTGauiw6xVNUYqIiETy84x7vj6cR19/h9e27IFmraHv+bEloCQhFMaq+3gvrQ+sh9MuDF2JiIhI2ujUuhn/MXkYNz22nL0fHdFUZYIpjFW3czl7Th0JTYtCVyIiIpJWxgzsyKVDu/D9WSvw/hfBjqVQvit0WVlBYay6fmMoHXxz6CpERETS0g/GDuL9A4f53RtlMOArsHZu6JKygsJYTWahKxAREUlLTQryuG/qCO5dsIm3u47VVGWCKIyJiIhI3Hq3b8kdlxXzrZda42XrYH8tLxWXelEYExERkXoZP6Ibw3p35PVmZ8Pq2aHLyXgKYyIiIlJv/zpuCDMPn8Xe12eELiXjKYyJiIhIvbVsWsDffeMqKvfvYPumVaHLyWgKYyIiItIgQ7q3Y1ePsbww+wGOHK0KXU7GUhgTERGRBht04dWMqXiRnz1TGrqUjKUwJiIiIg1m3UfRqXkVpSsWs3B9WehyMpLCmIiIiDRcXh75JRP56aCN/GDWSsoOHApdUcZRGBMREZHGGTqZbtvnc+XnevC9x5ZTWeWhK8ooCmMiIiLSOJ2HQV4BNww6wNFK54EXNoeuKKMojImIiEjjmEHJJArWzuGXU4bzPy+/xZK3PwhdVcZQGBMREZHGK5kEa2bTtXUTfjxhKDdOX87+gxWhq8oICmMiIiLSeB0GQov28M6rXDSkM18e3JHbZq/EXfeP1UVhTERERBKjZCKsfhyA2y8ZzNY9B3n09XcCF5X+FMZEREQkMUomwdonoLKCZoX53H/lCO5+dgPr3/swdGVpTWFMREREEuOUXtCuL2x5AYB+HYq47eJBXP/oUj4+Uhm4uPQVVxgzs7Fmtt7MNpnZbbXs72Vmz5vZSjNbZGbdo+1jzGx5tZ9DZjY+2tfHzBZH53zMzJoktjURERFJuZJJx6cqAb52ZneKu7Zm2lNrAxaV3uoMY2aWD/wauBgoBqaaWXGNYT8HHnH3YcA04C4Ad1/o7sPdfThwAXAQeDY65qfAPe5+GrAX+PsE9CMiIiIhFY+H9X+CithK/GbGv48v4ZXNu/nTyncDF5ee4rkyNgrY5O5b3P0IMAO4vMaYYmBB9HlhLfsBJgNPu/tBMzNi4WxWtO93wPj6Fi8iIiJppnWX2CKwm547vqlVs0LunTKCO55YzbYPDgYsLj3FE8a6Aduq/b492lbdCmBi9HkC0MrMTq0xZgowPfp8KrDP3Y+e5JwiIiKSiWpMVQKc3qMt153flxtnLKOisipQYenJ6lr/w8wmA2Pd/Zro96uAs9z9+mpjugL3A32AF4FJQIm774v2dwFWAl3dvcLM2gOvRVOUmFkPYlfNSmr5/muBawE6dep05owZMxrZ8smVl5dTVFSU1O9IZ7ncv3rPzd4ht/vP5d4ht/tPZu8FFQf4/GvX8eoXHqayoPnx7VXu3LPkML1a5zF5QLhbxVP15z5mzJgl7j6yrnEFcZxrB9Cj2u/do23HuftOoitjZlYETDoWxCJXAHPc/dhSvHuAtmZWEF0d+8w5q537QeBBgJEjR/ro0aPjKLnhFi1aRLK/I53lcv/qfXToMoLJ5f5zuXfI7f6T3nvZ7zmvYzkMu/hTm4d97jCX3vtXpowp4dz+7ZP3/SeRbn/u8UxTvgH0j55+bEJsunFe9QFm1t7Mjp3rduDhGueYyidTlHjsctxCYveRAfwt8ET9yxcREZG0VMtUJUD7oqbc/bXh3PLH5ewuPxygsPRTZxiLrlxdD/wZKAVmuvsaM5tmZuOiYaOB9Wa2AegE3HnseDPrTezK2gs1Tv2PwM1mtonYPWQPNaoTERERSR8DL4G3X4aP935m17n92zPpjO7cMnMFVVV6XVJc64y5+3x3H+Du/dz9zmjbHe4+L/o8y937R2OucffD1Y7d6u7d3L2qxjm3uPsodz/N3b9W/RgRERHJcM1aQ9/RUPpkrbtvunAABw5V8NuXtqS0rHSkFfhFREQkOU4wVQlQmJ/HvVNG8F8vbGHFtn21jskVCmMiIiKSHAO+AjuXQXlZrbt7tGvBtMtLuGH6Mj48VFHrmFygMCYiIiLJUdgcBoyFNXNPOOTSYV0457T2/GjOaupabitbKYyJiIhI8pxkqvKYOy4rZt17B/jjku0pKiq9KIyJiIhI8vQdA7s3wL5tJxzSvEk+9009g588vY5NZeUpLC49KIyJiIhI8hQ0gcFfhTWzTzpsYOdW3HLRAK5/dCmHKipTVFx6UBgTERGR5IpjqhLgylE96dO+JXfNL01BUelDYUxERESSq/e58OF7sHvTSYeZGT+ZOIy/lJbx7Jr3UlRceApjIiIiklx5+VA8Pq6rY21aFHLv1BH8cM4qdu77OAXFhacwJiIiIsk3dDKsngVxLF9xZq9TuPqcPnxvxnKOVlbVOT7TKYyJiIhI8nX/HFQcgvfXxDX82+f3o7DAuG/Byac2s4HCmIiIiCSfGZRMiF0di0N+nnHPFcN59PV3eG3LniQXF5bCmIiIiKRGyeTYfWNxrrTfsXUz/mPyMG56bDl7PzqS5OLCURgTERGR1Og8FPKbwo4lcR8yZmBHLhvWhe/PWpG1r0tSGBMREZHUMIutObYqvqnKY77/lUGUfXiY/31la3LqCkxhTERERFKnZBKsmQNV8a+y36Qgj3unjOC+BZtYvWN/EosLQ2FMREREUqfDACjqAG+/Uq/DerdvyT9/tZgbpy/jo8NHk1RcGApjIiIiklpxvh6ppsuHd+OMXqdwxxPxLY+RKRTGREREJLWGTITSeVBZUe9D/3XcEJZt28vcZTuSUFgYCmMiIiKSWqf0gnb9YMuieh/asmkB900dwbSn1rJ190eJry0AhTERERFJvQZOVQIM6dqGGy84jRumL+PI0cx/XZLCmIiIiKTekAmwfj5UNOxl4H97dm86tW7GfzyzLsGFpZ7CmIiIiKReq07Q5XTY+FyDDjczfjZ5GPNXvcvCdWUJLi61FMZEREQkjEZMVQKc0rIJ93x9ON+ftZL3DxxKYGGppTAmIiIiYQweB5sXwOEPG3yKs/qeyjfO6slNjy2nsiozX5ekMCYiIiJhtGgHPb8A659u1GluuOA0jlY6D7ywOUGFpZbCmIiIiITTyKlKgIL8PH45ZTj/8/JbLHn7gwQVljoKYyIiIhLOoEtir0Y62LgQ1bVtc348YSg3Tl/O/oP1X0w2JIUxERERCadpK+g3BkqfbPSpLhrSmS8P7shts1finjn3jymMiYiISFgJmKo85vZLBrN1z0H+sPidhJwvFRTGREREJKz+F8G7y+HD9xt9qmaF+dx/5QjufnY9699r+FOaqaQwJiIiImEVNocBF8PauQk5Xb8ORdx+yWCuf3QpHx+pTMg5k0lhTERERMJL4FQlwNfO7E5x19ZMe2pNws6ZLApjIiIiEl7f0bB7I+xLzL1eZsa/jy/hlc17+NPKdxNyzmRRGBMREZHwCppA8ThYPTthp2zVrJB7p4zgjidWs+2Dgwk7b6IpjImIiEh6SPBUJcDpPdry7fP7ccP0ZVRUViX03ImiMCYiIiLpodc5UF4Wm65MoL8/tw9tmhfyi+c2JPS8iaIwJiIiIukhLx+GTEj41bG8POPuK05n9tLt/HXjroSeOxEUxkRERCR9HJuqTPAK+u2LmnL314Zzy8wV7D+cXqvzK4yJiIhI+ug+EioOwfurE37qc/u3Z/KZ3fnvVYepqkqfQKYwJiIiIunDDEomwqpZSTn9TRcOYMip+RxVGBMRERE5gaGTY0tcJOFl34X5eVzcp5AmBekTgdKnEhERERGATiVQ2Ay2vxm6kpRQGBMREZH0YhbdyJ+cqcp0ozAmIiIi6adkEqyZA1Xp/6LvxlIYExERkfTTvj8UdYK3Xw5dSdIpjImIiEh6KpmUtKcq04nCmIiIiKSnkolQ+iQcPRK6kqRSGBMREZH01LZnbLpyy6LQlSSVwpiIiIikrxx4qlJhTERERNJX8XhY/wxUfBy6kqRRGBMREZH01aoTdB0OG58NXUnSKIyJiIhIeiuZBKsfD11F0iiMiYiISHob/FXYvBAOHQhdSVIojImIiEh6a9EOep0N658OXUlSxBXGzGysma03s01mdlst+3uZ2fNmttLMFplZ92r7eprZs2ZWamZrzax3tP1LZrbUzJab2UtmdlqimhIREZEsk8VTlXWGMTPLB34NXAwUA1PNrLjGsJ8Dj7j7MGAacFe1fY8AP3P3wcAooCza/p/AN9x9OPAo8E+NaURERESy2MCL4Z1X4eAHoStJuHiujI0CNrn7Fnc/AswALq8xphhYEH1eeGx/FNoK3P05AHcvd/eD0TgHWkef2wA7G9yFiIiIZLemraDfBVA6L3QlCRdPGOsGbKv2+/ZoW3UrgInR5wlAKzM7FRgA7DOz2Wa2zMx+Fl1pA7gGmG9m24GrgJ80tAkRERHJAVk6VWnufvIBZpOBse5+TfT7VcBZ7n59tTFdgfuBPsCLwCSgBPgy8BAwAngHeAyY7+4Pmdls4KfuvtjMvg8MPPYdNb7/WuBagE6dOp05Y8aMRrZ8cuXl5RQVFSX1O9JZLvev3nOzd8jt/nO5d8jt/jOx97zKw3zh1at543P3c6RpuwafJ1W9jxkzZom7j6xrXEEc59oB9Kj2e/do23HuvpPoypiZFQGT3H1fdNVrubtvifbNBT5vZvOA0919cXSKx4Bnavtyd38QeBBg5MiRPnr06DhKbrhFixaR7O9IZ7ncv3ofHbqMYHK5/1zuHXK7/4zt/cA4zm5TBp+fWPfYE0i33uOZpnwD6G9mfcysCTAF+NSErZm1N7Nj57odeLjasW3NrEP0+wXAWmAv0MbMBkTbLwRKG96GiIiI5IQsnKqsM4y5+1HgeuDPxALTTHdfY2bTzGxcNGw0sN7MNgCdgDujYyuBW4HnzWwVYMB/R+f8FvC4ma0gds/Y9xPamYiIiGSfvqPhg82w9+3QlSRMPNOUuPt8YH6NbXdU+zwLqPWV6tGTlMNq2T4HmFOfYkVERCTH5RfC4HGwZjace1PoahJCK/CLiIhIZsmyqUqFMREREcksvc6G8l2wa0PoShJCYUxEREQyS14+lEzMmqtjCmMiIiKSeY5NVdaxXmomUBgTERGRzNPtTKg8Au+tCl1JoymMiYiISOYxi66O1bqYQ0ZRGBMREZHMVDIJVs/O+KlKhTERERHJTJ2GQGEL2P5G6EoaRWFMREREMpMZDJ0MqzJ7qlJhTERERDLXkImwdi5UVYaupMEUxkRERCRztT8NWnWGrS+FrqTBFMZEREQks2X4U5UKYyIiIpLZhkyE0ifh6JHQlTSIwpiIiIhktrY9oP1A2LIwdCUNojAmIiIima9kUsY+VakwJiIiIplvyHjY8Gc4cjB0JfWmMCYiIiKZr6gjdBsBG58NXUm9KYyJiIhIdsjQpyoVxkRERCQ7DP4qbHkBDh0IXUm9KIyJiIhIdmh+CvQ6B9bPD11JvSiMiYiISPbIwKcqFcZEREQkewy8GLYtho/2hK4kbgpjIiIikj2aFsFpX4LSeaEriZvCmIiIiGSXkkmw+vHQVcRNYUxERESyy2kXwnur4MC7oSuJi8KYiIiIZJfCZjDwElg7N3QlcVEYExERkeyTQVOVCmMiIiKSffqeDx9sgb1bQ1dSJ4UxERERyT75hVB8OayeHbqSOimMiYiISHYqmaQwJiIiIhJMzy/Awd2wa33oSk5KYUxERESyU14+DJmY9jfyK4yJiIhI9jr2FBazlAAAB91JREFUVKV76EpOSGFMREREsle3M6DqKLy7InQlJ6QwJiIiItnLLO3XHFMYExERkexWMgnWzIGqqtCV1EphTERERLJbx2Jo0hK2vx66klopjImIiEh2M4OSyWk7VakwJiIiItmvZCKsmQuVR0NX8hkKYyIiIpL9Tu0HrbvC2y+FruQzFMZEREQkNwydDKtmha7iMxTGREREJDcMmQDrnsKqKkJX8ikKYyIiIpIb2nSHDoNo98Hy0JV8isKYiIiI5I6SSXQsezF0FZ+iMCYiIiK5o3g8bfetSqunKhXGREREJHcUdWDxWf8F+QWhKzlOYUxERERySlV+09AlfIrCmIiIiEhACmMiIiIiASmMiYiIiASkMCYiIiISkMKYiIiISEAKYyIiIiIBKYyJiIiIBKQwJiIiIhKQwpiIiIhIQHGFMTMba2brzWyTmd1Wy/5eZva8ma00s0Vm1r3avp5m9qyZlZrZWjPrHW03M7vTzDZE+25MVFMiIiIimaLOFzOZWT7wa+BCYDvwhpnNc/e11Yb9HHjE3X9nZhcAdwFXRfseAe509+fMrAioirZ/E+gBDHL3KjPrmJCORERERDJIPFfGRgGb3H2Lux8BZgCX1xhTDCyIPi88tt/MioECd38OwN3L3f1gNO4fgGnuXhXtK2tUJyIiIiIZyNz95APMJgNj3f2a6PergLPc/fpqYx4FFrv7r8xsIvA40B44D7gGOAL0Af4C3ObulWa2B/gFMAHYBdzo7htr+f5rgWsBOnXqdOaMGTMa2fLJlZeXU1RUlNTvSGe53L96z83eIbf7z+XeIbf7V+/J733MmDFL3H1kXePqnKaM063A/Wb2TeBFYAdQGZ3/PGAE8A7wGLHpyYeApsAhdx8ZBbiHo7Gf4u4PAg8CjBw50kePHp2gkmu3aNEikv0d6SyX+1fvo0OXEUwu95/LvUNu96/eR4cu47h4pil3ELu365ju0bbj3H2nu0909xHAj6Jt+4jdY7Y8muI8CswFzogO2w7Mjj7PAYY1uAsRERGRDBXPlbE3gP5m1odYCJsCXFl9gJm1Bz6I7v+6ndhVrmPHtjWzDu6+C7gAeDPaNxcYA7wFnA9sqKuQJUuW7Dazt+OouTHaA7uT/B3pLJf7V++5K5f7z+XeIbf7V+/J1yueQXXeMwZgZpcAvwTygYfd/U4zmwa86e7zovvK7gKc2DTld9z9cHTshcDdgAFLgGvd/YiZtQX+APQEyoFvu/uKejaZcGb2Zjzzu9kql/tX77nZO+R2/7ncO+R2/+o9fXqP654xd58PzK+x7Y5qn2cBs05w7HPUMgUZTWNeWp9iRURERLKNVuAXERERCUhh7LMeDF1AYLncv3rPXbncfy73Drndv3pPE3HdMyYiIiIiyaErYyIiIiIBKYxVU9cL0bOZmT1sZmVmtjp0LalmZj3MbGH0Ivs1Zvbd0DWlipk1M7PXzWxF1Pu/hq4p1cws38yWmdlToWtJNTPbamarzGy5mb1Z9xHZw8zamtksM1tnZqVm9oXQNaWKmQ2M/syP/Rwws++FritVzOym6O+71WY23cyaBa9J05Qx0QvRN1DthejA1BovRM9aZvZFYkuMPOLuJaHrSSUz6wJ0cfelZtaK2BIs43Phz97MDGjp7uVmVgi8BHzX3V8LXFrKmNnNwEigtbtfFrqeVDKzrcBId8+5tabM7HfAX939t2bWBGgRPeWfU6L/9u0g9prDZK/jGZyZdSP291yxu39sZjOB+e7+vyHr0pWxT8TzQvSs5e4vAh+EriMEd3/X3ZdGnz8ESoFuYatKDY8pj34tjH5y5l9oZtad2BI7vw1di6SOmbUBvkjs1Xy4+5FcDGKRLwGbcyGIVVMANDezAqAFsDNwPQpj1XQDtlX7fTs58h9k+YSZ9Sb2LtXFYStJnWiabjlQBjzn7jnTO7HFrH8AVIUuJBAHnjWzJWZ2behiUqgPsAv4n2iK+rdm1jJ0UYFMAaaHLiJV3H0H8HNi78t+F9jv7s+GrUphTOQ4MysCHge+5+4HQteTKu5e6e7Dib13dpSZ5cQ0tZldBpS5+5LQtQR0rrufAVwMfCe6XSEXFBB7T/J/Ru9U/gjIqfuEAaLp2XHAH0PXkipmdgqxWa8+QFegpZn9TdiqFMaqq/OF6JK9ovulHgf+4O6z6xqfjaJpmoXA2NC1pMg5wLjovqkZwAVm9v/ClpRa0VUC3L0MmEPsdo1csB3YXu0q8Cxi4SzXXAwsdff3QxeSQl8G3nL3Xe5eAcwGzg5ck8JYNcdfiB79a2EKMC9wTZIC0U3sDwGl7v6L0PWkkpl1iN4Ti5k1J/YAy7qwVaWGu9/u7t3dvTex/78vcPfg/0JOFTNrGT2wQjRFdxGQE09Tu/t7wDYzGxht+hKQ9Q/s1GIqOTRFGXkH+LyZtYj+7v8SsfuEg4rr3ZS5wN2Pmtn1wJ/55IXoawKXlTJmNh0YDbQ3s+3AP7v7Q2GrSplzgKuAVdG9UwA/jN7Jmu26AL+LnqjKA2a6e84t8ZCjOgFzYv89ogB41N2fCVtSSt0A/CH6x/cW4OrA9aRUFMAvBK4LXUsquftiM5sFLAWOAstIg9X4tbSFiIiISECaphQREREJSGFMREREJCCFMREREZGAFMZEREREAlIYExEREQlIYUxEREQkIIUxERERkYAUxkREREQC+v+IiSi1qplEGgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot Bengio \n",
    "\n",
    "# load results\n",
    "resSaveFile = '3n4'\n",
    "saveDir = 'bengioResults'\n",
    "acc3n4 = load_obj(saveDir,resSaveFile)\n",
    "\n",
    "resSaveFile = '3n4plus'\n",
    "saveDir = 'bengioResults'\n",
    "acc3n4plus = load_obj(saveDir,resSaveFile)\n",
    "\n",
    "\n",
    "# plot results\n",
    "AnB = acc3n4\n",
    "AnBplus = acc3n4plus\n",
    "x = [i for i in range(len(AnB))]\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x,AnB, label = '3n4', linewidth = 1)\n",
    "ax.plot(x,AnBplus, label = '3n4plus', linewidth = 1)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (49821, 4, 8, 8)\n",
      "y_train shape: (49821, 1)\n",
      "X_test shape: (24539, 4, 8, 8)\n",
      "y_test shape: (24539, 1)\n",
      "49821 train samples\n",
      "24539 test samples\n",
      "Done loading dataset\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_176 (Conv2D)          (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_177 (Conv2D)          (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_178 (Conv2D)          (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_179 (Conv2D)          (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_180 (Conv2D)          (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_181 (Conv2D)          (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_182 (Conv2D)          (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n",
      "=========== At layer 0 of 8 ===========\n",
      "Loading first 0 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 1: <keras.layers.convolutional.Conv2D object at 0x7f38480503c8>\n",
      "- Resetting layer nr 2: <keras.layers.convolutional.Conv2D object at 0x7f38481db668>\n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f3836defd68>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frimann/anaconda3/envs/endnetGpu/lib/python3.5/site-packages/keras/engine/training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 4s 73us/step - loss: 0.9411 - acc: 0.5274 - val_loss: 0.8195 - val_acc: 0.6341\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 68us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.8194782437873628\n",
      "Evaluated test accuracy: 0.6341334202576298\n",
      "Loading first 0 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 1: <keras.layers.convolutional.Conv2D object at 0x7f38480503c8>\n",
      "- Resetting layer nr 2: <keras.layers.convolutional.Conv2D object at 0x7f38481db668>\n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f3836defd68>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 1.0125 - acc: 0.4800 - val_loss: 0.8490 - val_acc: 0.5998\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 68us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.8489892382295117\n",
      "Evaluated test accuracy: 0.5998206936189435\n",
      "Loading first 0 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 1: <keras.layers.convolutional.Conv2D object at 0x7f38480503c8>\n",
      "- Resetting layer nr 2: <keras.layers.convolutional.Conv2D object at 0x7f38481db668>\n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f3836defd68>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 1.0083 - acc: 0.4804 - val_loss: 0.7866 - val_acc: 0.6338\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7865669600508597\n",
      "Evaluated test accuracy: 0.6338481600765805\n",
      "=========== At layer 1 of 8 ===========\n",
      "Loading first 1 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 2: <keras.layers.convolutional.Conv2D object at 0x7f38481db668>\n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f3836defd68>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 0.9094 - acc: 0.5514 - val_loss: 0.7213 - val_acc: 0.6744\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7213149213393513\n",
      "Evaluated test accuracy: 0.6743551082169787\n",
      "Loading first 1 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 2: <keras.layers.convolutional.Conv2D object at 0x7f38481db668>\n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f3836defd68>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 0.9297 - acc: 0.5341 - val_loss: 0.7770 - val_acc: 0.6396\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7770048349001495\n",
      "Evaluated test accuracy: 0.6396348669586382\n",
      "Loading first 1 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 2: <keras.layers.convolutional.Conv2D object at 0x7f38481db668>\n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f3836defd68>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.9562 - acc: 0.5207 - val_loss: 0.7384 - val_acc: 0.6626\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 67us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7384131096740375\n",
      "Evaluated test accuracy: 0.6625779371345347\n",
      "=========== At layer 2 of 8 ===========\n",
      "Loading first 2 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f3836defd68>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.8920 - acc: 0.5682 - val_loss: 0.7374 - val_acc: 0.6636\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.737449422894638\n",
      "Evaluated test accuracy: 0.6636374750275877\n",
      "Loading first 2 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f3836defd68>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.8943 - acc: 0.5657 - val_loss: 0.7168 - val_acc: 0.6779\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 67us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7168304132163814\n",
      "Evaluated test accuracy: 0.6778597334733272\n",
      "Loading first 2 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 3: <keras.layers.convolutional.Conv2D object at 0x7f3836defd68>\n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.8924 - acc: 0.5653 - val_loss: 0.7094 - val_acc: 0.6832\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7094065823236894\n",
      "Evaluated test accuracy: 0.6832389257721653\n",
      "=========== At layer 3 of 8 ===========\n",
      "Loading first 3 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.8535 - acc: 0.5960 - val_loss: 0.6691 - val_acc: 0.7127\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 65us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.6691200025502625\n",
      "Evaluated test accuracy: 0.712661477628394\n",
      "Loading first 3 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 0.8452 - acc: 0.6012 - val_loss: 0.7174 - val_acc: 0.6993\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7173769015001635\n",
      "Evaluated test accuracy: 0.699254248361239\n",
      "Loading first 3 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 4: <keras.layers.convolutional.Conv2D object at 0x7f3836f571d0>\n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.8612 - acc: 0.5889 - val_loss: 0.7053 - val_acc: 0.6780\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 67us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.705271925296715\n",
      "Evaluated test accuracy: 0.6779819878293472\n",
      "=========== At layer 4 of 8 ===========\n",
      "Loading first 4 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.7778 - acc: 0.6471 - val_loss: 0.5662 - val_acc: 0.7655\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5661920409334906\n",
      "Evaluated test accuracy: 0.765516117198761\n",
      "Loading first 4 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.7841 - acc: 0.6403 - val_loss: 0.6021 - val_acc: 0.7470\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 65us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.6021327972363529\n",
      "Evaluated test accuracy: 0.746974204301086\n",
      "Loading first 4 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 5: <keras.layers.convolutional.Conv2D object at 0x7f3836fb8a58>\n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.7914 - acc: 0.6387 - val_loss: 0.6522 - val_acc: 0.7160\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.6522488905789969\n",
      "Evaluated test accuracy: 0.7160030971082927\n",
      "=========== At layer 5 of 8 ===========\n",
      "Loading first 5 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.7283 - acc: 0.6736 - val_loss: 0.5023 - val_acc: 0.7932\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 67us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5023260084296056\n",
      "Evaluated test accuracy: 0.7932271078666774\n",
      "Loading first 5 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 0.7287 - acc: 0.6758 - val_loss: 0.5378 - val_acc: 0.7820\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5377881138650901\n",
      "Evaluated test accuracy: 0.7819797057477627\n",
      "Loading first 5 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 6: <keras.layers.convolutional.Conv2D object at 0x7f3836f4fef0>\n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 0.7260 - acc: 0.6727 - val_loss: 0.5205 - val_acc: 0.7875\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5205301201825931\n",
      "Evaluated test accuracy: 0.7874811524244814\n",
      "=========== At layer 6 of 8 ===========\n",
      "Loading first 6 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.7290 - acc: 0.6808 - val_loss: 0.5539 - val_acc: 0.7677\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5538778462329914\n",
      "Evaluated test accuracy: 0.7677166958694485\n",
      "Loading first 6 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.7213 - acc: 0.6837 - val_loss: 0.5115 - val_acc: 0.7886\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 65us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5114826017945848\n",
      "Evaluated test accuracy: 0.7885814418011178\n",
      "Loading first 6 layers from results Results/103/weights.hdf5, \n",
      "- Resetting layer nr 7: <keras.layers.convolutional.Conv2D object at 0x7f3848108780>\n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 0.7351 - acc: 0.6755 - val_loss: 0.5311 - val_acc: 0.7793\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5311151653718889\n",
      "Evaluated test accuracy: 0.7793308610515648\n",
      "=========== At layer 7 of 8 ===========\n",
      "Loading first 7 layers from results Results/103/weights.hdf5, \n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 0.7697 - acc: 0.6581 - val_loss: 0.5868 - val_acc: 0.7569\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5867953887705338\n",
      "Evaluated test accuracy: 0.7569175598246237\n",
      "Loading first 7 layers from results Results/103/weights.hdf5, \n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 0.7542 - acc: 0.6687 - val_loss: 0.5708 - val_acc: 0.7682\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 67us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5707559295527251\n",
      "Evaluated test accuracy: 0.7681649619119617\n",
      "Loading first 7 layers from results Results/103/weights.hdf5, \n",
      "- Skipping layer nr 8: <keras.layers.core.Flatten object at 0x7f38480ffeb8>\n",
      "- Resetting layer nr 9: <keras.layers.core.Dense object at 0x7f3837919ba8>\n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 0.7794 - acc: 0.6556 - val_loss: 0.5749 - val_acc: 0.7614\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.5749062031375113\n",
      "Evaluated test accuracy: 0.7614002200554381\n",
      "=========== At layer 8 of 8 ===========\n",
      "=========== At layer 9 of 8 ===========\n",
      "Loading first 9 layers from results Results/103/weights.hdf5, \n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 1.3739 - acc: 0.5714 - val_loss: 0.7428 - val_acc: 0.6740\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7427915640776818\n",
      "Evaluated test accuracy: 0.6740290965693491\n",
      "Loading first 9 layers from results Results/103/weights.hdf5, \n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 38us/step - loss: 1.3367 - acc: 0.5874 - val_loss: 0.7394 - val_acc: 0.6798\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 67us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7394437517361583\n",
      "Evaluated test accuracy: 0.679815803427117\n",
      "Loading first 9 layers from results Results/103/weights.hdf5, \n",
      "Train on 49821 samples, validate on 24539 samples\n",
      "Epoch 1/1\n",
      "49821/49821 [==============================] - 2s 39us/step - loss: 1.3776 - acc: 0.5806 - val_loss: 0.7467 - val_acc: 0.6755\n",
      "Training done\n",
      "Calculating score\n",
      "24539/24539 [==============================] - 2s 66us/step\n",
      "(49821, 4, 8, 8)\n",
      "Evaluated test loss: 0.7467082970576374\n",
      "Evaluated test accuracy: 0.6754961489678944\n",
      "/n Final Results: results\n"
     ]
    }
   ],
   "source": [
    "# 3n4 Freeze\n",
    "%run -i 'arena.py'\n",
    "\n",
    "# Parameters\n",
    "sourceNet = '103'\n",
    "freeze = True\n",
    "resSaveFile = '3n4plus'\n",
    "epochs = 1\n",
    "averageOver = 3 \n",
    "expDescr = \"Bengio - freeze = {} - average over {} runs\".format(str(freeze), averageOver)\n",
    "\n",
    "saveEveryRun = False # save stuff in results dir\n",
    "saveWeightsCheckpoints = False # save chkp in results dit\n",
    "saveTensorboardLogs = False # save logs in ./logs dir\n",
    "resSaveFile = resSaveFile + '-{} run average'.format(averageOver)\n",
    "fractionOfDataToUse = 0.01\n",
    "plotDuringTraining = False\n",
    "loadWeights = False \n",
    "askForConfirmation = False\n",
    "saveDir = 'bengioResults'\n",
    "\n",
    "X_train, X_test, y_train, y_test = loadData()\n",
    "model, nnStr = createModel()\n",
    "results = []\n",
    "accumulatedScore = 0\n",
    "layersCount = len(model.layers)\n",
    "\n",
    "for copyFirstNLayers in range(layersCount + 1):\n",
    "    print('=========== At layer {} of {} ==========='.format(copyFirstNLayers, layersCount - 1))\n",
    "    if copyFirstNLayers != layersCount - 1:\n",
    "        accumulatedScore = 0\n",
    "        for a in range(averageOver):\n",
    "            model = loadNFirstLayers(model, sourceNet, copyFirstNLayers , freeze)\n",
    "\n",
    "            if saveEveryRun:\n",
    "                resID = genNextResultsDir(model)\n",
    "                #add freeze and some tl parameters to save dir\n",
    "\n",
    "            # train\n",
    "            fitHistory, logDir = trainModel(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\n",
    "\n",
    "            # score and save accuracy\n",
    "            score = calcScore(model)\n",
    "            if saveEveryRun:\n",
    "                saveTrainResults(resID, model, logDir, score, copyFirstNLayers)\n",
    "            \n",
    "            # update Return\n",
    "            accumulatedScore += score[1]\n",
    "        results.append(accumulatedScore/averageOver)\n",
    "\n",
    "        # save results incrementally to txt file\n",
    "        save_obj(saveDir, resSaveFile, results)\n",
    "        with open(saveDir + '/' + str(resSaveFile) + '.txt','w') as file:\n",
    "            file.write(str(results))\n",
    "            \n",
    "        # to load:\n",
    "        # results = load_obj('temp','3n4.txt')\n",
    "print('/n Final Results: results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_148 (Conv2D)          (None, 16, 7, 7)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_149 (Conv2D)          (None, 15, 6, 32)         928       \n",
      "_________________________________________________________________\n",
      "conv2d_150 (Conv2D)          (None, 14, 5, 32)         4128      \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 13, 4, 64)         8256      \n",
      "_________________________________________________________________\n",
      "conv2d_152 (Conv2D)          (None, 12, 3, 128)        32896     \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 11, 2, 128)        65664     \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 10, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 3)                 3843      \n",
      "=================================================================\n",
      "Total params: 181,651\n",
      "Trainable params: 181,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Starting with random weights\n",
      "Done creating model\n",
      "X_train shape: (49821, 4, 8, 8)\n",
      "y_train shape: (49821, 1)\n",
      "X_test shape: (24539, 4, 8, 8)\n",
      "y_test shape: (24539, 1)\n",
      "49821 train samples\n",
      "24539 test samples\n",
      "Done loading dataset\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'initWeightsId' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/projects/Endnet/mainCode/arena.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# resID = genNextResultsDir(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfitHistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# score = calcScoreBigData(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# score = calcScore(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/Endnet/mainCode/arena.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(resID, model, saveWeightsCheckpoints, saveTensorboardLogs)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mcallbacksArr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msaveTensorboardLogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mlogDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./logs/{}-{}pc-{}-{}KPM-{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnPi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitWeightsId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpDescr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdateTime\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mcallbacksArr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'initWeightsId' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Train, evaluate and save \n",
    "%run -i 'arena.py'\n",
    "# %reload_ext autoreload\n",
    "plotDuringTraining = True\n",
    "fractionOfDataToUse = 0.01\n",
    "model, nnStr = createModel()\n",
    "# resID = genNextResultsDir(model)\n",
    "X_train, X_test, y_train, y_test = loadData()\n",
    "fitHistory, logDir = trainModel(resID, model)\n",
    "# score = calcScoreBigData(model)\n",
    "# score = calcScore(model)\n",
    "# saveTrainResults(resID, model, logDir, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:endnetGpu]",
   "language": "python",
   "name": "conda-env-endnetGpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
